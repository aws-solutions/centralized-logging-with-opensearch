{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The Log Hub solution provides comprehensive log management and analysis functions to help you simplify the build of log analytics pipelines. Built on top of Amazon OpenSearch Service, the solution allows you to streamline effectively log ingestion, log processing, and log visualization. You can leverage the solution in multiple use cases such as to abide by security and compliance regulations, achieve refined business operations, and enhance IT troubleshooting and maintenance. The solution has the following features: All-in-one log ingestion : provides a single web console to ingest both application logs and AWS service logs into the Amazon OpenSearch (AOS) domains. For supported AWS service logs, see AWS service logs . For supported application logs, see Application logs . Codeless log processor : supports log processor plugins developed by AWS. You are allowed to enrich the raw log data through a few clicks on the web console. Out-of-box dashboard template : offers a collection of reference designs of visualization templates, for both commonly used software such as Nginx and Apache HTTP Server, and AWS services such as Amazon S3 and Amazon CloudTrail. This guide includes a getting started chapter to walk you through the process of building log analytics pipelines, and a domain management chapter to introduce how to import AOS domains on the Log Hub web console. This implementation guide describes architectural considerations and configuration steps for deploying the Log Hub solution in the AWS cloud. It includes links to CloudFormation templates that launches and configures the AWS services required to deploy this solution using AWS best practices for security and availability. The guide is intended for IT architects, developers, DevOps, data engineers with practical experience architecting on the AWS Cloud.","title":"Overview"},{"location":"designs/","text":"Log Hub Important If you are looking for the user/implementation guide of Log Hub, please refer to Implementation Guide . The content here are design documentations of Log Hub solution. We have a plan to open source all our designs (including historical designs) on this site. However, we do NOT guarantee all documentations here are implemented in the Log Hub solution. Log Hub is an AWS Solution simplifies the build of log analytics pipelines on top of Amazon OpenSearch Service, which helps customers to improve engineering efficiency on log ingestion, log processing and log visualization. The Log Hub solution provides to customers, as a complementary of Amazon OpenSearch Service, capabilities of centralized log ingestion across multiple regions and account, one-click creation of codeless log processors and templated dashboards for visualization. With the unified web console, the Log Hub solution allows customers to create end-to-end log analytics workloads by automating the orchestration of different AWS services within minutes. Resources GitHub Repo Feature Request/Bug Report","title":"Overview"},{"location":"designs/#log-hub","text":"Important If you are looking for the user/implementation guide of Log Hub, please refer to Implementation Guide . The content here are design documentations of Log Hub solution. We have a plan to open source all our designs (including historical designs) on this site. However, we do NOT guarantee all documentations here are implemented in the Log Hub solution. Log Hub is an AWS Solution simplifies the build of log analytics pipelines on top of Amazon OpenSearch Service, which helps customers to improve engineering efficiency on log ingestion, log processing and log visualization. The Log Hub solution provides to customers, as a complementary of Amazon OpenSearch Service, capabilities of centralized log ingestion across multiple regions and account, one-click creation of codeless log processors and templated dashboards for visualization. With the unified web console, the Log Hub solution allows customers to create end-to-end log analytics workloads by automating the orchestration of different AWS services within minutes.","title":"Log Hub"},{"location":"designs/#resources","text":"GitHub Repo Feature Request/Bug Report","title":"Resources"},{"location":"designs/FAQ/","text":"Internal FAQ Will the solution support self-hosted Elasticsearch domain in the future? There is no clear answer for this question yet. We have heard from customers that the AOS price is too high comparing to self-hosted Elasticsearch domain. Because of this, we have added this feature in our backlog. However, we need more information to prioritize our backlogs. Currently, it is in low priority.","title":"Internal FAQ"},{"location":"designs/FAQ/#internal-faq","text":"","title":"Internal FAQ"},{"location":"designs/FAQ/#will-the-solution-support-self-hosted-elasticsearch-domain-in-the-future","text":"There is no clear answer for this question yet. We have heard from customers that the AOS price is too high comparing to self-hosted Elasticsearch domain. Because of this, we have added this feature in our backlog. However, we need more information to prioritize our backlogs. Currently, it is in low priority.","title":"Will the solution support self-hosted Elasticsearch domain in the future?"},{"location":"designs/assets/","text":"Assets Here are some (not all) assets that help in building the Log Hub solution. We appreciate their great contribution to those blogs, open source products. Blogs Configuring and authoring Kibana dashboards Query and analyze Amazon S3 data with the new Amazon Athena plugin for Grafana Query data in Amazon OpenSearch Service using SQL from Amazon Athena Build an observability solution using managed AWS services and the OpenTelemetry standard Deploy a dashboard for AWS WAF with minimal effort Log Analytics on AWS \u5728 AWS \u4e2d\u56fd\u533a\u5bf9 Amazon Elasticsearch Kibana \u8fdb\u884c\u8eab\u4efd\u8ba4\u8bc1\u7684\u89e3\u51b3\u65b9\u6848 GitHub projects awslabs/centralized-logging siem-on-amazon-opensearch-service mingrammer/flog aws-samples/amazon-elasticsearch-service-with-cognito jkeczan/aws-api-gateway-elastic-search-proxy","title":"Assets"},{"location":"designs/assets/#assets","text":"Here are some (not all) assets that help in building the Log Hub solution. We appreciate their great contribution to those blogs, open source products.","title":"Assets"},{"location":"designs/assets/#blogs","text":"Configuring and authoring Kibana dashboards Query and analyze Amazon S3 data with the new Amazon Athena plugin for Grafana Query data in Amazon OpenSearch Service using SQL from Amazon Athena Build an observability solution using managed AWS services and the OpenTelemetry standard Deploy a dashboard for AWS WAF with minimal effort Log Analytics on AWS \u5728 AWS \u4e2d\u56fd\u533a\u5bf9 Amazon Elasticsearch Kibana \u8fdb\u884c\u8eab\u4efd\u8ba4\u8bc1\u7684\u89e3\u51b3\u65b9\u6848","title":"Blogs"},{"location":"designs/assets/#github-projects","text":"awslabs/centralized-logging siem-on-amazon-opensearch-service mingrammer/flog aws-samples/amazon-elasticsearch-service-with-cognito jkeczan/aws-api-gateway-elastic-search-proxy","title":"GitHub projects"},{"location":"designs/concepts/","text":"Concepts We created a couple of concepts to keep us at the same page. The following session will explain the definition of each concept. Solution Components Search Engine . The Search Engine is a bottom layer to index the log information and provide CRUD (Create, Read, Update, Delete) capability to the other applications. In this system, the Search Engine represents Amazon Elasticsearch (AES) cluster by default. Log Visual . It is a piece of software used to build up visuals, metrics and dashboard. In this system, the Log Visual represents the Kibana associated with the AES cluster. Log Visual Template . A Log Visual Template is a standard configuration of commonly used applications (or AWS native service) in Log Visual. For example, a standard dashboard template for Nginx, Apache, MySQL, or CloudFront. Log Buffer . A middle layer between Log Agent and AES. We introduce this layer to protect the engine layer from being overwhelmed. Log Jobs . A Layer between Log Buffer Layer and Search Engine. In this layer, the users can perform some data cleanup using some additional compute resource. For example, Lambda, Glue. Log Store . A storage media to keep log data. Instance Agent . An Instance Agent is a piece of software installed on EC2 instances (or on-premise instances) which can be used to collect log and report to Amazon Elasticsearch (AES), Log Buffer or Log Storage. Container Agent . A daemon agent which being used on ECS/EKS cluster to collect log and report to Search Engine, Cache Layer or Storage Layer. Mobile SDK . An SDK embedded in the mobile (iOS, Android, Web) client. Customers can use this SDK to authenticate against AWS and send log, click stream to AWS. Configuration Center . It is a portal deployed in the customer's AWS account protected by Cognito User Pool or OpenID Connect Provider. Customers can manage/import Search Engine, install/configure log agents, backup data and others. Log Format Config . A log format template is a configuration file for log agent to know the format of the log, the location of the log file, the destination of the log, the local log processor, and others. Log Collector for Services . A component used to extract logs from AWS native services and send to Log Buffer or Log Engine. For example, Log Collector for Lambda is a component used to extract data from CloudWatch Logs and upload to AES or Kinesis. Log Collector for CloudFront is a component extract logs from S3 and upload to AES or Kinesis. Log Collector for Lambda@Edge can extract logs from CloudWatch Logs in different regions and upload. Log Monitor . A component to create alarm and send notifications. In this system, we use the Kibana built-in feature together with SNS. We also extend SNS notification target to support WeChat Enterprise account and DingTalk. Multi-tenant . A fine-grained access control to log data. Workload Simulator . A typical workload architect with application running on AWS. For example, a 3-tier web application. This is used for customers to get sample experience of this solution. Traffic Generator . A piece of software used to generate web traffic, this will cause the simulated workload to generate logs. Accounts Main Account . The main AWS account which contains the underlying infrastructure like Search Engine, Log Buffer, Log Jobs, Log Storage, Configuration Center and others. All logs are sent to this account for further analysis and storage. Sub Account . The other AWS accounts where your application are deployed and need to be sent to the centralized logging platform. Solution Assets Deliverables . Amazon CloudFormation templates or AWS CDK package used to create a solution component or a combination of solution components. The rest assets like Lambda code will be hosted in public S3 buckets owned by Solutions Builder team. Implementation Guide . A user manual gives guidance to the customers how to use the solution. It includes a step-by-step Getting Started guide. Workshop Portal . A portal hosting the associated solution workshop. The workshop content can be used for the field team to organize an offline customer facing workshop.","title":"Concepts"},{"location":"designs/concepts/#concepts","text":"We created a couple of concepts to keep us at the same page. The following session will explain the definition of each concept.","title":"Concepts"},{"location":"designs/concepts/#solution-components","text":"Search Engine . The Search Engine is a bottom layer to index the log information and provide CRUD (Create, Read, Update, Delete) capability to the other applications. In this system, the Search Engine represents Amazon Elasticsearch (AES) cluster by default. Log Visual . It is a piece of software used to build up visuals, metrics and dashboard. In this system, the Log Visual represents the Kibana associated with the AES cluster. Log Visual Template . A Log Visual Template is a standard configuration of commonly used applications (or AWS native service) in Log Visual. For example, a standard dashboard template for Nginx, Apache, MySQL, or CloudFront. Log Buffer . A middle layer between Log Agent and AES. We introduce this layer to protect the engine layer from being overwhelmed. Log Jobs . A Layer between Log Buffer Layer and Search Engine. In this layer, the users can perform some data cleanup using some additional compute resource. For example, Lambda, Glue. Log Store . A storage media to keep log data. Instance Agent . An Instance Agent is a piece of software installed on EC2 instances (or on-premise instances) which can be used to collect log and report to Amazon Elasticsearch (AES), Log Buffer or Log Storage. Container Agent . A daemon agent which being used on ECS/EKS cluster to collect log and report to Search Engine, Cache Layer or Storage Layer. Mobile SDK . An SDK embedded in the mobile (iOS, Android, Web) client. Customers can use this SDK to authenticate against AWS and send log, click stream to AWS. Configuration Center . It is a portal deployed in the customer's AWS account protected by Cognito User Pool or OpenID Connect Provider. Customers can manage/import Search Engine, install/configure log agents, backup data and others. Log Format Config . A log format template is a configuration file for log agent to know the format of the log, the location of the log file, the destination of the log, the local log processor, and others. Log Collector for Services . A component used to extract logs from AWS native services and send to Log Buffer or Log Engine. For example, Log Collector for Lambda is a component used to extract data from CloudWatch Logs and upload to AES or Kinesis. Log Collector for CloudFront is a component extract logs from S3 and upload to AES or Kinesis. Log Collector for Lambda@Edge can extract logs from CloudWatch Logs in different regions and upload. Log Monitor . A component to create alarm and send notifications. In this system, we use the Kibana built-in feature together with SNS. We also extend SNS notification target to support WeChat Enterprise account and DingTalk. Multi-tenant . A fine-grained access control to log data. Workload Simulator . A typical workload architect with application running on AWS. For example, a 3-tier web application. This is used for customers to get sample experience of this solution. Traffic Generator . A piece of software used to generate web traffic, this will cause the simulated workload to generate logs.","title":"Solution Components"},{"location":"designs/concepts/#accounts","text":"Main Account . The main AWS account which contains the underlying infrastructure like Search Engine, Log Buffer, Log Jobs, Log Storage, Configuration Center and others. All logs are sent to this account for further analysis and storage. Sub Account . The other AWS accounts where your application are deployed and need to be sent to the centralized logging platform.","title":"Accounts"},{"location":"designs/concepts/#solution-assets","text":"Deliverables . Amazon CloudFormation templates or AWS CDK package used to create a solution component or a combination of solution components. The rest assets like Lambda code will be hosted in public S3 buckets owned by Solutions Builder team. Implementation Guide . A user manual gives guidance to the customers how to use the solution. It includes a step-by-step Getting Started guide. Workshop Portal . A portal hosting the associated solution workshop. The workshop content can be used for the field team to organize an offline customer facing workshop.","title":"Solution Assets"},{"location":"designs/log-analytics-pipeline-service/","text":"Service Log Amazon S3 Access Log Amazon CloudTrail Log","title":"Service Log"},{"location":"designs/log-analytics-pipeline-service/#service-log","text":"","title":"Service Log"},{"location":"designs/log-analytics-pipeline-service/#amazon-s3-access-log","text":"","title":"Amazon S3 Access Log"},{"location":"designs/log-analytics-pipeline-service/#amazon-cloudtrail-log","text":"","title":"Amazon CloudTrail Log"},{"location":"designs/user-stories/","text":"User Stories Deploy Configuration Center Install Instance Agent EC2 instances launched from EC2 Quick Start comes with SSM Agent installed. However, it is not associated with an appropriate instance profile which enable them to connect to the SSM control panel. Once the instance profile associated with EC2 instances, we can use the SSM Run Command to install Log Agent to report logs to Elasticsearch. Install Container Agent Import Search Engine s","title":"User Stories"},{"location":"designs/user-stories/#user-stories","text":"","title":"User Stories"},{"location":"designs/user-stories/#deploy-configuration-center","text":"","title":"Deploy Configuration Center"},{"location":"designs/user-stories/#install-instance-agent","text":"EC2 instances launched from EC2 Quick Start comes with SSM Agent installed. However, it is not associated with an appropriate instance profile which enable them to connect to the SSM control panel. Once the instance profile associated with EC2 instances, we can use the SSM Run Command to install Log Agent to report logs to Elasticsearch.","title":"Install Instance Agent"},{"location":"designs/user-stories/#install-container-agent","text":"","title":"Install Container Agent"},{"location":"designs/user-stories/#import-search-engine","text":"s","title":"Import Search Engine"},{"location":"designs/UI/help-panel/","text":"Help Panel Help panel is a place to offer more information to customers. The Sketch file will not provide help panel information. We consolidate all help panel information in this PRD. The following is an example of Help Panel and its description. Example Section Content Notes Title Help panel title Body This is a paragraph with some bold text and also some italic text. h4 section header Code can be formatted as lines of code or blocks of code. <this is a block of code> h4 section header Code can be formated as lines of code or blocks of code. <This is a block of code> Learn more First link to the documentation Second link to the documentation Domain detail Access Proxy Section Content Notes Title Access Proxy Body Access Proxy creates a Nginx based proxy (behind Application Load Balancer ) which allows you to access the OpenSearch Dashboards through Internet. Prerequisites 1. Domain name 2. The domain associated SSL certificate in Amazon Certificate Manager (ACM) 3. A EC2 public key Learn more Create a Access Proxy Alarms Section Content Notes Title Alarms Body Amazon OpenSearch provides a set of recommended CloudWatch alarms , Log Hub can help customers to create the alarms automatically, and sent notification to your email (or SMS) via SNS. Learn more Create OpenSearch Alarms Log Processing Section Content Notes Title Log Processing Body Log Hub will provision Lambda (or other compute resource) to process logs using these networking configurations. You can specify the log processing networking layer when import OpenSearch domains. Note The log processing layer has access to the OpenSearch domain. Learn more Import OpenSearch domain Import Domain Networking creation - Creation method Section Content Notes Title Creation method Body When import OpenSearch domains, you need to specify the networking configuration associated with the Log Processing Layer. Log Hub will automatically place Lambda (or other compute resource) in this layer. The Log Processing Layer must have access to the OpenSearch domain. Automatic Log Hub will detect if there is a need to create a VPC Peering Connection . If needed, Log Hub will automatically create a VPC Peering Connection, update route table, and update the security group of OpenSearch domain. Manual Manually specify the Log Processing Layer networking information. You may need to create VPC Peering Connection, update route table and security group of OpenSearch domain. Learn more Import OpenSearch domain Log processing network Section Content Notes Title Log processing network Body When import OpenSearch domains, you need to specify the networking configuration associated with the Log Processing Layer. Log Hub will automatically place Lambda (or other compute resource) in this layer. The Log Processing Layer must have access to the OpenSearch domain. S3 Service access By default, Log Hub will output error logs to Amazon S3. Please guarantee the log processing layer has network access to S3. You can do it by place the log processing layer in public subnets, use AWS PrivateLink for Amazon S3 or via NAT Gateways . CloudWatch Logs access Many AWS services output service logs to CloudWatch Logs . If you use Log Hub to ingest service logs. Please guarantee the log processing layer has network access to CloudWatch Logs. Kinesis Data Streams access Application logs are sent to Kinesis Data Streams in Log Hub. Please guarantee the log processing layer has networking access to Kinesis Data Streams. Learn more Service Log ingestion Creation method Section Content Notes Title Log enabling Body Log Hub can automatically detect the log location, or you can specify the log location manually. Automatic Log Hub will automatically detect the log location of the selected AWS service. If needed, it will enable the service log and save to a centralized log bucket. Manual Manually input the AWS service source and its log location . Log Hub will read logs from the location you specified. Learn more Sample dashboard Section Content Notes Title Sample dashboard Body Log Hub will insert a preconfigured dashboard into the OpenSearch domain if Yes being selected. The dashboard name will be consist with your index name. Learn more Log lifecycle Section Content Notes Title Log lifecycle Body Log Hub will insert an Index State Management (ISM) into the OpenSearch domain. The life cycle will periodically move your indices in OpenSearch to save cost. Learn more Index State Management Log Config Log Path Section Content Notes Title Log Path Body Specify the log file locations. If you have mutliple locations, please write all the locations and split using ','. e.g. /var/log/app1/*.log,/var/log/app2/*.log . Learn more Nginx Log Format Section Content Notes Title Nginx Log Format Body Nginx capture detailed information about errors and request in log files. You can find the log format configuration in Nginx configuration file, such as the /etc/nginx/nginx.conf file. The log format directive starts with log_format . Learn more Configuring Logging in Nginx Apache Log Format Section Content Notes Title Apache HTTP Server Log Format Body Apache HTTP Server capture detailed information about errors and request in log files. You can find the log format configuration in Apache HTTP Server configuration file, such as the /etc/httpd/conf/httpd.conf file. The log format directive starts with LogFormat . Learn more Apache HTTP Server Log Files Regular Expression Section Content Notes Title RegEx Log Format Body Log Hub uses custom Ruby Regular Expression to parse logs. It supports both single-line log format and mutliple input format. Write the regular expression in Rubular to validate first and input the value here. Learn more Regular Expression Rubular: A Rudy-based reular expression editor Regular Expression in Fluent Bit Application Pipeline Creation Method Section Content Notes Title Instance Group Creation Body Create a new instance group, or choose an existing Instance Group created before. Learn more Instance Group","title":"Help Panel"},{"location":"designs/UI/help-panel/#help-panel","text":"Help panel is a place to offer more information to customers. The Sketch file will not provide help panel information. We consolidate all help panel information in this PRD. The following is an example of Help Panel and its description.","title":"Help Panel"},{"location":"designs/UI/help-panel/#example","text":"Section Content Notes Title Help panel title Body This is a paragraph with some bold text and also some italic text. h4 section header Code can be formatted as lines of code or blocks of code. <this is a block of code> h4 section header Code can be formated as lines of code or blocks of code. <This is a block of code> Learn more First link to the documentation Second link to the documentation","title":"Example"},{"location":"designs/UI/help-panel/#domain-detail","text":"","title":"Domain detail"},{"location":"designs/UI/help-panel/#access-proxy","text":"Section Content Notes Title Access Proxy Body Access Proxy creates a Nginx based proxy (behind Application Load Balancer ) which allows you to access the OpenSearch Dashboards through Internet. Prerequisites 1. Domain name 2. The domain associated SSL certificate in Amazon Certificate Manager (ACM) 3. A EC2 public key Learn more Create a Access Proxy","title":"Access Proxy"},{"location":"designs/UI/help-panel/#alarms","text":"Section Content Notes Title Alarms Body Amazon OpenSearch provides a set of recommended CloudWatch alarms , Log Hub can help customers to create the alarms automatically, and sent notification to your email (or SMS) via SNS. Learn more Create OpenSearch Alarms","title":"Alarms"},{"location":"designs/UI/help-panel/#log-processing","text":"Section Content Notes Title Log Processing Body Log Hub will provision Lambda (or other compute resource) to process logs using these networking configurations. You can specify the log processing networking layer when import OpenSearch domains. Note The log processing layer has access to the OpenSearch domain. Learn more Import OpenSearch domain","title":"Log Processing"},{"location":"designs/UI/help-panel/#import-domain","text":"","title":"Import Domain"},{"location":"designs/UI/help-panel/#networking-creation-creation-method","text":"Section Content Notes Title Creation method Body When import OpenSearch domains, you need to specify the networking configuration associated with the Log Processing Layer. Log Hub will automatically place Lambda (or other compute resource) in this layer. The Log Processing Layer must have access to the OpenSearch domain. Automatic Log Hub will detect if there is a need to create a VPC Peering Connection . If needed, Log Hub will automatically create a VPC Peering Connection, update route table, and update the security group of OpenSearch domain. Manual Manually specify the Log Processing Layer networking information. You may need to create VPC Peering Connection, update route table and security group of OpenSearch domain. Learn more Import OpenSearch domain","title":"Networking creation - Creation method"},{"location":"designs/UI/help-panel/#log-processing-network","text":"Section Content Notes Title Log processing network Body When import OpenSearch domains, you need to specify the networking configuration associated with the Log Processing Layer. Log Hub will automatically place Lambda (or other compute resource) in this layer. The Log Processing Layer must have access to the OpenSearch domain. S3 Service access By default, Log Hub will output error logs to Amazon S3. Please guarantee the log processing layer has network access to S3. You can do it by place the log processing layer in public subnets, use AWS PrivateLink for Amazon S3 or via NAT Gateways . CloudWatch Logs access Many AWS services output service logs to CloudWatch Logs . If you use Log Hub to ingest service logs. Please guarantee the log processing layer has network access to CloudWatch Logs. Kinesis Data Streams access Application logs are sent to Kinesis Data Streams in Log Hub. Please guarantee the log processing layer has networking access to Kinesis Data Streams. Learn more","title":"Log processing network"},{"location":"designs/UI/help-panel/#service-log-ingestion","text":"","title":"Service Log ingestion"},{"location":"designs/UI/help-panel/#creation-method","text":"Section Content Notes Title Log enabling Body Log Hub can automatically detect the log location, or you can specify the log location manually. Automatic Log Hub will automatically detect the log location of the selected AWS service. If needed, it will enable the service log and save to a centralized log bucket. Manual Manually input the AWS service source and its log location . Log Hub will read logs from the location you specified. Learn more","title":"Creation method"},{"location":"designs/UI/help-panel/#sample-dashboard","text":"Section Content Notes Title Sample dashboard Body Log Hub will insert a preconfigured dashboard into the OpenSearch domain if Yes being selected. The dashboard name will be consist with your index name. Learn more","title":"Sample dashboard"},{"location":"designs/UI/help-panel/#log-lifecycle","text":"Section Content Notes Title Log lifecycle Body Log Hub will insert an Index State Management (ISM) into the OpenSearch domain. The life cycle will periodically move your indices in OpenSearch to save cost. Learn more Index State Management","title":"Log lifecycle"},{"location":"designs/UI/help-panel/#log-config","text":"","title":"Log Config"},{"location":"designs/UI/help-panel/#log-path","text":"Section Content Notes Title Log Path Body Specify the log file locations. If you have mutliple locations, please write all the locations and split using ','. e.g. /var/log/app1/*.log,/var/log/app2/*.log . Learn more","title":"Log Path"},{"location":"designs/UI/help-panel/#nginx-log-format","text":"Section Content Notes Title Nginx Log Format Body Nginx capture detailed information about errors and request in log files. You can find the log format configuration in Nginx configuration file, such as the /etc/nginx/nginx.conf file. The log format directive starts with log_format . Learn more Configuring Logging in Nginx","title":"Nginx Log Format"},{"location":"designs/UI/help-panel/#apache-log-format","text":"Section Content Notes Title Apache HTTP Server Log Format Body Apache HTTP Server capture detailed information about errors and request in log files. You can find the log format configuration in Apache HTTP Server configuration file, such as the /etc/httpd/conf/httpd.conf file. The log format directive starts with LogFormat . Learn more Apache HTTP Server Log Files","title":"Apache Log Format"},{"location":"designs/UI/help-panel/#regular-expression","text":"Section Content Notes Title RegEx Log Format Body Log Hub uses custom Ruby Regular Expression to parse logs. It supports both single-line log format and mutliple input format. Write the regular expression in Rubular to validate first and input the value here. Learn more Regular Expression Rubular: A Rudy-based reular expression editor Regular Expression in Fluent Bit","title":"Regular Expression"},{"location":"designs/UI/help-panel/#application-pipeline","text":"","title":"Application Pipeline"},{"location":"designs/UI/help-panel/#creation-method_1","text":"Section Content Notes Title Instance Group Creation Body Create a new instance group, or choose an existing Instance Group created before. Learn more Instance Group","title":"Creation Method"},{"location":"designs/app-log/api-design/","text":"Overview APIs Log Config APIs The following operations are available in the solution's Log Config APIs. List Log Configs Type: Query Description: List all Log Configs Resolver: Lambda Parameters: Name Type Required Default Description count Int No 10 page number, start from 1 page Int No 1 number of records per page Simple Request & Response: Request: query example{ listLogConfs(count: 10, page: 1) { logConfs { confName createdDt id logPath logType } } } Response: { \"data\": { \"listLogConfs\": { \"logConfs\": [{ \"confName\": \"sys-log\", \"createdDt\": \"2021-11-07T14:30:16.024007\", \"id\": \"41848bb3-f48a-4cdd-b0af-861d4be768ca\", \"logPath\": \"/log/*/ab/*.log\", \"logType\": \"JSON\" }] } } } Create Log Config Type: Mutation Description: Create a record in DynamoDB Resolver: Lambda Parameters: Name Type Required Default Description confName String Yes The name of the log configuration. The name must be unique, and can only contains lower case letters and -. logPath String Yes The location of the log files. All files under the specified folder will be included. Use ' , ' to separate multiple paths. logType enum Yes JSON, Apache, Nginx, SingleLineText, MultiLineText. multilineLogParser enum No JAVA_SPRING_BOOT. userLogFormat String No The log format configuration. For instance, the log format configuration of Apache. e.g. LogFormat \"%h %l %u %t \\\"%r\\\" %>s %b\" common. regularExpression String No When the log type you select is SingleLineText, MultiLineText, you need to define a regular expression to parse the log. regularSpecs K-V No To be used to parse the log field type, we will create an index template for the search engine based on this. Simple Request & Response: query example{ createLogConf( confName: \"nginx-log\", logPath: \"/var/log/nginx/*.log\", logType: \"Nginx\" ) } Request without region query example { listDomainNames { domainNames } } Response: { \"data\": { \"createLogConf\": \"41848bb3-f48a-4cdd-b0af-861d4be768ca\" } } Update Log Config Type: Mutation Description: Update the configuration of your choice. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Log Config Unique ID (key in DynamoDB) confName String Yes The name of the log configuration. The name must be unique, and can only contains lower case letters and -. logPath String Yes The location of the log files. All files under the specified folder will be included. Use ' , ' to separate multiple paths. logType enum Yes JSON, Apache, Nginx, SingleLineText, MultiLineText. multilineLogParser enum No JAVA_SPRING_BOOT. userLogFormat String No The log format configuration. For instance, the log format configuration of Apache. e.g. LogFormat \"%h %l %u %t \\\"%r\\\" %>s %b\" common. regularExpression String No When the log type you select is SingleLineText, MultiLineText, you need to define a regular expression to parse the log. regularSpecs K-V No To be used to parse the log field type, we will create an index template for the search engine based on this. Simple Request & Response: Request: mutation example{ updateLogConf( id: \"41848bb3-f48a-4cdd-b0af-861d4be768ca\", logPath: \"/app/gaming/app.log\", logType: JSON, confName: \"applog\" ) } Response: { \"data\": { \"importDomain\": \"OK\" } } Exceptions: confName already exists { \"data\": { \"updateLogConf\": null }, \"errors\": [{ \"path\": [ \"updateLogConf\" ], \"data\": null, \"errorType\": \"Lambda:Unhandled\", \"errorInfo\": null, \"locations\": [{ \"line\": 3, \"column\": 3, \"sourceName\": null }], \"message\": \"confName already exists\" }] } Delete Log Config Type: Mutation Description: We don't physically delete the record, we just set the state of the item to INACTIVE in DynamoDB Table. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Log Config Unique ID (key in DynamoDB) Simple Request & Response: Request: mutation example { deleteLogConf(id: \"41848bb3-f48a-4cdd-b0af-861d4be768ca\") } Response: { \"data\": { \"deleteLogConf\": \"OK\" } } Exceptions: Unknown exception, please check Lambda log for more details { \"data\": { \"deleteLogConf\": null }, \"errors\": [ { \"path\": [ \"deleteLogConf\" ], \"data\": null, \"errorType\": \"Lambda:Unhandled\", \"errorInfo\": null, \"locations\": [ { \"line\": 32, \"column\": 3, \"sourceName\": null } ], \"message\": \"Unknown exception, please check Lambda log for more details\" } ] } Get Log Config Details Type: Query Description: Get details of a Log Config. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Log Config Unique ID (key in DynamoDB) Simple Request & Response: Request: query example { getLogConf(id: \"41848bb3-f48a-4cdd-b0af-861d4be768ca\") { confName logPath logType multilineLogParser createdDt userLogFormat regularExpression regularSpecs } } Response: { \"data\": { \"getLogConf\": { \"confName\": \"fff\", \"createdDt\": \"2021-11-07T14:30:16.024007\", \"id\": \"41848bb3-f48a-4cdd-b0af-861d4be768ca\", \"logPath\": \"/log/*/ab/*.log\", \"logType\": \"JSON\" } } } Log Group API Design Overview This document is about the API Design for Log Group component. To learn more information about the component, refer to Component Design Log Group APIs The following operations are available in the solution's Log Group APIs. List Log Groups Type: Query Description: List all Log Groups Resolver: Lambda Parameters: Name Type Required Default Description count Int No 10 page number, start from 1 page Int No 1 number of records per page Simple Request & Response: Request: query example{ listInstanceGroups(count: 10, page: 1) { total instanceGroups { createdDt groupName id instanceSet } } } Response: { \"data\": { \"listInstanceGroups\": { \"total\": 1, \"instanceGroups\": [{ \"createdDt\": \"2021-11-06T12:28:52.041408\", \"groupName\": \"fsf1\", \"id\": \"1089057b-888b-4794-b797-fef943adccf0\", \"instanceSet\": [ \"1\", \"2\" ] }] } } } Create Log Group Type: Mutation Description: Create a record in DynamoDB Resolver: Lambda Parameters: Name Type Required Default Description groupName String Yes The name of the log group. The name must be unique, and can only contains lower case letters and -. instanceSet String[] Yes EC2 Instance Id set Simple Request & Response: Request: query example{ createInstanceGroup(groupName: \"nginx-webgrp\", instanceSet: [\"web1\", \"web2\"]) } Response: { \"data\": { \"createInstanceGroup\": \"2de27afe-d568-49cc-b7b5-86b161ce0662\" } } Update Log Group Type: Mutation Description: Update the group of your choice. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Log Group Unique ID (key in DynamoDB) groupName String Yes The name of the log group. The name must be unique, and can only contains lower case letters and -. instanceSet String[] Yes EC2 Instance Id set Simple Request & Response: Request: mutation example{ updateInstanceGroup( id: \"1089057b-888b-4794-b797-fef943adccf0\", groupName: \"fsf1\", instanceSet: [\"1\", \"2\"] ) } Response: { \"data\": { \"importDomain\": \"OK\" } } Exceptions: groupName already exists { \"data\": { \"updateInstanceGroup\": null }, \"errors\": [{ \"path\": [ \"updateInstanceGroup\" ], \"data\": null, \"errorType\": \"Lambda:Unhandled\", \"errorInfo\": null, \"locations\": [{ \"line\": 3, \"column\": 3, \"sourceName\": null }], \"message\": \"Group Name already exists\" }] } Delete Log Group Type: Mutation Description: We don't physically delete the record, we just set the state of the item to INACTIVE in DynamoDB Table. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Log Group Unique ID (key in DynamoDB) Simple Request & Response: Request: mutation example { deleteInstanceGroup(id: \"41848bb3-f48a-4cdd-b0af-861d4be768ca\") } Response: { \"data\": { \"deleteInstanceGroup\": \"OK\" } } Exceptions: Unknown exception, please check Lambda log for more details { \"data\": { \"deleteInstanceGroup\": null }, \"errors\": [ { \"path\": [ \"deleteInstanceGroup\" ], \"data\": null, \"errorType\": \"Lambda:Unhandled\", \"errorInfo\": null, \"locations\": [ { \"line\": 32, \"column\": 3, \"sourceName\": null } ], \"message\": \"Unknown exception, please check Lambda log for more details\" } ] } Get Log Group Details Type: Query Description: Get details of a Log Group. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Log Group Unique ID (key in DynamoDB) Simple Request & Response: Request: query example { getInstanceGroup(id: \"41848bb3-f48a-4cdd-b0af-861d4be768ca\") { createdDt groupName id instanceSet } } Response: { \"data\": { \"getInstanceGroup\": { \"createdDt\": \"2021-11-06T12:28:52.041408\", \"groupName\": \"fsf1\", \"id\": \"1089057b-888b-4794-b797-fef943adccf0\", \"instanceSet\": [ \"1\", \"2\" ] } } List Instances Type: Query Description: If you specify one or more managed node IDs, it returns information for those managed nodes. Resolver: Lambda Parameters: Name Type Required Default Description nextToken String No The token for the next set of items to return. (You received this token from a previous call.) maxResults Int No 10 The maximum number of items to return for this call. The call also returns a token that you can specify in a subsequent call to get the next set of results. instanceSet String[] No 1 The ID of the managed instance should be retrieved Simple Request & Response: Request: query example{ listInstances(maxResults: 10, instanceSet: [\"i-0bbf9209068ced7ed\"]) { instances { computerName id ipAddress platformName } } } Response: { \"data\": { \"listInstances\": { \"instances\": [{ \"computerName\": \"ip-172-31-44-205.us-west-2.compute.internal\", \"id\": \"i-0bbf9209068ced7ed\", \"ipAddress\": \"172.31.44.205\", \"platformName\": \"CentOS Linux\" }] } } } Get Log Agent Status Type: Query Description: Get Fluent Bit installation status. Resolver: Lambda Parameters: Name Type Required Default Description instanceId String No 1 The ID of the managed instance should be retrieved Simple Request & Response: Request: query example{ getLogAgentStatus(instanceId: \"i-022c5110c4e3226bb\") } } Response: { \"data\": { \"getLogAgentStatus\": \"Online/Offline\" } } Request Install Fluent Bit Type: Mutation Description: To install Fluent Bit by SSM Document. Resolver: Lambda Parameters: Name Type Required Default Description instanceIdSet String[]eiifcc No 1 Request to install the instance id of Fluent Bit Simple Request & Response: Request: mutation example{ requestInstallLogAgent(instanceIdSet: [\"i-022c5110c4e3226b\"]) } } Response: { \"data\": { \"requestInstallLogAgent\": \"commandID\" } } Application Log Pipelines API Design Overview This document is about the API Design for Application log Pipeline component. To learn more information about the component, refer to Component Design Application Log Pipelines APIs The following operations are available in the solution's Application Log Pipelines APIs. List App Pipelines Type: Query Description: List all Pipelines Resolver: Lambda Parameters: Name Type Required Default Description count Int No 10 page number, start from 1 page Int No 1 number of records per page Simple Request & Response: Request: query example{ listAppPipelines(count: 10, page: 1) { appPipelines { createdDt id status kdsParas { enableAutoScaling kdsArn maxShardNumber regionName startShardNumber streamName } aosParas { coldLogTransition domainName engine indexPrefix logRetention warmLogTransition opensearchArn } } total } } Response: { \"data\": { \"listAppPipelines\": { \"appPipelines\": [{ \"createdDt\": \"2021-11-12T03:20:57.049336\", \"id\": \"de7137e2-f2f1-429f-b692-d8882b670200\", \"status\": \"DELETING\", \"kdsParas\": [{ \"enableAutoScaling\": false, \"kdsArn\": \"kar\", \"maxShardNumber\": 10, \"regionName\": \"us-\", \"startShardNumber\": 10, \"streamName\": \"s\" }], \"aosParas\": [{ \"coldLogTransition\": 10, \"domainName\": null, \"engine\": \"OpenSearch\", \"indexPrefix\": \"i1\", \"logRetention\": 32, \"warmLogTransition\": 30, \"opensearchArn\": \"t\" }] }, { \"createdDt\": \"2021-11-08T10:44:11.523895\", \"id\": \"45851795-6401-41f7-8ded-6c6db14f375c\", \"status\": \"CREATING\", \"kdsParas\": [{ \"enableAutoScaling\": true, \"kdsArn\": \"karn\", \"maxShardNumber\": 20, \"regionName\": \"us-west-1\", \"startShardNumber\": 10, \"streamName\": \"aa\" }], \"aosParas\": [{ \"coldLogTransition\": 10, \"domainName\": null, \"engine\": null, \"indexPrefix\": \"fy\", \"logRetention\": 10, \"warmLogTransition\": 10, \"opensearchArn\": \"\" }] } ], \"total\": 2 } } } Create Pipelines Type: Mutation Description: Create a record in DynamoDB Resolver: Lambda Parameters: Name Type Required Default Description aosParas K-V Yes Selected Amazonn OpenSearch related parameters. kdsParas K-V Yes Created Kinesis Data Stream related parameters. Simple Request & Response: Request: mutation example{ createAppPipeline(aosParas: { engine: \"OpenSearch_1.0\", indexPrefix: \"nginx-log\", opensearchArn: \"arn:aws:es:us-east-1:xxxxx:domain/testing-vpc-opensearch\", coldLogTransition: 10, warmLogTransition: 5 logRetention: 10 }, kdsParas: { enableAutoScaling: true, kdsArn: \"arn:aws:kinesis:us-east-1:xxxxx:stream/LogHub-Pipe-b8c96-CWtoOpenSearchStackcwDataStream22A58C70-LOrG0yqq40py\", regionName: \"us-east-1\", startShardNumber: 10, maxShardNumber: 20, streamName: \"LogHub-Pipe-b8c96-CWtoOpenSearchStackcwDataStream22A58C70-LOrG0yqq40py\" }) } Response: { \"data\": { \"createAppPipeline\": \"2de27afe-d568-49cc-b7b5-86b161ce0662\" } } Delete Pipeline Type: Mutation Description: We don't physically delete the record, we just set the state of the item to INACTIVE in DynamoDB Table. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Log Group Unique ID (key in DynamoDB) Simple Request & Response: Request: mutation example { deleteAppPipeline(id: \"41848bb3-f48a-4cdd-b0af-861d4be768ca\") } Response: { \"data\": { \"deleteAppPipeline\": \"OK\" } } Exceptions: Unknown exception, please check Lambda log for more details { \"data\": { \"deleteAppPipeline\": null }, \"errors\": [ { \"path\": [ \"deleteAppPipeline\" ], \"data\": null, \"errorType\": \"Lambda:Unhandled\", \"errorInfo\": null, \"locations\": [ { \"line\": 32, \"column\": 3, \"sourceName\": null } ], \"message\": \"Unknown exception, please check Lambda log for more details\" } ] } Get Pipeline Details Type: Query Description: Get details of a Pipeline. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes App Pipeline Unique ID (key in DynamoDB) Simple Request & Response: Request: query example { getAppPipeline(id: \"45851795-6401-41f7-8ded-6c6db14f375c\") { createdDt id aosParas { coldLogTransition indexPrefix logRetention warmLogTransition opensearchArn } kdsParas { enableAutoScaling engine kdsArn maxShardNumber regionName startShardNumber streamName } tags[{ key value }] } } Response: { \"data\": { \"getAppPipeline\": { \"createdDt\": \"2021-11-08T10:44:11.523895\", \"id\": \"45851795-6401-41f7-8ded-6c6db14f375c\", \"aosParas\": [{ \"engine\": \"OpenSearch_1.0\", \"indexPrefix\": \"nginx-log\", \"opensearchArn\": \"arn:aws:es:us-east-1:xxxxx:domain/testing-vpc-opensearch\", \"coldLogTransition\": 10, \"warmLogTransition\": 5 \"logRetention\": 10 }], \"kdsParas\": [{ \"enableAutoScaling\": true, \"kdsArn\": \"arn:aws:kinesis:us-east-1:xxxxx:stream/\"LogHub-Pipe-b8c96-CWtoOpenSearchStackcwDataStream22A58C70-LOrG0yqq40py\", \"regionName\": \"us-east-1\", \"startShardNumber\": 10, \"maxShardNumber\": 20, \"streamName\": \"LogHub-Pipe-b8c96-CWtoOpenSearchStackcwDataStream22A58C70-LOrG0yqq40py\" }], \"tags\": [] } } } Application Log Ingestion API Design Overview This document is about the API Design for Application log Ingestion component. To learn more information about the component, refer to Component Design Application Log Ingestion APIs The following operations are available in the solution's Application Log Pipelines APIs. List Log Ingestion Type: Query Description: List all Ingestion Resolver: Lambda Parameters: Name Type Required Default Description appPipelineId String Yes 10 Application Pipeline Unique Id count Int No 10 page number, start from 1 page Int No 1 number of records per page Simple Request & Response: Request: query example{ listAppLogIngestions(appPipelineId: \"45851795-6401-41f7-8ded-6c6db14f375c\", count: 10, page: 1) { appLogIngestions { appPipelineId confId confName createdDt groupId groupName stackName stackId id tags [{ key value }] } total } } Response: { \"data\": { \"listAppLogIngestions\": { \"appLogIngestions\": [{ \"appPipelineId\": \"45851795-6401-41f7-8ded-6c6db14f375c\", \"confId\": \"01523e70-b571-4583-8882-56c877ec098c\", \"confName\": \"c2\", \"createdDt\": \"2021-11-16T11:26:35.509759\", \"groupId\": \"afa6c23f-765c-4322-bb00-234525a5ff85\", \"groupName\": \"g4\", \"stackName\": \"\", \"stackId\": \"\", \"id\": \"dd0eb789-6a33-4b51-873d-f5473ccdf144\", \"tags\": [] }, { \"appPipelineId\": \"45851795-6401-41f7-8ded-6c6db14f375c\", \"confId\": \"01523e70-b571-4583-8882-56c877ec098c\", \"confName\": \"c2\", \"createdDt\": \"2021-11-16T11:26:35.509716\", \"groupId\": \"8ef2debb-1c72-4821-9e61-ce89b6c6ed00\", \"groupName\": \"g3\", \"stackName\": \"\", \"stackId\": \"\", \"id\": \"af65c64b-7403-4e92-90f6-1ec13d655deb\", \"tags\": [] } ], \"total\": 2 } } } Create Ingestion Type: Mutation Description: Create a record in DynamoDB Resolver: Lambda Parameters: Name Type Required Default Description appPipelineId K-V Yes Selected Amazonn OpenSearch related parameters. confId K-V Yes Created Kinesis Data Stream related parameters. groupIds String[] Yes Created Kinesis Data Stream related parameters. stackId String Yes In the process of creating an application log pipeline, KDS and Lambda are created through the CloudFormation stack. This item can be obtained through the listAppLogIngestions API. stackName String Yes In the process of creating an application log pipeline, KDS and Lambda are created through the CloudFormation stack. This item can be obtained through the listAppLogIngestions API. Simple Request & Response: Request: mutation example{ createAppLogIngestion( appPipelineId: \"45851795-6401-41f7-8ded-6c6db14f375c\", confId: \"01523e70-b571-4583-8882-56c877ec098c\", groupIds: [\"afa6c23f-765c-4322-bb00-234525a5ff85\"], stackId: \"\", stackName: \"\") } Response: { \"data\": { \"createAppLogIngestion\": \"2de27afe-d568-49cc-b7b5-86b161ce0662\" } } Exceptions: Unknown exception, please check Lambda log for more details { \"data\": { \"createAppLogIngestion\": null }, \"errors\": [{ \"path\": [ \"createAppLogIngestion\" ], \"data\": null, \"errorType\": \"Lambda:Unhandled\", \"errorInfo\": null, \"locations\": [{ \"line\": 23, \"column\": 3, \"sourceName\": null }], \"message\": \"please check groupId afa6c23f-765c-4322-bb00-234525a5ff85 and conId 01523e70-b571-4583-8882-56c877ec098c, they already exist in applineId 45851795-6401-41f7-8ded-6c6db14f375c\" }] } Delete Application Log Ingestion Type: Mutation Description: We don't physically delete the record, we just set the state of the item to INACTIVE in DynamoDB Table. Resolver: Lambda Parameters: Name Type Required Default Description ids String[] Yes Log Ingestion ID Set (key in DynamoDB) Simple Request & Response: Request: mutation example { deleteAppLogIngestion( ids: [\"60779959-95e3-45b6-a433-225f5c57edcc\", \"86b02ebc-d952-4b37-ac17-f001150d3a16\"] ) } Response: { \"data\": { \"deleteAppLogIngestion\": \"OK\" } } Get Log Ingestion Details Type: Query Description: Get details of a Ingestion. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes App Log Ingestion Unique ID (key in DynamoDB) Simple Request & Response: Request: query example { getAppLogIngestion(id: \"5051c5ce-f0fb-4b6e-be39-05490756b335\") { appPipelineId confId createdDt groupId id stackId stackName tags[{ key value }] } } Response: { \"data\": { \"getAppLogIngestion\": { \"appPipelineId\": \"f45648b9-cfa8-4bfb-bf6b-f7a06a8fecf1\", \"confId\": \"c1\", \"createdDt\": \"2021-11-07T17:48:03.935902\", \"groupId\": \"g1\", \"id\": \"5051c5ce-f0fb-4b6e-be39-05490756b335\", \"stackId\": \"s\", \"stackName\": \"ss\", \"tags\": [] } } }","title":"API Design"},{"location":"designs/app-log/api-design/#overview","text":"","title":"Overview"},{"location":"designs/app-log/api-design/#apis","text":"","title":"APIs"},{"location":"designs/app-log/api-design/#log-config-apis","text":"The following operations are available in the solution's Log Config APIs.","title":"Log Config APIs"},{"location":"designs/app-log/api-design/#list-log-configs","text":"Type: Query Description: List all Log Configs Resolver: Lambda Parameters: Name Type Required Default Description count Int No 10 page number, start from 1 page Int No 1 number of records per page Simple Request & Response: Request: query example{ listLogConfs(count: 10, page: 1) { logConfs { confName createdDt id logPath logType } } } Response: { \"data\": { \"listLogConfs\": { \"logConfs\": [{ \"confName\": \"sys-log\", \"createdDt\": \"2021-11-07T14:30:16.024007\", \"id\": \"41848bb3-f48a-4cdd-b0af-861d4be768ca\", \"logPath\": \"/log/*/ab/*.log\", \"logType\": \"JSON\" }] } } }","title":"List Log Configs"},{"location":"designs/app-log/api-design/#create-log-config","text":"Type: Mutation Description: Create a record in DynamoDB Resolver: Lambda Parameters: Name Type Required Default Description confName String Yes The name of the log configuration. The name must be unique, and can only contains lower case letters and -. logPath String Yes The location of the log files. All files under the specified folder will be included. Use ' , ' to separate multiple paths. logType enum Yes JSON, Apache, Nginx, SingleLineText, MultiLineText. multilineLogParser enum No JAVA_SPRING_BOOT. userLogFormat String No The log format configuration. For instance, the log format configuration of Apache. e.g. LogFormat \"%h %l %u %t \\\"%r\\\" %>s %b\" common. regularExpression String No When the log type you select is SingleLineText, MultiLineText, you need to define a regular expression to parse the log. regularSpecs K-V No To be used to parse the log field type, we will create an index template for the search engine based on this. Simple Request & Response: query example{ createLogConf( confName: \"nginx-log\", logPath: \"/var/log/nginx/*.log\", logType: \"Nginx\" ) } Request without region query example { listDomainNames { domainNames } } Response: { \"data\": { \"createLogConf\": \"41848bb3-f48a-4cdd-b0af-861d4be768ca\" } }","title":"Create Log Config"},{"location":"designs/app-log/api-design/#update-log-config","text":"Type: Mutation Description: Update the configuration of your choice. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Log Config Unique ID (key in DynamoDB) confName String Yes The name of the log configuration. The name must be unique, and can only contains lower case letters and -. logPath String Yes The location of the log files. All files under the specified folder will be included. Use ' , ' to separate multiple paths. logType enum Yes JSON, Apache, Nginx, SingleLineText, MultiLineText. multilineLogParser enum No JAVA_SPRING_BOOT. userLogFormat String No The log format configuration. For instance, the log format configuration of Apache. e.g. LogFormat \"%h %l %u %t \\\"%r\\\" %>s %b\" common. regularExpression String No When the log type you select is SingleLineText, MultiLineText, you need to define a regular expression to parse the log. regularSpecs K-V No To be used to parse the log field type, we will create an index template for the search engine based on this. Simple Request & Response: Request: mutation example{ updateLogConf( id: \"41848bb3-f48a-4cdd-b0af-861d4be768ca\", logPath: \"/app/gaming/app.log\", logType: JSON, confName: \"applog\" ) } Response: { \"data\": { \"importDomain\": \"OK\" } } Exceptions: confName already exists { \"data\": { \"updateLogConf\": null }, \"errors\": [{ \"path\": [ \"updateLogConf\" ], \"data\": null, \"errorType\": \"Lambda:Unhandled\", \"errorInfo\": null, \"locations\": [{ \"line\": 3, \"column\": 3, \"sourceName\": null }], \"message\": \"confName already exists\" }] }","title":"Update Log Config"},{"location":"designs/app-log/api-design/#delete-log-config","text":"Type: Mutation Description: We don't physically delete the record, we just set the state of the item to INACTIVE in DynamoDB Table. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Log Config Unique ID (key in DynamoDB) Simple Request & Response: Request: mutation example { deleteLogConf(id: \"41848bb3-f48a-4cdd-b0af-861d4be768ca\") } Response: { \"data\": { \"deleteLogConf\": \"OK\" } } Exceptions: Unknown exception, please check Lambda log for more details { \"data\": { \"deleteLogConf\": null }, \"errors\": [ { \"path\": [ \"deleteLogConf\" ], \"data\": null, \"errorType\": \"Lambda:Unhandled\", \"errorInfo\": null, \"locations\": [ { \"line\": 32, \"column\": 3, \"sourceName\": null } ], \"message\": \"Unknown exception, please check Lambda log for more details\" } ] }","title":"Delete Log Config"},{"location":"designs/app-log/api-design/#get-log-config-details","text":"Type: Query Description: Get details of a Log Config. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Log Config Unique ID (key in DynamoDB) Simple Request & Response: Request: query example { getLogConf(id: \"41848bb3-f48a-4cdd-b0af-861d4be768ca\") { confName logPath logType multilineLogParser createdDt userLogFormat regularExpression regularSpecs } } Response: { \"data\": { \"getLogConf\": { \"confName\": \"fff\", \"createdDt\": \"2021-11-07T14:30:16.024007\", \"id\": \"41848bb3-f48a-4cdd-b0af-861d4be768ca\", \"logPath\": \"/log/*/ab/*.log\", \"logType\": \"JSON\" } } }","title":"Get Log Config Details"},{"location":"designs/app-log/api-design/#log-group-api-design","text":"","title":"Log Group API Design"},{"location":"designs/app-log/api-design/#overview_1","text":"This document is about the API Design for Log Group component. To learn more information about the component, refer to Component Design","title":"Overview"},{"location":"designs/app-log/api-design/#log-group-apis","text":"The following operations are available in the solution's Log Group APIs.","title":"Log Group APIs"},{"location":"designs/app-log/api-design/#list-log-groups","text":"Type: Query Description: List all Log Groups Resolver: Lambda Parameters: Name Type Required Default Description count Int No 10 page number, start from 1 page Int No 1 number of records per page Simple Request & Response: Request: query example{ listInstanceGroups(count: 10, page: 1) { total instanceGroups { createdDt groupName id instanceSet } } } Response: { \"data\": { \"listInstanceGroups\": { \"total\": 1, \"instanceGroups\": [{ \"createdDt\": \"2021-11-06T12:28:52.041408\", \"groupName\": \"fsf1\", \"id\": \"1089057b-888b-4794-b797-fef943adccf0\", \"instanceSet\": [ \"1\", \"2\" ] }] } } }","title":"List Log Groups"},{"location":"designs/app-log/api-design/#create-log-group","text":"Type: Mutation Description: Create a record in DynamoDB Resolver: Lambda Parameters: Name Type Required Default Description groupName String Yes The name of the log group. The name must be unique, and can only contains lower case letters and -. instanceSet String[] Yes EC2 Instance Id set Simple Request & Response: Request: query example{ createInstanceGroup(groupName: \"nginx-webgrp\", instanceSet: [\"web1\", \"web2\"]) } Response: { \"data\": { \"createInstanceGroup\": \"2de27afe-d568-49cc-b7b5-86b161ce0662\" } }","title":"Create Log Group"},{"location":"designs/app-log/api-design/#update-log-group","text":"Type: Mutation Description: Update the group of your choice. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Log Group Unique ID (key in DynamoDB) groupName String Yes The name of the log group. The name must be unique, and can only contains lower case letters and -. instanceSet String[] Yes EC2 Instance Id set Simple Request & Response: Request: mutation example{ updateInstanceGroup( id: \"1089057b-888b-4794-b797-fef943adccf0\", groupName: \"fsf1\", instanceSet: [\"1\", \"2\"] ) } Response: { \"data\": { \"importDomain\": \"OK\" } } Exceptions: groupName already exists { \"data\": { \"updateInstanceGroup\": null }, \"errors\": [{ \"path\": [ \"updateInstanceGroup\" ], \"data\": null, \"errorType\": \"Lambda:Unhandled\", \"errorInfo\": null, \"locations\": [{ \"line\": 3, \"column\": 3, \"sourceName\": null }], \"message\": \"Group Name already exists\" }] }","title":"Update Log Group"},{"location":"designs/app-log/api-design/#delete-log-group","text":"Type: Mutation Description: We don't physically delete the record, we just set the state of the item to INACTIVE in DynamoDB Table. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Log Group Unique ID (key in DynamoDB) Simple Request & Response: Request: mutation example { deleteInstanceGroup(id: \"41848bb3-f48a-4cdd-b0af-861d4be768ca\") } Response: { \"data\": { \"deleteInstanceGroup\": \"OK\" } } Exceptions: Unknown exception, please check Lambda log for more details { \"data\": { \"deleteInstanceGroup\": null }, \"errors\": [ { \"path\": [ \"deleteInstanceGroup\" ], \"data\": null, \"errorType\": \"Lambda:Unhandled\", \"errorInfo\": null, \"locations\": [ { \"line\": 32, \"column\": 3, \"sourceName\": null } ], \"message\": \"Unknown exception, please check Lambda log for more details\" } ] }","title":"Delete Log Group"},{"location":"designs/app-log/api-design/#get-log-group-details","text":"Type: Query Description: Get details of a Log Group. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Log Group Unique ID (key in DynamoDB) Simple Request & Response: Request: query example { getInstanceGroup(id: \"41848bb3-f48a-4cdd-b0af-861d4be768ca\") { createdDt groupName id instanceSet } } Response: { \"data\": { \"getInstanceGroup\": { \"createdDt\": \"2021-11-06T12:28:52.041408\", \"groupName\": \"fsf1\", \"id\": \"1089057b-888b-4794-b797-fef943adccf0\", \"instanceSet\": [ \"1\", \"2\" ] } }","title":"Get Log Group Details"},{"location":"designs/app-log/api-design/#list-instances","text":"Type: Query Description: If you specify one or more managed node IDs, it returns information for those managed nodes. Resolver: Lambda Parameters: Name Type Required Default Description nextToken String No The token for the next set of items to return. (You received this token from a previous call.) maxResults Int No 10 The maximum number of items to return for this call. The call also returns a token that you can specify in a subsequent call to get the next set of results. instanceSet String[] No 1 The ID of the managed instance should be retrieved Simple Request & Response: Request: query example{ listInstances(maxResults: 10, instanceSet: [\"i-0bbf9209068ced7ed\"]) { instances { computerName id ipAddress platformName } } } Response: { \"data\": { \"listInstances\": { \"instances\": [{ \"computerName\": \"ip-172-31-44-205.us-west-2.compute.internal\", \"id\": \"i-0bbf9209068ced7ed\", \"ipAddress\": \"172.31.44.205\", \"platformName\": \"CentOS Linux\" }] } } }","title":"List Instances"},{"location":"designs/app-log/api-design/#get-log-agent-status","text":"Type: Query Description: Get Fluent Bit installation status. Resolver: Lambda Parameters: Name Type Required Default Description instanceId String No 1 The ID of the managed instance should be retrieved Simple Request & Response: Request: query example{ getLogAgentStatus(instanceId: \"i-022c5110c4e3226bb\") } } Response: { \"data\": { \"getLogAgentStatus\": \"Online/Offline\" } }","title":"Get Log Agent Status"},{"location":"designs/app-log/api-design/#request-install-fluent-bit","text":"Type: Mutation Description: To install Fluent Bit by SSM Document. Resolver: Lambda Parameters: Name Type Required Default Description instanceIdSet String[]eiifcc No 1 Request to install the instance id of Fluent Bit Simple Request & Response: Request: mutation example{ requestInstallLogAgent(instanceIdSet: [\"i-022c5110c4e3226b\"]) } } Response: { \"data\": { \"requestInstallLogAgent\": \"commandID\" } }","title":"Request Install Fluent Bit"},{"location":"designs/app-log/api-design/#application-log-pipelines-api-design","text":"","title":"Application Log Pipelines API Design"},{"location":"designs/app-log/api-design/#overview_2","text":"This document is about the API Design for Application log Pipeline component. To learn more information about the component, refer to Component Design","title":"Overview"},{"location":"designs/app-log/api-design/#application-log-pipelines-apis","text":"The following operations are available in the solution's Application Log Pipelines APIs.","title":"Application Log Pipelines APIs"},{"location":"designs/app-log/api-design/#list-app-pipelines","text":"Type: Query Description: List all Pipelines Resolver: Lambda Parameters: Name Type Required Default Description count Int No 10 page number, start from 1 page Int No 1 number of records per page Simple Request & Response: Request: query example{ listAppPipelines(count: 10, page: 1) { appPipelines { createdDt id status kdsParas { enableAutoScaling kdsArn maxShardNumber regionName startShardNumber streamName } aosParas { coldLogTransition domainName engine indexPrefix logRetention warmLogTransition opensearchArn } } total } } Response: { \"data\": { \"listAppPipelines\": { \"appPipelines\": [{ \"createdDt\": \"2021-11-12T03:20:57.049336\", \"id\": \"de7137e2-f2f1-429f-b692-d8882b670200\", \"status\": \"DELETING\", \"kdsParas\": [{ \"enableAutoScaling\": false, \"kdsArn\": \"kar\", \"maxShardNumber\": 10, \"regionName\": \"us-\", \"startShardNumber\": 10, \"streamName\": \"s\" }], \"aosParas\": [{ \"coldLogTransition\": 10, \"domainName\": null, \"engine\": \"OpenSearch\", \"indexPrefix\": \"i1\", \"logRetention\": 32, \"warmLogTransition\": 30, \"opensearchArn\": \"t\" }] }, { \"createdDt\": \"2021-11-08T10:44:11.523895\", \"id\": \"45851795-6401-41f7-8ded-6c6db14f375c\", \"status\": \"CREATING\", \"kdsParas\": [{ \"enableAutoScaling\": true, \"kdsArn\": \"karn\", \"maxShardNumber\": 20, \"regionName\": \"us-west-1\", \"startShardNumber\": 10, \"streamName\": \"aa\" }], \"aosParas\": [{ \"coldLogTransition\": 10, \"domainName\": null, \"engine\": null, \"indexPrefix\": \"fy\", \"logRetention\": 10, \"warmLogTransition\": 10, \"opensearchArn\": \"\" }] } ], \"total\": 2 } } }","title":"List App Pipelines"},{"location":"designs/app-log/api-design/#create-pipelines","text":"Type: Mutation Description: Create a record in DynamoDB Resolver: Lambda Parameters: Name Type Required Default Description aosParas K-V Yes Selected Amazonn OpenSearch related parameters. kdsParas K-V Yes Created Kinesis Data Stream related parameters. Simple Request & Response: Request: mutation example{ createAppPipeline(aosParas: { engine: \"OpenSearch_1.0\", indexPrefix: \"nginx-log\", opensearchArn: \"arn:aws:es:us-east-1:xxxxx:domain/testing-vpc-opensearch\", coldLogTransition: 10, warmLogTransition: 5 logRetention: 10 }, kdsParas: { enableAutoScaling: true, kdsArn: \"arn:aws:kinesis:us-east-1:xxxxx:stream/LogHub-Pipe-b8c96-CWtoOpenSearchStackcwDataStream22A58C70-LOrG0yqq40py\", regionName: \"us-east-1\", startShardNumber: 10, maxShardNumber: 20, streamName: \"LogHub-Pipe-b8c96-CWtoOpenSearchStackcwDataStream22A58C70-LOrG0yqq40py\" }) } Response: { \"data\": { \"createAppPipeline\": \"2de27afe-d568-49cc-b7b5-86b161ce0662\" } }","title":"Create Pipelines"},{"location":"designs/app-log/api-design/#delete-pipeline","text":"Type: Mutation Description: We don't physically delete the record, we just set the state of the item to INACTIVE in DynamoDB Table. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Log Group Unique ID (key in DynamoDB) Simple Request & Response: Request: mutation example { deleteAppPipeline(id: \"41848bb3-f48a-4cdd-b0af-861d4be768ca\") } Response: { \"data\": { \"deleteAppPipeline\": \"OK\" } } Exceptions: Unknown exception, please check Lambda log for more details { \"data\": { \"deleteAppPipeline\": null }, \"errors\": [ { \"path\": [ \"deleteAppPipeline\" ], \"data\": null, \"errorType\": \"Lambda:Unhandled\", \"errorInfo\": null, \"locations\": [ { \"line\": 32, \"column\": 3, \"sourceName\": null } ], \"message\": \"Unknown exception, please check Lambda log for more details\" } ] }","title":"Delete Pipeline"},{"location":"designs/app-log/api-design/#get-pipeline-details","text":"Type: Query Description: Get details of a Pipeline. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes App Pipeline Unique ID (key in DynamoDB) Simple Request & Response: Request: query example { getAppPipeline(id: \"45851795-6401-41f7-8ded-6c6db14f375c\") { createdDt id aosParas { coldLogTransition indexPrefix logRetention warmLogTransition opensearchArn } kdsParas { enableAutoScaling engine kdsArn maxShardNumber regionName startShardNumber streamName } tags[{ key value }] } } Response: { \"data\": { \"getAppPipeline\": { \"createdDt\": \"2021-11-08T10:44:11.523895\", \"id\": \"45851795-6401-41f7-8ded-6c6db14f375c\", \"aosParas\": [{ \"engine\": \"OpenSearch_1.0\", \"indexPrefix\": \"nginx-log\", \"opensearchArn\": \"arn:aws:es:us-east-1:xxxxx:domain/testing-vpc-opensearch\", \"coldLogTransition\": 10, \"warmLogTransition\": 5 \"logRetention\": 10 }], \"kdsParas\": [{ \"enableAutoScaling\": true, \"kdsArn\": \"arn:aws:kinesis:us-east-1:xxxxx:stream/\"LogHub-Pipe-b8c96-CWtoOpenSearchStackcwDataStream22A58C70-LOrG0yqq40py\", \"regionName\": \"us-east-1\", \"startShardNumber\": 10, \"maxShardNumber\": 20, \"streamName\": \"LogHub-Pipe-b8c96-CWtoOpenSearchStackcwDataStream22A58C70-LOrG0yqq40py\" }], \"tags\": [] } } }","title":"Get Pipeline Details"},{"location":"designs/app-log/api-design/#application-log-ingestion-api-design","text":"","title":"Application Log Ingestion API Design"},{"location":"designs/app-log/api-design/#overview_3","text":"This document is about the API Design for Application log Ingestion component. To learn more information about the component, refer to Component Design","title":"Overview"},{"location":"designs/app-log/api-design/#application-log-ingestion-apis","text":"The following operations are available in the solution's Application Log Pipelines APIs.","title":"Application Log Ingestion APIs"},{"location":"designs/app-log/api-design/#list-log-ingestion","text":"Type: Query Description: List all Ingestion Resolver: Lambda Parameters: Name Type Required Default Description appPipelineId String Yes 10 Application Pipeline Unique Id count Int No 10 page number, start from 1 page Int No 1 number of records per page Simple Request & Response: Request: query example{ listAppLogIngestions(appPipelineId: \"45851795-6401-41f7-8ded-6c6db14f375c\", count: 10, page: 1) { appLogIngestions { appPipelineId confId confName createdDt groupId groupName stackName stackId id tags [{ key value }] } total } } Response: { \"data\": { \"listAppLogIngestions\": { \"appLogIngestions\": [{ \"appPipelineId\": \"45851795-6401-41f7-8ded-6c6db14f375c\", \"confId\": \"01523e70-b571-4583-8882-56c877ec098c\", \"confName\": \"c2\", \"createdDt\": \"2021-11-16T11:26:35.509759\", \"groupId\": \"afa6c23f-765c-4322-bb00-234525a5ff85\", \"groupName\": \"g4\", \"stackName\": \"\", \"stackId\": \"\", \"id\": \"dd0eb789-6a33-4b51-873d-f5473ccdf144\", \"tags\": [] }, { \"appPipelineId\": \"45851795-6401-41f7-8ded-6c6db14f375c\", \"confId\": \"01523e70-b571-4583-8882-56c877ec098c\", \"confName\": \"c2\", \"createdDt\": \"2021-11-16T11:26:35.509716\", \"groupId\": \"8ef2debb-1c72-4821-9e61-ce89b6c6ed00\", \"groupName\": \"g3\", \"stackName\": \"\", \"stackId\": \"\", \"id\": \"af65c64b-7403-4e92-90f6-1ec13d655deb\", \"tags\": [] } ], \"total\": 2 } } }","title":"List Log Ingestion"},{"location":"designs/app-log/api-design/#create-ingestion","text":"Type: Mutation Description: Create a record in DynamoDB Resolver: Lambda Parameters: Name Type Required Default Description appPipelineId K-V Yes Selected Amazonn OpenSearch related parameters. confId K-V Yes Created Kinesis Data Stream related parameters. groupIds String[] Yes Created Kinesis Data Stream related parameters. stackId String Yes In the process of creating an application log pipeline, KDS and Lambda are created through the CloudFormation stack. This item can be obtained through the listAppLogIngestions API. stackName String Yes In the process of creating an application log pipeline, KDS and Lambda are created through the CloudFormation stack. This item can be obtained through the listAppLogIngestions API. Simple Request & Response: Request: mutation example{ createAppLogIngestion( appPipelineId: \"45851795-6401-41f7-8ded-6c6db14f375c\", confId: \"01523e70-b571-4583-8882-56c877ec098c\", groupIds: [\"afa6c23f-765c-4322-bb00-234525a5ff85\"], stackId: \"\", stackName: \"\") } Response: { \"data\": { \"createAppLogIngestion\": \"2de27afe-d568-49cc-b7b5-86b161ce0662\" } } Exceptions: Unknown exception, please check Lambda log for more details { \"data\": { \"createAppLogIngestion\": null }, \"errors\": [{ \"path\": [ \"createAppLogIngestion\" ], \"data\": null, \"errorType\": \"Lambda:Unhandled\", \"errorInfo\": null, \"locations\": [{ \"line\": 23, \"column\": 3, \"sourceName\": null }], \"message\": \"please check groupId afa6c23f-765c-4322-bb00-234525a5ff85 and conId 01523e70-b571-4583-8882-56c877ec098c, they already exist in applineId 45851795-6401-41f7-8ded-6c6db14f375c\" }] }","title":"Create Ingestion"},{"location":"designs/app-log/api-design/#delete-application-log-ingestion","text":"Type: Mutation Description: We don't physically delete the record, we just set the state of the item to INACTIVE in DynamoDB Table. Resolver: Lambda Parameters: Name Type Required Default Description ids String[] Yes Log Ingestion ID Set (key in DynamoDB) Simple Request & Response: Request: mutation example { deleteAppLogIngestion( ids: [\"60779959-95e3-45b6-a433-225f5c57edcc\", \"86b02ebc-d952-4b37-ac17-f001150d3a16\"] ) } Response: { \"data\": { \"deleteAppLogIngestion\": \"OK\" } }","title":"Delete Application Log Ingestion"},{"location":"designs/app-log/api-design/#get-log-ingestion-details","text":"Type: Query Description: Get details of a Ingestion. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes App Log Ingestion Unique ID (key in DynamoDB) Simple Request & Response: Request: query example { getAppLogIngestion(id: \"5051c5ce-f0fb-4b6e-be39-05490756b335\") { appPipelineId confId createdDt groupId id stackId stackName tags[{ key value }] } } Response: { \"data\": { \"getAppLogIngestion\": { \"appPipelineId\": \"f45648b9-cfa8-4bfb-bf6b-f7a06a8fecf1\", \"confId\": \"c1\", \"createdDt\": \"2021-11-07T17:48:03.935902\", \"groupId\": \"g1\", \"id\": \"5051c5ce-f0fb-4b6e-be39-05490756b335\", \"stackId\": \"s\", \"stackName\": \"ss\", \"tags\": [] } } }","title":"Get Log Ingestion Details"},{"location":"designs/app-log/architecture-design/","text":"Application Log Analytics Design Overview Application Log Analytics, as one module of Log Hub solution, is used to collect logs for Application, process and ingest into Amazon OpenSearch Service (AOS). This document is to describe this module is designed. Currently, this solution supports JSON format, Nginx Format, Apache Format, Spring Boot Logs, Single-line text, Multi-line text. Info For more information about solution overall design, refer to Architecture Design . High Level Design Model Layer -The proxy of the back-end service encapsulates the model required by the view layer and defines the output content by the caller. Resources - Here we specifically refer to the Amazon Web Services created and invoked through APIs in the solution, such as EC2 instances that need to transmit log data, Systems Manager used by Fluent Bit installed, Amazon Kinesis Data Streams, Amazon Lambda, Amazon OpenSearch Service used for log storage and data analysis and presentation. Log Config Service - To used to describe log configuration information, including log location, log type, search engine field type, etc. Instance Group Service - An instance Group is a collection of instances. Currently, only instances in the same region as Log Hub are supported. This service is responsible for the logical classification of instances, the installation of Fluent Bit on the instance, and the status detection of Fluent Bit. For the installation of Fluent Bit, the system is processed through multi-threading. Application Log Pipeline Service - Responsible for asynchronous creation of data buffers, data buffer automatic scaling service, and log processor instance. Application Log Ingestion Service - Responsible for generating configuration files, distributing configuration through SSM, and scheduling Fluent Bit for data transmission, and creating OpenSearch templates according to the log field data types defined by Log config to ensure that the data written to OpenSearch conforms to the preset data types. Kinesis Data Streams Auto Scaling Service Amazon Kinesis Data Streams is automatically scaled by using Amazon CloudWatch and AWS Lambda if the user turns on autoscaling for the data buffer.","title":"Architecture Design"},{"location":"designs/app-log/architecture-design/#application-log-analytics-design","text":"","title":"Application Log Analytics Design"},{"location":"designs/app-log/architecture-design/#overview","text":"Application Log Analytics, as one module of Log Hub solution, is used to collect logs for Application, process and ingest into Amazon OpenSearch Service (AOS). This document is to describe this module is designed. Currently, this solution supports JSON format, Nginx Format, Apache Format, Spring Boot Logs, Single-line text, Multi-line text. Info For more information about solution overall design, refer to Architecture Design .","title":"Overview"},{"location":"designs/app-log/architecture-design/#high-level-design","text":"Model Layer -The proxy of the back-end service encapsulates the model required by the view layer and defines the output content by the caller. Resources - Here we specifically refer to the Amazon Web Services created and invoked through APIs in the solution, such as EC2 instances that need to transmit log data, Systems Manager used by Fluent Bit installed, Amazon Kinesis Data Streams, Amazon Lambda, Amazon OpenSearch Service used for log storage and data analysis and presentation. Log Config Service - To used to describe log configuration information, including log location, log type, search engine field type, etc. Instance Group Service - An instance Group is a collection of instances. Currently, only instances in the same region as Log Hub are supported. This service is responsible for the logical classification of instances, the installation of Fluent Bit on the instance, and the status detection of Fluent Bit. For the installation of Fluent Bit, the system is processed through multi-threading. Application Log Pipeline Service - Responsible for asynchronous creation of data buffers, data buffer automatic scaling service, and log processor instance. Application Log Ingestion Service - Responsible for generating configuration files, distributing configuration through SSM, and scheduling Fluent Bit for data transmission, and creating OpenSearch templates according to the log field data types defined by Log config to ensure that the data written to OpenSearch conforms to the preset data types. Kinesis Data Streams Auto Scaling Service Amazon Kinesis Data Streams is automatically scaled by using Amazon CloudWatch and AWS Lambda if the user turns on autoscaling for the data buffer.","title":"High Level Design"},{"location":"designs/app-log/data-model-design/","text":"Application Log Analytics Data Model Design Overview This part uses Amazon DynamoDB as the backend NoSQL database. This document is about the Data Model Design for Application Log Analytics module. Entity Relationship Diagram LogConf Table LogConf table stores information about the Application log configuration by this solution, such as log type, log path. The data attributes are listed as below: Attribute name Type Description Comments id String Unique ID of a configuration Partition key confName String The name of the configuration name createdDt String creation time logPath String Log file path logType String Json, Regex, Nginx, Apache, MultiLineText multilineLogParser String JAVA_SPRING_BOOT regularExpression String Regular expressions regularSpec String Field type definition after regular parsing status String ACTIVE, INACTIVE INACTIVE means delete state userLogFormat String Log format updatedDt String The last time the data was updated InstanceGroup Table InstanceGroup table stores information about the instance and grouping relationship information by this solution, such as log type. The data attributes are listed as below: Attribute name Type Description Comments id String Unique ID of a group Partition key groupName String The name of the log group. the name must be unique, and can only contains lower case letters and -. createdDt String Creation time instanceSet String List of instance ids status String ACTIVE, INACTIVE INACTIVE means delete state updatedDt String The last time the data was updated InstanceMeta Table InstanceMeta table stores information about the instance ingestion by this solution. The data attributes are listed as below: Attribute name Type Description Comments id String Unique ID of a configuration Partition key createdDt String Creation time intanceId String The EC2 instance id appPipelineId String The Partition key of the AppPipeline table logAgent Map sub-field: agentName: FluentBit sub-field: version: 1.8.2 confId String The Partition key of the LogConf table groupId String The Partition key of the InstanceGroup table status String ACTIVE, INACTIVE updatedDt String The last time the data was updated LogAgentStatus Table LogAgentStatus table stores information about the status of Fluent Bit installation by this solution. The data attributes are listed as below: Attribute name Type Description Comments intanceId String the EC2 instance Id Partition key createdDt String creation time id String the Command Id status String Not_Installed, Online, Offline updatedDt String The last time the data was updated AppPipeline Table AppPipeline table stores information about Application Log Pipeline by this solution. The data attributes are listed as below: Attribute name Type Description Comments id String Unique ID of a pipeline Partition key createdDt String creation time aosParas Map the Command Id sub-field: opensearchArn, type: String sub-field: domainName, type: String sub-field: indexPrefix, type: String sub-field: warmLogTransition, type: Number sub-field: coldLogTransition, type: Number sub-field: logRetention, type: Number kdsParas Map sub-field: kdsArn, type: String sub-field: streamName, type:String sub-field: enableAutoScaling, type:Boolean, True, False; In UI, we use yes or no sub-field: startShardNumber, type:Number sub-field: maxShardNumber, type:Number sub-field: regionName, type:String sub-field:engine, type:String tags Map sub-field: key-value, type:String status String CREATING, DELETING, ERROR, INACTIVE, ACTIVE updatedDt String The last time the data was updated AppLogIngestion Table AppLogIngestion table is used to the information about Application Log Ingestion by this solution. The data attributes are listed as below: Attribute name Type Description Comments id String Unique ID of a pipeline Partition key createdDt String creation time confId String The Partition key of the LogConf table sourceType String EC2,EKS, S3 sourceId String If EC2 then sourceId is groupId; If EKS then sourceId is EKSClusterId; If S3 then sourceId is S3LogSourceInfo; groupId String The Partition key of the InstanceGroup table stackId String The Cloudformation stack ID for ingesting application logs from the S3 bucket or K8s pod. stackName String The Cloudformation stack Name for ingesting application logs from the S3 bucket or K8s pod. appPipelineId String The Partition key of the AppPipeline table tags Map Sub-field: key-value, type:String status String CREATING, DELETING, ERROR, INACTIVE, ACTIVE updatedDt String The last time the data was updated EKSClusterLogSource Table EKSClusterLogSource table stores information about imported EKS Cluster by this solution. The data attributes are listed as below: Attribute name Type Description Comments id String Unique ID of a pipeline Partition key createdDt String creation time aosDomainId String The Partition key of the Cluster table region String The region to which the imported EKS cluster belongs accountId String The account to which the imported EKS cluster belongs eksClusterName String The Partition key of the InstanceGroup table eksClusterArn String The imported EKS Cluster ARN. cri String The K8s Container runtime : containerd,docker. subnetIds String The EKS Cluster Subnets vpcId Map The EKS Cluster vpcId eksClusterSGId String The EKS Cluster security group oidcIssuer String OpenID Connect provider URL endpoint String The EKS Cluster API server endpoint tags Map Sub-field: key-value, type:String logAgentRoleArn String The ARN of the role corresponding to the service account of K8s, this role attaches write-related permissions to KDS. status String CREATING, DELETING, ERROR, INACTIVE, ACTIVE updatedDt String The last time the data was updated LogAgentEKSDeploymentKind Table The LogAgentEKSDeploymentKind table stores information about the deployment type of the log agent by this solution. The data attributes are listed as below: Attribute name Type Description Comments id String Unique ID of a pipeline Partition key createdDt String creation time eksClusterId String The Partition key of the EKSClusterLogSource table deploymentKind String DaemonSet,Sidecar updatedDt String The last time the data was updated S3LogSource Table The S3LogSource table stores information about which log source is the S3 bucket by this solution. The data attributes are listed as below: Attribute name Type Description Comments id String Unique ID of a pipeline Partition key createdDt String creation time region String The region to which the iS3 bucket belongs accountId String The account to which the S3 bucket belongs s3Name String The S3 bucket name for log storage s3Prefix String The S3 prefix for log storage archiveFormat String The log format tags Map Sub-field: key-value, type:String updatedDt String The last time the data was updated","title":"Data Model Design"},{"location":"designs/app-log/data-model-design/#application-log-analytics-data-model-design","text":"","title":"Application Log Analytics Data Model Design"},{"location":"designs/app-log/data-model-design/#overview","text":"This part uses Amazon DynamoDB as the backend NoSQL database. This document is about the Data Model Design for Application Log Analytics module.","title":"Overview"},{"location":"designs/app-log/data-model-design/#entity-relationship-diagram","text":"","title":"Entity Relationship Diagram"},{"location":"designs/app-log/data-model-design/#logconf-table","text":"LogConf table stores information about the Application log configuration by this solution, such as log type, log path. The data attributes are listed as below: Attribute name Type Description Comments id String Unique ID of a configuration Partition key confName String The name of the configuration name createdDt String creation time logPath String Log file path logType String Json, Regex, Nginx, Apache, MultiLineText multilineLogParser String JAVA_SPRING_BOOT regularExpression String Regular expressions regularSpec String Field type definition after regular parsing status String ACTIVE, INACTIVE INACTIVE means delete state userLogFormat String Log format updatedDt String The last time the data was updated","title":"LogConf Table"},{"location":"designs/app-log/data-model-design/#instancegroup-table","text":"InstanceGroup table stores information about the instance and grouping relationship information by this solution, such as log type. The data attributes are listed as below: Attribute name Type Description Comments id String Unique ID of a group Partition key groupName String The name of the log group. the name must be unique, and can only contains lower case letters and -. createdDt String Creation time instanceSet String List of instance ids status String ACTIVE, INACTIVE INACTIVE means delete state updatedDt String The last time the data was updated","title":"InstanceGroup Table"},{"location":"designs/app-log/data-model-design/#instancemeta-table","text":"InstanceMeta table stores information about the instance ingestion by this solution. The data attributes are listed as below: Attribute name Type Description Comments id String Unique ID of a configuration Partition key createdDt String Creation time intanceId String The EC2 instance id appPipelineId String The Partition key of the AppPipeline table logAgent Map sub-field: agentName: FluentBit sub-field: version: 1.8.2 confId String The Partition key of the LogConf table groupId String The Partition key of the InstanceGroup table status String ACTIVE, INACTIVE updatedDt String The last time the data was updated","title":"InstanceMeta Table"},{"location":"designs/app-log/data-model-design/#logagentstatus-table","text":"LogAgentStatus table stores information about the status of Fluent Bit installation by this solution. The data attributes are listed as below: Attribute name Type Description Comments intanceId String the EC2 instance Id Partition key createdDt String creation time id String the Command Id status String Not_Installed, Online, Offline updatedDt String The last time the data was updated","title":"LogAgentStatus Table"},{"location":"designs/app-log/data-model-design/#apppipeline-table","text":"AppPipeline table stores information about Application Log Pipeline by this solution. The data attributes are listed as below: Attribute name Type Description Comments id String Unique ID of a pipeline Partition key createdDt String creation time aosParas Map the Command Id sub-field: opensearchArn, type: String sub-field: domainName, type: String sub-field: indexPrefix, type: String sub-field: warmLogTransition, type: Number sub-field: coldLogTransition, type: Number sub-field: logRetention, type: Number kdsParas Map sub-field: kdsArn, type: String sub-field: streamName, type:String sub-field: enableAutoScaling, type:Boolean, True, False; In UI, we use yes or no sub-field: startShardNumber, type:Number sub-field: maxShardNumber, type:Number sub-field: regionName, type:String sub-field:engine, type:String tags Map sub-field: key-value, type:String status String CREATING, DELETING, ERROR, INACTIVE, ACTIVE updatedDt String The last time the data was updated","title":"AppPipeline Table"},{"location":"designs/app-log/data-model-design/#applogingestion-table","text":"AppLogIngestion table is used to the information about Application Log Ingestion by this solution. The data attributes are listed as below: Attribute name Type Description Comments id String Unique ID of a pipeline Partition key createdDt String creation time confId String The Partition key of the LogConf table sourceType String EC2,EKS, S3 sourceId String If EC2 then sourceId is groupId; If EKS then sourceId is EKSClusterId; If S3 then sourceId is S3LogSourceInfo; groupId String The Partition key of the InstanceGroup table stackId String The Cloudformation stack ID for ingesting application logs from the S3 bucket or K8s pod. stackName String The Cloudformation stack Name for ingesting application logs from the S3 bucket or K8s pod. appPipelineId String The Partition key of the AppPipeline table tags Map Sub-field: key-value, type:String status String CREATING, DELETING, ERROR, INACTIVE, ACTIVE updatedDt String The last time the data was updated","title":"AppLogIngestion Table"},{"location":"designs/app-log/data-model-design/#eksclusterlogsource-table","text":"EKSClusterLogSource table stores information about imported EKS Cluster by this solution. The data attributes are listed as below: Attribute name Type Description Comments id String Unique ID of a pipeline Partition key createdDt String creation time aosDomainId String The Partition key of the Cluster table region String The region to which the imported EKS cluster belongs accountId String The account to which the imported EKS cluster belongs eksClusterName String The Partition key of the InstanceGroup table eksClusterArn String The imported EKS Cluster ARN. cri String The K8s Container runtime : containerd,docker. subnetIds String The EKS Cluster Subnets vpcId Map The EKS Cluster vpcId eksClusterSGId String The EKS Cluster security group oidcIssuer String OpenID Connect provider URL endpoint String The EKS Cluster API server endpoint tags Map Sub-field: key-value, type:String logAgentRoleArn String The ARN of the role corresponding to the service account of K8s, this role attaches write-related permissions to KDS. status String CREATING, DELETING, ERROR, INACTIVE, ACTIVE updatedDt String The last time the data was updated","title":"EKSClusterLogSource Table"},{"location":"designs/app-log/data-model-design/#logagenteksdeploymentkind-table","text":"The LogAgentEKSDeploymentKind table stores information about the deployment type of the log agent by this solution. The data attributes are listed as below: Attribute name Type Description Comments id String Unique ID of a pipeline Partition key createdDt String creation time eksClusterId String The Partition key of the EKSClusterLogSource table deploymentKind String DaemonSet,Sidecar updatedDt String The last time the data was updated","title":"LogAgentEKSDeploymentKind Table"},{"location":"designs/app-log/data-model-design/#s3logsource-table","text":"The S3LogSource table stores information about which log source is the S3 bucket by this solution. The data attributes are listed as below: Attribute name Type Description Comments id String Unique ID of a pipeline Partition key createdDt String creation time region String The region to which the iS3 bucket belongs accountId String The account to which the S3 bucket belongs s3Name String The S3 bucket name for log storage s3Prefix String The S3 prefix for log storage archiveFormat String The log format tags Map Sub-field: key-value, type:String updatedDt String The last time the data was updated","title":"S3LogSource Table"},{"location":"designs/app-log/log-analytics-pipeline-app/","text":"Application Log A Log Pipeline includes the process of receiving, cleaning, enhancing, and writing data to AOS. Typically, a log pipeline only accepts logs in one format. A log analytics pipeline corresponds to an index pattern in AOS (e.g. log-hub-nginx-log-index )\u3002 System Architecture design Concept Log Config Log Config contains Config Name: The name of the log configuration, the name must be unique, and can only contains lower case letters and -. Log Path: Specify the log file locations. If you have multiple locations, please write all the locations and split using ' , '. e.g./var/log/app1/ .log,/var/log/app2/ .log. All files in the specified folder that match the file name will be monitored. The file name can be a full name or wildcard pattern matching is supported. Log Type: the Log Hub has built-in plugins to parse log data from log agents. Currently supported log types are as follows: JSON, Nginx Log, Apache Log, Spring Boot Log Additionally, we also point to custom parsing via regular expressions Log Format: the log format configuration in Nginx, Spring Boot, Apache configuration files. Such as Nginx, if you want to know more, you can refer to configuring logging in Nginx Log Group A Log Group is a collection of one or more Log Configs applied to a group of EC2 instances. The following figure can better understand the concepts of Log Group and Log Config. According to the configuration shown in the figure above, the configuration files of FluentBit in Instance A, B, and C are all different. Instance A: Collect Nginx type log a and JSON format log b. Instance B: Collect all four types of logs. Instance C: Collect Apache type logs c and JSON format logs d. FAQ Q. Why not use Firehose to collect and write to AOS? Because the minimum buffer interval of Firehose is 60s, it is difficult to meet the scene of real-time class analysis. Please refer to Amazon Kinesis Data Firehose Quota .","title":"Overview"},{"location":"designs/app-log/log-analytics-pipeline-app/#application-log","text":"A Log Pipeline includes the process of receiving, cleaning, enhancing, and writing data to AOS. Typically, a log pipeline only accepts logs in one format. A log analytics pipeline corresponds to an index pattern in AOS (e.g. log-hub-nginx-log-index )\u3002","title":"Application Log"},{"location":"designs/app-log/log-analytics-pipeline-app/#system-architecture-design","text":"","title":"System Architecture design"},{"location":"designs/app-log/log-analytics-pipeline-app/#concept","text":"","title":"Concept"},{"location":"designs/app-log/log-analytics-pipeline-app/#log-config","text":"Log Config contains Config Name: The name of the log configuration, the name must be unique, and can only contains lower case letters and -. Log Path: Specify the log file locations. If you have multiple locations, please write all the locations and split using ' , '. e.g./var/log/app1/ .log,/var/log/app2/ .log. All files in the specified folder that match the file name will be monitored. The file name can be a full name or wildcard pattern matching is supported. Log Type: the Log Hub has built-in plugins to parse log data from log agents. Currently supported log types are as follows: JSON, Nginx Log, Apache Log, Spring Boot Log Additionally, we also point to custom parsing via regular expressions Log Format: the log format configuration in Nginx, Spring Boot, Apache configuration files. Such as Nginx, if you want to know more, you can refer to configuring logging in Nginx","title":"Log Config"},{"location":"designs/app-log/log-analytics-pipeline-app/#log-group","text":"A Log Group is a collection of one or more Log Configs applied to a group of EC2 instances. The following figure can better understand the concepts of Log Group and Log Config. According to the configuration shown in the figure above, the configuration files of FluentBit in Instance A, B, and C are all different. Instance A: Collect Nginx type log a and JSON format log b. Instance B: Collect all four types of logs. Instance C: Collect Apache type logs c and JSON format logs d.","title":"Log Group"},{"location":"designs/app-log/log-analytics-pipeline-app/#faq","text":"Q. Why not use Firehose to collect and write to AOS? Because the minimum buffer interval of Firehose is 60s, it is difficult to meet the scene of real-time class analysis. Please refer to Amazon Kinesis Data Firehose Quota .","title":"FAQ"},{"location":"designs/app-log/process-design/","text":"Application Log Pipeline Process This document is about the Process Design for Log Agent Installation, Application Log Pipeline and Ingestion . Overview Install Log Agent Create an Application Log Ingestion","title":"Process Design"},{"location":"designs/app-log/process-design/#application-log-pipeline-process","text":"This document is about the Process Design for Log Agent Installation, Application Log Pipeline and Ingestion .","title":"Application Log Pipeline Process"},{"location":"designs/app-log/process-design/#overview","text":"","title":"Overview"},{"location":"designs/app-log/process-design/#install-log-agent","text":"","title":"Install Log Agent"},{"location":"designs/app-log/process-design/#create-an-application-log-ingestion","text":"","title":"Create an Application Log Ingestion"},{"location":"designs/domain-management/api-design/","text":"Domain Management API Design Overview This document is about the API Design for Domain Management component. To learn more information about the component, refer to Component Design Domain APIs Domain APIs are a list of operations on top of Amazon OpenSearch Service (AOS). The following operations are available in the solution's Domain APIs. List Domain Names Type: Query Description: List all existing Amazon OpenSearch domains in a region Resolver: Lambda Parameters: Name Type Required Default Description region String No current region To support cross region listing (in the same account) Simple Request & Response: Request with region query example{ listDomainNames(region: \"us-west-2\") { domainNames } } Request without region query example { listDomainNames { domainNames } } Response: { \"data\": { \"listDomainNames\": { \"domainNames\": [ \"dev\", \"test\" ] } } } Import Domain Type: Mutation Description: Import an Exisiting Amazon OpenSearch Domain, store general info from DynamoDB table. Resolver: Lambda Parameters: Name Type Required Default Description domainName String Yes Amazon OpenSearch Domain Name region String No current region To support cross region Amazon OpenSearch import vpc K-V Yes Log processing vpc tags K-V No Custom tags for the imported domain Simple Request & Response: Request: mutation example{ importDomain( domainName: \"dev\", tags: {key: \"project\", value: \"Loghub\"}, vpc: { securityGroupId: \"sg-1\", vpcId: \"vpc-1\", privateSubnetIds: \"subnet-a,subnet-b\", publicSubnetIds: \"subnet-c,subnet-d\" }, region: \"us-west-2\" ) } Response: { \"data\": { \"importDomain\": \"OK\" } } Exceptions: Domain is already imported Elasticsearch Domain Not Found Public network type is not supported, only Amazon OpenSearch domain within VPC can be imported The domain to be imported must be active Unknown exception, please check Lambda log for more details { \"data\": { \"importDomain\": null }, \"errors\": [ { \"path\": [ \"importDomain\" ], \"data\": null, \"errorType\": \"Lambda:Unhandled\", \"errorInfo\": null, \"locations\": [ { \"line\": 8, \"column\": 3, \"sourceName\": null } ], \"message\": \"Domain is already imported\" } ] } Remove Domain Type: Mutation Description: Remove an Amazon OpenSearch Domain record from DynamoDB table. This will not remove the backend AOS domain. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Amazon OpenSearch Domain Arn (key in DynamoDB) Simple Request & Response: Request: mutation example { removeDomain(id: \"439239da8014f9a419c92b1b0c72a5fc\") } Response: { \"data\": { \"removeDomain\": \"OK\" } } Exceptions: Unknown exception, please check Lambda log for more details { \"data\": { \"removeDomain\": null }, \"errors\": [ { \"path\": [ \"removeDomain\" ], \"data\": null, \"errorType\": \"Lambda:Unhandled\", \"errorInfo\": null, \"locations\": [ { \"line\": 32, \"column\": 3, \"sourceName\": null } ], \"message\": \"Unknown exception, please check Lambda log for more details\" } ] } List Imported Domains Type: Query Description: List all existing Amazon OpenSearch domains in a region Resolver: Lambda Parameters: Name Type Required Default Description metrics Boolean No FALSE To decide wheather need to query domain metrix (additional request) Simple Request & Response: Request: query example { listImportedDomains(metrics: true) { domainName endpoint id metrics { freeStorageSpace health searchableDocs } version engine } } Response: { \"data\": { \"listImportedDomains\": [ { \"id\": \"439239da8014f9a419c92b1b0c72a5fc\", \"domainName\": \"dev\", \"endpoint\": \"vpc-dev-3ze2yoxxxxxxxxx.us-west-2.es.amazonaws.com\", \"metrics\": { \"freeStorageSpace\": 16058.91, \"health\": \"GREEN\", \"searchableDocs\": 13159 }, \"version\": \"1.0\", \"engine\": \"OpenSearch\" } ] } } Get Domain Details Type: Query Description: Get details of an imported domain. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Amazon OpenSearch Domain Arn (key in DynamoDB) metrics Boolean No FALSE Whether to include metrics Simple Request & Response: Request: query example { getDomainDetails(id: \"439239da8014f9a419c92b1b0c72a5fc\") { domainName endpoint id nodes { coldEnabled dedicatedMasterCount dedicatedMasterEnabled dedicatedMasterType instanceCount instanceType warmCount warmEnabled warmType zoneAwarenessEnabled } tags { key value } storageType volume { size type } vpc { privateSubnetIds publicSubnetIds securityGroupId vpcId } metrics { freeStorageSpace health searchableDocs } engine version proxyALB proxyError proxyInput { certificateArn cognitoEndpoint customEndpoint keyName vpc { privateSubnetIds publicSubnetIds securityGroupId vpcId } } proxyStatus alarmError alarmInput { email phone alarms { type value } } alarmStatus cognito { domain enabled identityPoolId userPoolId roleArn } accountId domainArn region } } Response: { \"data\": { \"getDomainDetails\": { \"id\": \"439239da8014f9a419c92b1b0c72a5fc\", \"domainName\": \"dev\", \"endpoint\": \"vpc-dev-3ze2yoxxxxxxxxx.us-west-2.es.amazonaws.com\", \"engine\": \"OpenSearch\", \"version\": \"1.0\" \"vpc\": { \"privateSubnetIds\": \"subnet-1234\", \"publicSubnetIds\": \"subnet-6789\", \"securityGroupId\": \"sg-1\", \"vpcId\": \"vpc-1\" }, \"cognito\": { \"domain\": \"\", \"enabled\": false, \"identityPoolId\": \"N/A\", \"userPoolId\": \"N/A\", \"roleArn\": \"N/A\" } \"nodes\": { \"coldEnabled\": false, \"dedicatedMasterCount\": 0, \"dedicatedMasterEnabled\": false, \"dedicatedMasterType\": \"N/A\", \"instanceCount\": 1, \"instanceType\": \"r6g.large.elasticsearch\", \"warmCount\": 0, \"warmEnabled\": false, \"warmType\": \"N/A\", \"zoneAwarenessEnabled\": false }, \"tags\": [ { \"key\": \"project\", \"value\": \"Loghub\" } ], \"storageType\": \"EBS\", \"volume\": { \"size\": 100, \"type\": \"gp2\" } \"esVpc\": { \"availabilityZones\": [ \"us-west-2b\" ], \"securityGroupIds\": [ \"sg-07cdfb011fba47e27\" ], \"subnetIds\": [ \"subnet-0f88a069\" ], \"vpcId\": \"vpc-538e702a\" }, \"metrics\": { \"freeStorageSpace\": 1, \"health\": \"GREEN\", \"searchableDocs\": 1 }, \"alarmError\": \"\", \"alarmInput\": { \"email\": \"test@example.com\", \"phone\": null, \"alarms\": [ { \"type\": \"CLUSTER_RED\", \"value\": \"true\" } ] }, \"alarmStatus\": \"ENABLED\", \"proxyStatus\": \"ENABLED\", \"proxyALB\": \"LogHu-LoadB-xxx.us-west-2.elb.amazonaws.com\", \"proxyError\": \"\" \"proxyInput\": { \"certificateArn\": \"arn:aws:es:us-west-2:123456789012:domain/mycert\", \"cognitoEndpoint\": \"\", \"customEndpoint\": \"www.example.com\", \"keyName\": \"my-key\", \"vpc\": { \"publicSubnetIds\": \"subnet-1234,subnet-1235\", \"privateSubnetIds\": \"subnet-5678,subnet-5679\", \"securityGroupId\": \"sg-1234\", \"vpcId\": \"vpc-1234\" } } } } } Exceptions: Cannot find domain in the imported list Unknown exception, please check Lambda log for more details Get Domain VPC Type: Query Description: Get VPC info of an Amazon OpenSearch domain in a region Resolver: Lambda Parameters: Name Type Required Default Description region String No current region To support cross region listing (in the same account) domainName String Yes Domain Name Simple Request & Response: Request with region query example { getDomainVpc(domainName: \"dev\", region: \"eu-west-1\") { availabilityZones securityGroupIds subnetIds vpcId } } Request without region query example { getDomainVpc(domainName: \"dev\") { availabilityZones securityGroupIds subnetIds vpcId } } Response: { \"data\": { \"getDomainVpc\": { \"availabilityZones\": [ \"eu-west-1a\" ], \"securityGroupIds\": [ \"sg-07cdfb011fba47e27\" ], \"subnetIds\": [ \"subnet-0f88a069\" ], \"vpcId\": \"vpc-538e702a\" } } } Create Proxy For OpenSearch Type: Mutation Description: Create a Nginx Proxy for Amazon OpenSearch in vpc Resolver: Lambda Parameters: Name Type Required Default Description customEndpoint String Yes Custom Domain to access Kibana cognitoEndpoint String No Cognito Domain for Amazon OpenSearch, blank if Amazon OpenSearch doesn't have cognito enabled id String Yes Amazon OpenSearch Domain Arn keyName String Yes? EC2 (nginx) key name vpc K-V Yes VPC for EC2 (nginx) certificateArn String Yes ACM certificate Arn for ELB Simple Request & Response: Request: mutation example { createProxyForOpenSearch( nginx: { vpc: { securityGroupId: \"sg-1234\", privateSubnetIds: \"subnet-1234,subnet-1235\", publicSubnetIds: \"subnet-5678,subnet-5679\", vpcId: \"vpc-1234\" }, certificateArn: \"arn:aws:es:us-west-2:123456789012:domain/mycert\", keyName: \"my-key\", cognitoEndpoint: \"hello.auth.us-west-2.amazoncognito.com\", customEndpoint: \"www.example.com\", }, id: \"439239da8014f9a419c92b1b0c72a5fc\" ) } Response: { \"data\": { \"createNginxProxyForOpenSearch\": \"OK\" } } Exceptions: Unknown exception, please check Lambda log for more details Delete Proxy For OpenSearch Type: Mutation Description: Remove an Amazon OpenSearch Nginx Proxy Stack Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Amazon OpenSearch Domain Arn (key in DynamoDB) Request: mutation example { deleteProxyForOpenSearch(id: \"439239da8014f9a419c92b1b0c72a5fc\") } Response: { \"data\": { \"deleteProxyForOpenSearch\": \"OK\" } } Exceptions: Unknown exception, please check Lambda log for more details Create Alarm For OpenSearch Type: Mutation Description: Create an Alarm for opensearch domain Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Amazon OpenSearch Domain Arn email String Yes? Email to receive notification alarms List Yes List of k-v for alarm parameters phone String No Phone number to receive notification Simple Request & Response: Request: mutation example { createAlarmForOpenSearch( id: \"439239da8014f9a419c92b1b0c72a5fc\", input: { email: \"test@example.com\", alarms: [ {Type: CLUSTER_RED, value: \"true\"}, {Type: FREE_STORAGE_SPACE, value: \"20\"} ... }) } Response: { \"data\": { \"createAlarmForOpenSearch\": \"OK\" } } Exceptions: Unknown exception, please check Lambda log for more details Delete Alarm For OpenSearch Type: Mutation Description: Remove an Alarm Stack Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Amazon OpenSearch Domain Arn (key in DynamoDB) Simple Request & Response: Request: mutation example { deleteAlarmForOpenSearch(id: \"439239da8014f9a419c92b1b0c72a5fc\") } Response: { \"data\": { \"deleteAlarmForOpenSearch\": \"OK\" } } Exceptions: Unknown exception, please check Lambda log for more details Resource APIs Resource APIs are a list of helper functions for AWS Resources that are used in the solution, such as listing VPCs etc. List Resources Type: Query Description: List AWS Resources (Services) in current region Resolver: Lambda Parameters: Name Type Required Default Description type String Yes Available List: S3Bucket, VPC, Subnet, SecurityGroup, Certificate, KeyName, Trail parentId String No To filter by parent Id if any, if not provided, all are returned Simple Request & Response: Request for list S3Bucket query example { listResources(Type:S3Bucket) { id name parentId } } Response: { \"data\": { \"listResources\": [ { \"id\": \"bucketa\", \"name\": \"bucketa\", \"parentId\": null }, { \"id\": \"bucketb\", \"name\": \"bucketb\", \"parentId\": null } ] } } Request for list VPC Id query example { listResources(Type:VPC) { id name parentId } } Response: { \"data\": { \"listResources\": [ { \"id\": \"vpc-040e5096a29a457db\", \"name\": \"test-vpc\", \"parentId\": null }, { \"id\": \"vpc-538e702a\", \"name\": \"default-vpc\", \"parentId\": null }, { \"id\": \"vpc-1112456\", \"name\": \"-\", \"parentId\": null } ] } } Request for list Subnet Id query example { listResources(Type:Subnet, parentId: \"vpc-088c09a3e0b797406\") { id description name parentId } } Response: { \"data\": { \"listResources\": [ { \"id\": \"subnet-00a5510951c6b4bad\", \"description\": \"eu-west-1a\", \"name\": \"LogHub/LogHubVPC/DefaultVPC/publicSubnet1\", \"parentId\": \"vpc-088c09a3e0b797406\" }, { \"id\": \"subnet-066f81646e30f0e48\", \"description\": \"eu-west-1b\", \"name\": \"LogHub/LogHubVPC/DefaultVPC/publicSubnet2\", \"parentId\": \"vpc-088c09a3e0b797406\" }, { \"id\": \"subnet-06c232cfb88789980\", \"description\": \"eu-west-1a\", \"name\": \"LogHub/LogHubVPC/DefaultVPC/privateSubnet1\", \"parentId\": \"vpc-088c09a3e0b797406\" }, { \"id\": \"subnet-04324df4484d33cfb\", \"description\": \"eu-west-1b\", \"name\": \"LogHub/LogHubVPC/DefaultVPC/privateSubnet2\", \"parentId\": \"vpc-088c09a3e0b797406\" }, { \"id\": \"subnet-065c2b45471b08568\", \"description\": \"eu-west-1b\", \"name\": \"LogHub/LogHubVPC/DefaultVPC/isolatedSubnet2\", \"parentId\": \"vpc-088c09a3e0b797406\" }, { \"id\": \"subnet-0934357dfce96eba3\", \"description\": \"eu-west-1a\", \"name\": \"LogHub/LogHubVPC/DefaultVPC/isolatedSubnet1\", \"parentId\": \"vpc-088c09a3e0b797406\" } ] } } Request for list lambda functions query example { listResources(Type:Lambda) { description id name } } Response: { \"data\": { \"listResources\": [ { \"description\": \"Log Hub - Helper function to handle CloudFormation deployment\", \"id\": \"LogHub-LogHubCfnFlowCfnHelperD9302B91-VZNJXLqIZjVu\", \"name\": \"LogHub-LogHubCfnFlowCfnHelperD9302B91-VZNJXLqIZjVu-$LATEST\" }, ... ] } } Request for list RDS instances query example { listResources(Type:RDS) { description id name } } Response: { \"data\": { \"listResources\": [ { \"description\": \"/aws/rds/instance/database-1\", \"id\": \"database-1\", \"name\": \"database-1 (mysql)\" }, { \"description\": \"/aws/rds/cluster/demodb\", \"id\": \"demodb-instance-1\", \"name\": \"demodb-instance-1 (aurora-mysql)\" } ] } } Put Resource Logging Bucket Type: Mutation Description: Put Logging bucket for resource in current region Resolver: Lambda Parameters: Name Type Required Default Description type String Yes Available List: S3Bucket, CloudFront resourceName String Yes The resource name or ID Simple Request & Response: Request query example { putResourceLoggingBucket(resourceName: \"test-bucket\", Type: S3Bucket) { bucket prefix enabled } } Response: { \"data\": { \"putResourceLoggingBucket\": { \"bucket\": \"loghub-loghubloggingbucket0fa53b76-mkvj68ix2ufo\", \"prefix\": \"s3/test-bucket/\", \"enabled\": true } } } Get Resource Logging Bucket Type: Query Description: Get Logging bucket for resource in current region Resolver: Lambda Parameters: Name Type Required Default Description type String Yes Available List: S3Bucket, Trail resourceName String Yes The resource name or ID Simple Request & Response: Request query example { getResourceLoggingBucket(Type: Trail, resourceName: \"testtrail\") { bucket prefix enabled } } Response: { \"data\": { \"getResourceLoggingBucket\": { \"bucket\": \"aws-cloudtrail-logs-123456789012-222dcf7b\", \"prefix\": \"AWSLogs/123456789012/CloudTrail/\", \"enabled: true } } }","title":"API Design"},{"location":"designs/domain-management/api-design/#domain-management-api-design","text":"","title":"Domain Management API Design"},{"location":"designs/domain-management/api-design/#overview","text":"This document is about the API Design for Domain Management component. To learn more information about the component, refer to Component Design","title":"Overview"},{"location":"designs/domain-management/api-design/#domain-apis","text":"Domain APIs are a list of operations on top of Amazon OpenSearch Service (AOS). The following operations are available in the solution's Domain APIs.","title":"Domain APIs"},{"location":"designs/domain-management/api-design/#list-domain-names","text":"Type: Query Description: List all existing Amazon OpenSearch domains in a region Resolver: Lambda Parameters: Name Type Required Default Description region String No current region To support cross region listing (in the same account) Simple Request & Response: Request with region query example{ listDomainNames(region: \"us-west-2\") { domainNames } } Request without region query example { listDomainNames { domainNames } } Response: { \"data\": { \"listDomainNames\": { \"domainNames\": [ \"dev\", \"test\" ] } } }","title":"List Domain Names"},{"location":"designs/domain-management/api-design/#import-domain","text":"Type: Mutation Description: Import an Exisiting Amazon OpenSearch Domain, store general info from DynamoDB table. Resolver: Lambda Parameters: Name Type Required Default Description domainName String Yes Amazon OpenSearch Domain Name region String No current region To support cross region Amazon OpenSearch import vpc K-V Yes Log processing vpc tags K-V No Custom tags for the imported domain Simple Request & Response: Request: mutation example{ importDomain( domainName: \"dev\", tags: {key: \"project\", value: \"Loghub\"}, vpc: { securityGroupId: \"sg-1\", vpcId: \"vpc-1\", privateSubnetIds: \"subnet-a,subnet-b\", publicSubnetIds: \"subnet-c,subnet-d\" }, region: \"us-west-2\" ) } Response: { \"data\": { \"importDomain\": \"OK\" } } Exceptions: Domain is already imported Elasticsearch Domain Not Found Public network type is not supported, only Amazon OpenSearch domain within VPC can be imported The domain to be imported must be active Unknown exception, please check Lambda log for more details { \"data\": { \"importDomain\": null }, \"errors\": [ { \"path\": [ \"importDomain\" ], \"data\": null, \"errorType\": \"Lambda:Unhandled\", \"errorInfo\": null, \"locations\": [ { \"line\": 8, \"column\": 3, \"sourceName\": null } ], \"message\": \"Domain is already imported\" } ] }","title":"Import Domain"},{"location":"designs/domain-management/api-design/#remove-domain","text":"Type: Mutation Description: Remove an Amazon OpenSearch Domain record from DynamoDB table. This will not remove the backend AOS domain. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Amazon OpenSearch Domain Arn (key in DynamoDB) Simple Request & Response: Request: mutation example { removeDomain(id: \"439239da8014f9a419c92b1b0c72a5fc\") } Response: { \"data\": { \"removeDomain\": \"OK\" } } Exceptions: Unknown exception, please check Lambda log for more details { \"data\": { \"removeDomain\": null }, \"errors\": [ { \"path\": [ \"removeDomain\" ], \"data\": null, \"errorType\": \"Lambda:Unhandled\", \"errorInfo\": null, \"locations\": [ { \"line\": 32, \"column\": 3, \"sourceName\": null } ], \"message\": \"Unknown exception, please check Lambda log for more details\" } ] }","title":"Remove Domain"},{"location":"designs/domain-management/api-design/#list-imported-domains","text":"Type: Query Description: List all existing Amazon OpenSearch domains in a region Resolver: Lambda Parameters: Name Type Required Default Description metrics Boolean No FALSE To decide wheather need to query domain metrix (additional request) Simple Request & Response: Request: query example { listImportedDomains(metrics: true) { domainName endpoint id metrics { freeStorageSpace health searchableDocs } version engine } } Response: { \"data\": { \"listImportedDomains\": [ { \"id\": \"439239da8014f9a419c92b1b0c72a5fc\", \"domainName\": \"dev\", \"endpoint\": \"vpc-dev-3ze2yoxxxxxxxxx.us-west-2.es.amazonaws.com\", \"metrics\": { \"freeStorageSpace\": 16058.91, \"health\": \"GREEN\", \"searchableDocs\": 13159 }, \"version\": \"1.0\", \"engine\": \"OpenSearch\" } ] } }","title":"List Imported Domains"},{"location":"designs/domain-management/api-design/#get-domain-details","text":"Type: Query Description: Get details of an imported domain. Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Amazon OpenSearch Domain Arn (key in DynamoDB) metrics Boolean No FALSE Whether to include metrics Simple Request & Response: Request: query example { getDomainDetails(id: \"439239da8014f9a419c92b1b0c72a5fc\") { domainName endpoint id nodes { coldEnabled dedicatedMasterCount dedicatedMasterEnabled dedicatedMasterType instanceCount instanceType warmCount warmEnabled warmType zoneAwarenessEnabled } tags { key value } storageType volume { size type } vpc { privateSubnetIds publicSubnetIds securityGroupId vpcId } metrics { freeStorageSpace health searchableDocs } engine version proxyALB proxyError proxyInput { certificateArn cognitoEndpoint customEndpoint keyName vpc { privateSubnetIds publicSubnetIds securityGroupId vpcId } } proxyStatus alarmError alarmInput { email phone alarms { type value } } alarmStatus cognito { domain enabled identityPoolId userPoolId roleArn } accountId domainArn region } } Response: { \"data\": { \"getDomainDetails\": { \"id\": \"439239da8014f9a419c92b1b0c72a5fc\", \"domainName\": \"dev\", \"endpoint\": \"vpc-dev-3ze2yoxxxxxxxxx.us-west-2.es.amazonaws.com\", \"engine\": \"OpenSearch\", \"version\": \"1.0\" \"vpc\": { \"privateSubnetIds\": \"subnet-1234\", \"publicSubnetIds\": \"subnet-6789\", \"securityGroupId\": \"sg-1\", \"vpcId\": \"vpc-1\" }, \"cognito\": { \"domain\": \"\", \"enabled\": false, \"identityPoolId\": \"N/A\", \"userPoolId\": \"N/A\", \"roleArn\": \"N/A\" } \"nodes\": { \"coldEnabled\": false, \"dedicatedMasterCount\": 0, \"dedicatedMasterEnabled\": false, \"dedicatedMasterType\": \"N/A\", \"instanceCount\": 1, \"instanceType\": \"r6g.large.elasticsearch\", \"warmCount\": 0, \"warmEnabled\": false, \"warmType\": \"N/A\", \"zoneAwarenessEnabled\": false }, \"tags\": [ { \"key\": \"project\", \"value\": \"Loghub\" } ], \"storageType\": \"EBS\", \"volume\": { \"size\": 100, \"type\": \"gp2\" } \"esVpc\": { \"availabilityZones\": [ \"us-west-2b\" ], \"securityGroupIds\": [ \"sg-07cdfb011fba47e27\" ], \"subnetIds\": [ \"subnet-0f88a069\" ], \"vpcId\": \"vpc-538e702a\" }, \"metrics\": { \"freeStorageSpace\": 1, \"health\": \"GREEN\", \"searchableDocs\": 1 }, \"alarmError\": \"\", \"alarmInput\": { \"email\": \"test@example.com\", \"phone\": null, \"alarms\": [ { \"type\": \"CLUSTER_RED\", \"value\": \"true\" } ] }, \"alarmStatus\": \"ENABLED\", \"proxyStatus\": \"ENABLED\", \"proxyALB\": \"LogHu-LoadB-xxx.us-west-2.elb.amazonaws.com\", \"proxyError\": \"\" \"proxyInput\": { \"certificateArn\": \"arn:aws:es:us-west-2:123456789012:domain/mycert\", \"cognitoEndpoint\": \"\", \"customEndpoint\": \"www.example.com\", \"keyName\": \"my-key\", \"vpc\": { \"publicSubnetIds\": \"subnet-1234,subnet-1235\", \"privateSubnetIds\": \"subnet-5678,subnet-5679\", \"securityGroupId\": \"sg-1234\", \"vpcId\": \"vpc-1234\" } } } } } Exceptions: Cannot find domain in the imported list Unknown exception, please check Lambda log for more details","title":"Get Domain Details"},{"location":"designs/domain-management/api-design/#get-domain-vpc","text":"Type: Query Description: Get VPC info of an Amazon OpenSearch domain in a region Resolver: Lambda Parameters: Name Type Required Default Description region String No current region To support cross region listing (in the same account) domainName String Yes Domain Name Simple Request & Response: Request with region query example { getDomainVpc(domainName: \"dev\", region: \"eu-west-1\") { availabilityZones securityGroupIds subnetIds vpcId } } Request without region query example { getDomainVpc(domainName: \"dev\") { availabilityZones securityGroupIds subnetIds vpcId } } Response: { \"data\": { \"getDomainVpc\": { \"availabilityZones\": [ \"eu-west-1a\" ], \"securityGroupIds\": [ \"sg-07cdfb011fba47e27\" ], \"subnetIds\": [ \"subnet-0f88a069\" ], \"vpcId\": \"vpc-538e702a\" } } }","title":"Get Domain VPC"},{"location":"designs/domain-management/api-design/#create-proxy-for-opensearch","text":"Type: Mutation Description: Create a Nginx Proxy for Amazon OpenSearch in vpc Resolver: Lambda Parameters: Name Type Required Default Description customEndpoint String Yes Custom Domain to access Kibana cognitoEndpoint String No Cognito Domain for Amazon OpenSearch, blank if Amazon OpenSearch doesn't have cognito enabled id String Yes Amazon OpenSearch Domain Arn keyName String Yes? EC2 (nginx) key name vpc K-V Yes VPC for EC2 (nginx) certificateArn String Yes ACM certificate Arn for ELB Simple Request & Response: Request: mutation example { createProxyForOpenSearch( nginx: { vpc: { securityGroupId: \"sg-1234\", privateSubnetIds: \"subnet-1234,subnet-1235\", publicSubnetIds: \"subnet-5678,subnet-5679\", vpcId: \"vpc-1234\" }, certificateArn: \"arn:aws:es:us-west-2:123456789012:domain/mycert\", keyName: \"my-key\", cognitoEndpoint: \"hello.auth.us-west-2.amazoncognito.com\", customEndpoint: \"www.example.com\", }, id: \"439239da8014f9a419c92b1b0c72a5fc\" ) } Response: { \"data\": { \"createNginxProxyForOpenSearch\": \"OK\" } } Exceptions: Unknown exception, please check Lambda log for more details","title":"Create Proxy For OpenSearch"},{"location":"designs/domain-management/api-design/#delete-proxy-for-opensearch","text":"Type: Mutation Description: Remove an Amazon OpenSearch Nginx Proxy Stack Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Amazon OpenSearch Domain Arn (key in DynamoDB) Request: mutation example { deleteProxyForOpenSearch(id: \"439239da8014f9a419c92b1b0c72a5fc\") } Response: { \"data\": { \"deleteProxyForOpenSearch\": \"OK\" } } Exceptions: Unknown exception, please check Lambda log for more details","title":"Delete Proxy For OpenSearch"},{"location":"designs/domain-management/api-design/#create-alarm-for-opensearch","text":"Type: Mutation Description: Create an Alarm for opensearch domain Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Amazon OpenSearch Domain Arn email String Yes? Email to receive notification alarms List Yes List of k-v for alarm parameters phone String No Phone number to receive notification Simple Request & Response: Request: mutation example { createAlarmForOpenSearch( id: \"439239da8014f9a419c92b1b0c72a5fc\", input: { email: \"test@example.com\", alarms: [ {Type: CLUSTER_RED, value: \"true\"}, {Type: FREE_STORAGE_SPACE, value: \"20\"} ... }) } Response: { \"data\": { \"createAlarmForOpenSearch\": \"OK\" } } Exceptions: Unknown exception, please check Lambda log for more details","title":"Create Alarm For OpenSearch"},{"location":"designs/domain-management/api-design/#delete-alarm-for-opensearch","text":"Type: Mutation Description: Remove an Alarm Stack Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Amazon OpenSearch Domain Arn (key in DynamoDB) Simple Request & Response: Request: mutation example { deleteAlarmForOpenSearch(id: \"439239da8014f9a419c92b1b0c72a5fc\") } Response: { \"data\": { \"deleteAlarmForOpenSearch\": \"OK\" } } Exceptions: Unknown exception, please check Lambda log for more details","title":"Delete Alarm For OpenSearch"},{"location":"designs/domain-management/api-design/#resource-apis","text":"Resource APIs are a list of helper functions for AWS Resources that are used in the solution, such as listing VPCs etc.","title":"Resource APIs"},{"location":"designs/domain-management/api-design/#list-resources","text":"Type: Query Description: List AWS Resources (Services) in current region Resolver: Lambda Parameters: Name Type Required Default Description type String Yes Available List: S3Bucket, VPC, Subnet, SecurityGroup, Certificate, KeyName, Trail parentId String No To filter by parent Id if any, if not provided, all are returned Simple Request & Response: Request for list S3Bucket query example { listResources(Type:S3Bucket) { id name parentId } } Response: { \"data\": { \"listResources\": [ { \"id\": \"bucketa\", \"name\": \"bucketa\", \"parentId\": null }, { \"id\": \"bucketb\", \"name\": \"bucketb\", \"parentId\": null } ] } } Request for list VPC Id query example { listResources(Type:VPC) { id name parentId } } Response: { \"data\": { \"listResources\": [ { \"id\": \"vpc-040e5096a29a457db\", \"name\": \"test-vpc\", \"parentId\": null }, { \"id\": \"vpc-538e702a\", \"name\": \"default-vpc\", \"parentId\": null }, { \"id\": \"vpc-1112456\", \"name\": \"-\", \"parentId\": null } ] } } Request for list Subnet Id query example { listResources(Type:Subnet, parentId: \"vpc-088c09a3e0b797406\") { id description name parentId } } Response: { \"data\": { \"listResources\": [ { \"id\": \"subnet-00a5510951c6b4bad\", \"description\": \"eu-west-1a\", \"name\": \"LogHub/LogHubVPC/DefaultVPC/publicSubnet1\", \"parentId\": \"vpc-088c09a3e0b797406\" }, { \"id\": \"subnet-066f81646e30f0e48\", \"description\": \"eu-west-1b\", \"name\": \"LogHub/LogHubVPC/DefaultVPC/publicSubnet2\", \"parentId\": \"vpc-088c09a3e0b797406\" }, { \"id\": \"subnet-06c232cfb88789980\", \"description\": \"eu-west-1a\", \"name\": \"LogHub/LogHubVPC/DefaultVPC/privateSubnet1\", \"parentId\": \"vpc-088c09a3e0b797406\" }, { \"id\": \"subnet-04324df4484d33cfb\", \"description\": \"eu-west-1b\", \"name\": \"LogHub/LogHubVPC/DefaultVPC/privateSubnet2\", \"parentId\": \"vpc-088c09a3e0b797406\" }, { \"id\": \"subnet-065c2b45471b08568\", \"description\": \"eu-west-1b\", \"name\": \"LogHub/LogHubVPC/DefaultVPC/isolatedSubnet2\", \"parentId\": \"vpc-088c09a3e0b797406\" }, { \"id\": \"subnet-0934357dfce96eba3\", \"description\": \"eu-west-1a\", \"name\": \"LogHub/LogHubVPC/DefaultVPC/isolatedSubnet1\", \"parentId\": \"vpc-088c09a3e0b797406\" } ] } } Request for list lambda functions query example { listResources(Type:Lambda) { description id name } } Response: { \"data\": { \"listResources\": [ { \"description\": \"Log Hub - Helper function to handle CloudFormation deployment\", \"id\": \"LogHub-LogHubCfnFlowCfnHelperD9302B91-VZNJXLqIZjVu\", \"name\": \"LogHub-LogHubCfnFlowCfnHelperD9302B91-VZNJXLqIZjVu-$LATEST\" }, ... ] } } Request for list RDS instances query example { listResources(Type:RDS) { description id name } } Response: { \"data\": { \"listResources\": [ { \"description\": \"/aws/rds/instance/database-1\", \"id\": \"database-1\", \"name\": \"database-1 (mysql)\" }, { \"description\": \"/aws/rds/cluster/demodb\", \"id\": \"demodb-instance-1\", \"name\": \"demodb-instance-1 (aurora-mysql)\" } ] } }","title":"List Resources"},{"location":"designs/domain-management/api-design/#put-resource-logging-bucket","text":"Type: Mutation Description: Put Logging bucket for resource in current region Resolver: Lambda Parameters: Name Type Required Default Description type String Yes Available List: S3Bucket, CloudFront resourceName String Yes The resource name or ID Simple Request & Response: Request query example { putResourceLoggingBucket(resourceName: \"test-bucket\", Type: S3Bucket) { bucket prefix enabled } } Response: { \"data\": { \"putResourceLoggingBucket\": { \"bucket\": \"loghub-loghubloggingbucket0fa53b76-mkvj68ix2ufo\", \"prefix\": \"s3/test-bucket/\", \"enabled\": true } } }","title":"Put Resource Logging Bucket"},{"location":"designs/domain-management/api-design/#get-resource-logging-bucket","text":"Type: Query Description: Get Logging bucket for resource in current region Resolver: Lambda Parameters: Name Type Required Default Description type String Yes Available List: S3Bucket, Trail resourceName String Yes The resource name or ID Simple Request & Response: Request query example { getResourceLoggingBucket(Type: Trail, resourceName: \"testtrail\") { bucket prefix enabled } } Response: { \"data\": { \"getResourceLoggingBucket\": { \"bucket\": \"aws-cloudtrail-logs-123456789012-222dcf7b\", \"prefix\": \"AWSLogs/123456789012/CloudTrail/\", \"enabled: true } } }","title":"Get Resource Logging Bucket"},{"location":"designs/domain-management/component-design/","text":"Domain Management Component Design Overview Log Hub solution uses Amazon OpenSearch service (AOS) as the underlying engine to store and analyze logs. This component consists a list of operations on top of AOS domains. This document is to describe this component is designed. Info For more information about solution overall design, refer to High Level Design . Component Design High-Level Architecture This component contains two sub components. Proxy for AOS As OpenSearch Dashboards is within VPC and has no public accesses. Customer can choose to deploy a proxy stack to access the OpenSearch Dashboards from internet with a custom domain. Below is the high level architecture diagram: The process is described as below: Customer accesses custom domain for the proxy, the domain needs to be resolved via DNS service (for example, using Route 53 on AWS) The DNS service routes the traffic to internet-facing Application Load Balancer (ALB) The ALB distributes web traffic to backend Nginx server running on Amazon EC2 within Auto Scaling Group. The Nginx server redirects the requests to OpenSearch Dashboards. (optional) VPC peering is required if the VPC for the proxy is not the same one as the OpenSearch service. Info This stack can be deployed independently without the UI, check more details about the CloudFormation Design Alarm for AOS There are a list of recommended CloudWatch alarms to be set up for Amazon OpenSearch Service. For example, to sent an email if the cluster health status is red for longer than one minute. Customer can choose to deploy an Alarm stack with one click to set up alarms in AWS. Below is the high level architecture diagram: Info This stack can be deployed indepentdantly without the UI, check more details about the CloudFormation Design The process is described as below: CloudWatch Alarm to monitor Amazon OpenSearch service and send state change event to Amazon EventBridge Amazon EventBridge rule to trigger and send information to Amazon SNS as target Amazon SNS uses Email as subscription and notifies Administrators Process Design This components includes a list of processes for domain management. For details about how the processes are designed, please refer to Process Design API Design This solution uses GraphQL APIs built on AWS Appsync service. For details about how the backend APIs are designed, please refer to API Design Data Model Design This component uses Amazon DynamoDB as the backend NoSQL database to store the information about AOS domains. To learn more information about how the data model is designed, please refer to Data Model Design CloudFormation Design Proxy for AOS CloudFormation Design The parameters in the CloudFormation template are listed as below: Parameter Default Description VPCId <Requires input> The VPC to deploy the Nginx proxy resources, for example, vpc-bef13dc7 . PublicSubnetIds <Requires input> The public subnets where ELB are deployed. You need to select at least two public subnets, for example, subnet-12345abc, subnet-54321cba . ELBSecurityGroupId <Requires input> The Security group being associated with the ELB, for example, sg-123456 . ELBDomain <Requires input> The custom domain name of the ELB, for example, dashboard.example.com . ELBDomainCertificateArn <Requires input> The SSL certificate ARN associated with the ELBDomain. The certificate must be created from [Amazon Certificate Manager (ACM)][acm]. PrivateSubnetIds <Requires input> The private subnets where Nginx instances are deployed. You need to select at least two private subnets, for example, subnet-12345abc, subnet-54321cba . NginxSecurityGroupId <Requires input> The Security group associated with the Nginx instances. The security group must allow access from ELB security group. KeyName <Requires input> The PEM key name of the Nginx instances. EngineType OpenSearch The engine type of the OpenSearch. Select OpenSearch or Elasticsearch. Endpoint <Requires input> The OpenSearch endpoint, for example, vpc-your_opensearch_domain_name-xcvgw6uu2o6zafsiefxubwuohe.us-east-1.es.amazonaws.com . CognitoEndpoint <Optional> The Cognito User Pool endpoint URL of the OpenSearch domain, for example, mydomain.auth.us-east-1.amazoncognito.com . Leave empty if your OpenSearch domain is not authenticated through Cognito User Pool. Alarm for AOS CloudFormation Design The parameters in the CloudFormation template are listed as below: Parameter Default Description Endpoint <Requires input> The endpoint of the OpenSearch domain, for example, vpc-your_opensearch_domain_name-xcvgw6uu2o6zafsiefxubwuohe.us-east-1.es.amazonaws.com . DomainName <Requires input> The name of the OpenSearch domain. Email <Requires input> The notification email address. Alarms will be sent to this email address via SNS. ClusterStatusRed Yes Whether to enable alarm when at least one primary shard and its replicas are not allocated to a node. ClusterStatusYellow Yes Whether to enable alarm when at least one replica shard is not allocated to a node. FreeStorageSpace 10 Whether to enable alarm when a node in your cluster is down to the free storage space you typed in GiB. We recommend setting it to 25% of the storage space for each node. 0 means the alarm is disabled. ClusterIndexWritesBlocked 1 Index writes blocked error occurs for >= x times in 5 minutes, 1 consecutive time. Input 0 to disable this alarm. UnreachableNodeNumber 3 Nodes minimum is < x for 1 day, 1 consecutive time. 0 means the alarm is disabled. AutomatedSnapshotFailure Yes Whether to enable alarm when automated snapshot failed. AutomatedSnapshotFailure maximum is >= 1 for 1 minute, 1 consecutive time. CPUUtilization Yes Whether to enable alarm when sustained high usage of CPU occurred. CPUUtilization or WarmCPUUtilization maximum is >= 80% for 15 minutes, 3 consecutive times. JVMMemoryPressure Yes Whether to enable alarm when JVM RAM usage peak occurred. JVMMemoryPressure or WarmJVMMemoryPressure maximum is >= 80% for 5 minutes, 3 consecutive times. MasterCPUUtilization Yes Whether to enable alarm when sustained high usage of CPU occurred in master nodes. MasterCPUUtilization maximum is >= 50% for 15 minutes, 3 consecutive times. MasterJVMMemoryPressure Yes Whether to enable alarm when JVM RAM usage peak occurred in master nodes. MasterJVMMemoryPressure maximum is >= 80% for 15 minutes, 1 consecutive time. KMSKeyError Yes Whether to enable alarm when KMS encryption key is disabled. KMSKeyError is >= 1 for 1 minute, 1 consecutive time. KMSKeyInaccessible Yes Whether to enable alarm when KMS encryption key has been deleted or has revoked its grants to OpenSearch Service. KMSKeyInaccessible is >= 1 for 1 minute, 1 consecutive time.","title":"Component Design"},{"location":"designs/domain-management/component-design/#domain-management-component-design","text":"","title":"Domain Management Component Design"},{"location":"designs/domain-management/component-design/#overview","text":"Log Hub solution uses Amazon OpenSearch service (AOS) as the underlying engine to store and analyze logs. This component consists a list of operations on top of AOS domains. This document is to describe this component is designed. Info For more information about solution overall design, refer to High Level Design .","title":"Overview"},{"location":"designs/domain-management/component-design/#component-design","text":"","title":"Component Design"},{"location":"designs/domain-management/component-design/#high-level-architecture","text":"This component contains two sub components. Proxy for AOS As OpenSearch Dashboards is within VPC and has no public accesses. Customer can choose to deploy a proxy stack to access the OpenSearch Dashboards from internet with a custom domain. Below is the high level architecture diagram: The process is described as below: Customer accesses custom domain for the proxy, the domain needs to be resolved via DNS service (for example, using Route 53 on AWS) The DNS service routes the traffic to internet-facing Application Load Balancer (ALB) The ALB distributes web traffic to backend Nginx server running on Amazon EC2 within Auto Scaling Group. The Nginx server redirects the requests to OpenSearch Dashboards. (optional) VPC peering is required if the VPC for the proxy is not the same one as the OpenSearch service. Info This stack can be deployed independently without the UI, check more details about the CloudFormation Design Alarm for AOS There are a list of recommended CloudWatch alarms to be set up for Amazon OpenSearch Service. For example, to sent an email if the cluster health status is red for longer than one minute. Customer can choose to deploy an Alarm stack with one click to set up alarms in AWS. Below is the high level architecture diagram: Info This stack can be deployed indepentdantly without the UI, check more details about the CloudFormation Design The process is described as below: CloudWatch Alarm to monitor Amazon OpenSearch service and send state change event to Amazon EventBridge Amazon EventBridge rule to trigger and send information to Amazon SNS as target Amazon SNS uses Email as subscription and notifies Administrators","title":"High-Level Architecture"},{"location":"designs/domain-management/component-design/#process-design","text":"This components includes a list of processes for domain management. For details about how the processes are designed, please refer to Process Design","title":"Process Design"},{"location":"designs/domain-management/component-design/#api-design","text":"This solution uses GraphQL APIs built on AWS Appsync service. For details about how the backend APIs are designed, please refer to API Design","title":"API Design"},{"location":"designs/domain-management/component-design/#data-model-design","text":"This component uses Amazon DynamoDB as the backend NoSQL database to store the information about AOS domains. To learn more information about how the data model is designed, please refer to Data Model Design","title":"Data Model Design"},{"location":"designs/domain-management/component-design/#cloudformation-design","text":"Proxy for AOS CloudFormation Design The parameters in the CloudFormation template are listed as below: Parameter Default Description VPCId <Requires input> The VPC to deploy the Nginx proxy resources, for example, vpc-bef13dc7 . PublicSubnetIds <Requires input> The public subnets where ELB are deployed. You need to select at least two public subnets, for example, subnet-12345abc, subnet-54321cba . ELBSecurityGroupId <Requires input> The Security group being associated with the ELB, for example, sg-123456 . ELBDomain <Requires input> The custom domain name of the ELB, for example, dashboard.example.com . ELBDomainCertificateArn <Requires input> The SSL certificate ARN associated with the ELBDomain. The certificate must be created from [Amazon Certificate Manager (ACM)][acm]. PrivateSubnetIds <Requires input> The private subnets where Nginx instances are deployed. You need to select at least two private subnets, for example, subnet-12345abc, subnet-54321cba . NginxSecurityGroupId <Requires input> The Security group associated with the Nginx instances. The security group must allow access from ELB security group. KeyName <Requires input> The PEM key name of the Nginx instances. EngineType OpenSearch The engine type of the OpenSearch. Select OpenSearch or Elasticsearch. Endpoint <Requires input> The OpenSearch endpoint, for example, vpc-your_opensearch_domain_name-xcvgw6uu2o6zafsiefxubwuohe.us-east-1.es.amazonaws.com . CognitoEndpoint <Optional> The Cognito User Pool endpoint URL of the OpenSearch domain, for example, mydomain.auth.us-east-1.amazoncognito.com . Leave empty if your OpenSearch domain is not authenticated through Cognito User Pool. Alarm for AOS CloudFormation Design The parameters in the CloudFormation template are listed as below: Parameter Default Description Endpoint <Requires input> The endpoint of the OpenSearch domain, for example, vpc-your_opensearch_domain_name-xcvgw6uu2o6zafsiefxubwuohe.us-east-1.es.amazonaws.com . DomainName <Requires input> The name of the OpenSearch domain. Email <Requires input> The notification email address. Alarms will be sent to this email address via SNS. ClusterStatusRed Yes Whether to enable alarm when at least one primary shard and its replicas are not allocated to a node. ClusterStatusYellow Yes Whether to enable alarm when at least one replica shard is not allocated to a node. FreeStorageSpace 10 Whether to enable alarm when a node in your cluster is down to the free storage space you typed in GiB. We recommend setting it to 25% of the storage space for each node. 0 means the alarm is disabled. ClusterIndexWritesBlocked 1 Index writes blocked error occurs for >= x times in 5 minutes, 1 consecutive time. Input 0 to disable this alarm. UnreachableNodeNumber 3 Nodes minimum is < x for 1 day, 1 consecutive time. 0 means the alarm is disabled. AutomatedSnapshotFailure Yes Whether to enable alarm when automated snapshot failed. AutomatedSnapshotFailure maximum is >= 1 for 1 minute, 1 consecutive time. CPUUtilization Yes Whether to enable alarm when sustained high usage of CPU occurred. CPUUtilization or WarmCPUUtilization maximum is >= 80% for 15 minutes, 3 consecutive times. JVMMemoryPressure Yes Whether to enable alarm when JVM RAM usage peak occurred. JVMMemoryPressure or WarmJVMMemoryPressure maximum is >= 80% for 5 minutes, 3 consecutive times. MasterCPUUtilization Yes Whether to enable alarm when sustained high usage of CPU occurred in master nodes. MasterCPUUtilization maximum is >= 50% for 15 minutes, 3 consecutive times. MasterJVMMemoryPressure Yes Whether to enable alarm when JVM RAM usage peak occurred in master nodes. MasterJVMMemoryPressure maximum is >= 80% for 15 minutes, 1 consecutive time. KMSKeyError Yes Whether to enable alarm when KMS encryption key is disabled. KMSKeyError is >= 1 for 1 minute, 1 consecutive time. KMSKeyInaccessible Yes Whether to enable alarm when KMS encryption key has been deleted or has revoked its grants to OpenSearch Service. KMSKeyInaccessible is >= 1 for 1 minute, 1 consecutive time.","title":"CloudFormation Design"},{"location":"designs/domain-management/data-model-design/","text":"Domain Management Data Model Design Overview This component uses Amazon DynamoDB as the backend NoSQL database. This document is about the Data Model Design for Domain Management component. To learn more information about the component, refer to Component Design Cluster Table Cluster table is used to store basic information on imported AOS domain. The data attributes are listed as below: Attribute name Type Example Description Comments id String 439239da8014f9a419c92b1b0c72a5fc MD5 of OpenSearch domain ARN Partition key version String 1.0 OpenSearch Version engine String OpenSearch Either OpenSearch or Elasticsearch region String us-east-1 AWS region endpoint String vpc-dev-i5jwvhie5lzhsfvnxapny.us-east-1.es.amazonaws.com OpenSearch Endpoint domainArn String arn:aws:es:us-east-1:123456789012:domain/dev OpenSearch domain ARN domainName String dev OpenSearch domain name importedDt String 2021-12-20T05:37:20.523951 Date of import proxyStatus String ENABLED OpenSearch Proxy stack status proxyALB String LogHu-LoadB-1T8YLOO675OCN-1782845820.us-east-1.elb.amazonaws.com ELB url for OpenSearch Proxy stack proxyStackId String arn:aws:cloudformation:us-east-1:123456789012:stack/LogHub-Proxy-14682/1b492000-615e-11ec-b5e4-1213fdb3e837 OpenSearch Proxy stack ID proxyInput Map {...} Parameters used when deploy a proxy stack for OpenSearch proxyError String Error messages when deploy a proxy stack for OpenSearch alarmStatus String DISABLED OpenSearch Alarm stack status vpc Map {...} Processing layer VPC when importing domain tags List [{...}] Custom Tags","title":"Data Model Design"},{"location":"designs/domain-management/data-model-design/#domain-management-data-model-design","text":"","title":"Domain Management Data Model Design"},{"location":"designs/domain-management/data-model-design/#overview","text":"This component uses Amazon DynamoDB as the backend NoSQL database. This document is about the Data Model Design for Domain Management component. To learn more information about the component, refer to Component Design","title":"Overview"},{"location":"designs/domain-management/data-model-design/#cluster-table","text":"Cluster table is used to store basic information on imported AOS domain. The data attributes are listed as below: Attribute name Type Example Description Comments id String 439239da8014f9a419c92b1b0c72a5fc MD5 of OpenSearch domain ARN Partition key version String 1.0 OpenSearch Version engine String OpenSearch Either OpenSearch or Elasticsearch region String us-east-1 AWS region endpoint String vpc-dev-i5jwvhie5lzhsfvnxapny.us-east-1.es.amazonaws.com OpenSearch Endpoint domainArn String arn:aws:es:us-east-1:123456789012:domain/dev OpenSearch domain ARN domainName String dev OpenSearch domain name importedDt String 2021-12-20T05:37:20.523951 Date of import proxyStatus String ENABLED OpenSearch Proxy stack status proxyALB String LogHu-LoadB-1T8YLOO675OCN-1782845820.us-east-1.elb.amazonaws.com ELB url for OpenSearch Proxy stack proxyStackId String arn:aws:cloudformation:us-east-1:123456789012:stack/LogHub-Proxy-14682/1b492000-615e-11ec-b5e4-1213fdb3e837 OpenSearch Proxy stack ID proxyInput Map {...} Parameters used when deploy a proxy stack for OpenSearch proxyError String Error messages when deploy a proxy stack for OpenSearch alarmStatus String DISABLED OpenSearch Alarm stack status vpc Map {...} Processing layer VPC when importing domain tags List [{...}] Custom Tags","title":"Cluster Table"},{"location":"designs/domain-management/eks-auto-import/","text":"Automatically Import AOS Domain Process Overview This document is about the process design for Automatically Import AOS Domain method.","title":"Automatically Import AOS Domain Process"},{"location":"designs/domain-management/eks-auto-import/#automatically-import-aos-domain-process","text":"","title":"Automatically Import AOS Domain Process"},{"location":"designs/domain-management/eks-auto-import/#overview","text":"This document is about the process design for Automatically Import AOS Domain method.","title":"Overview"},{"location":"designs/domain-management/process-design/","text":"Domain Management Process Design Overview This document is about the Process Design for Domain Management component. To learn more information about the component, refer to Component Design Domain Management Process Import Domain This operation is to import an existing AOS domain into Log Hub solution to ingest logs to. The process to import domain is described in below diagram: Design consideration: Store AOS information in DynamoDB. When a domain is imported, basic domain information is stored in Cluster table in DynamoDB. Consider only information that can not/might not be changed, such as endpoint, vpc etc. Other information such as EBS volume, Node information can be resized hence is derived via OpenSearch SDK on demand. Solution specified information such as processing layer vpc, tags is also stored in Cluster table. The domain metrics such as free storage are also not stored in Cluster table, as they are changing all the time. Domain ID design Considering that we will support cross account and cross region log ingestion in future, the unique domain ID (partition key in DynamoDB table) must support this. In this solution, we use MD5 of the domain ARN as the domain ID (Assumption is that it's unlikely that two different domain ARNs can have the same MD5 string) Exception handling When a domain is deleting or creating, or a domain is with public network, the import must fail with expection. When importing a domain that is already imported, the import should fail. To avoid such case happening, from frontend, when customer choose from a drop down list of OpenSearch domains, imported domains are excluded from the list. When a domain is already imported and then deleted. the list should not fail. References: Import Domain API Cluster Table Remove Domain This operation is to remove an imported AOS domain from Log Hub rather than deleting the AOS domain. The process to remove domain is described in below diagram: Design consideration: Delete process Deleting an imported domain only removes the item from Cluster table in DynamoDB. The backend OpenSearch domain will not be affected. Also deleting domain will not impact any existing log ingestion pipelines. There is no need to implement soft delete for this process. Customer can easily re-import the domain as needed. References: Remove Domain API Cluster Table List Imported Domains This operation is to support listing of all the imported domain along with key metrics (Cluster Health, Free Storage Space, Searchable documents). The process to import domain is described in below diagram: Design consideration: Where to get AOS metrics There are two ways of getting AOS domain metrics such as free storage space, domain health etc. One is to use AOS REST API such as GET _cluster/health , the other is to query in CloudWatch metrics. In this design, CloudWatch metrics are chosen to get domain metrics for two reasons: a) The API backend Lambda doesn't need to have VPC access. b) The CloudWatch metric data is same as what is shown in the AWS Management console. Not all calls need metrics Getting metrics from CloudWatch takes time and bring extra costs. But not all the listing scenerios requires metrics, For example, when customer is choosing an imported domain as a destionation from a list. So an option to choose whether to include metrics is provided. References: List Imported Domains API Cluster Table Get Domain Details This operation is to provide more details about an imported AOS domain, including nodes, volumes, networks etc. The process to Get domain details is described in below diagram: Design consideration: Same as List Imported Domain References: Get Domain Details API Cluster Table Proxy for AOS This operation is to provide a proxy to access OpenSearch dashboards which is within VPC. The process to Create/Delete Proxy for AOS Domain is described in below diagram: Design consideration: Step Functions Design Use an independent CloudFormation stack to provision resources (such as EC2, ELB etc.) for proxy stacks. Create a reusable Child step function flow for orchestrating the deployment/delete of the sub-stack. When create/delete proxy is triggerred, a parent flow will trigger the child flow to run, and once child flow is completed, the parent flow will be informed will the result and update the status in Cluster table. Store Proxy information in DynamoDB. Store the related parameter key-values of proxy stack in cluster table in DynamoDB. When the proxy is created, the stack id is stored in the table as the stack id is required in order to delete the proxy stack. References: Create Proxy for AOS API Delete Proxy for AOS API Cluster Table Alarm for AOS This operation is to quicly create recommended CloudAlarms to monitor AOS. An email notification will be triggered for alarm. The process to Create/Delete Alarm for AOS Domain is described in below diagram: Design consideration: Step Functions Design Use an independent CloudFormation stack to provision resources (such as CloudWatch alarms, SNS topic etc.) for alarm stacks. Create a reusable Child step function flow for orchestrating the deployment/delete of the sub-stack. When create/delete alarm is triggerred, a parent flow will trigger the child flow to run, and once child flow is completed, the parent flow will be informed will the result and update the status in Cluster table. Store Proxy information in DynamoDB. Store the related parameter key-values of proxy stack in cluster table in DynamoDB. When the alarm is created, the stack id is stored in the table as the stack id is required in order to delete the alarm stack. References: Create Alarm for AOS API Delete Alarm for AOS API Cluster Table","title":"Process Design"},{"location":"designs/domain-management/process-design/#domain-management-process-design","text":"","title":"Domain Management Process Design"},{"location":"designs/domain-management/process-design/#overview","text":"This document is about the Process Design for Domain Management component. To learn more information about the component, refer to Component Design","title":"Overview"},{"location":"designs/domain-management/process-design/#domain-management-process","text":"","title":"Domain Management Process"},{"location":"designs/domain-management/process-design/#import-domain","text":"This operation is to import an existing AOS domain into Log Hub solution to ingest logs to. The process to import domain is described in below diagram: Design consideration: Store AOS information in DynamoDB. When a domain is imported, basic domain information is stored in Cluster table in DynamoDB. Consider only information that can not/might not be changed, such as endpoint, vpc etc. Other information such as EBS volume, Node information can be resized hence is derived via OpenSearch SDK on demand. Solution specified information such as processing layer vpc, tags is also stored in Cluster table. The domain metrics such as free storage are also not stored in Cluster table, as they are changing all the time. Domain ID design Considering that we will support cross account and cross region log ingestion in future, the unique domain ID (partition key in DynamoDB table) must support this. In this solution, we use MD5 of the domain ARN as the domain ID (Assumption is that it's unlikely that two different domain ARNs can have the same MD5 string) Exception handling When a domain is deleting or creating, or a domain is with public network, the import must fail with expection. When importing a domain that is already imported, the import should fail. To avoid such case happening, from frontend, when customer choose from a drop down list of OpenSearch domains, imported domains are excluded from the list. When a domain is already imported and then deleted. the list should not fail. References: Import Domain API Cluster Table","title":"Import Domain"},{"location":"designs/domain-management/process-design/#remove-domain","text":"This operation is to remove an imported AOS domain from Log Hub rather than deleting the AOS domain. The process to remove domain is described in below diagram: Design consideration: Delete process Deleting an imported domain only removes the item from Cluster table in DynamoDB. The backend OpenSearch domain will not be affected. Also deleting domain will not impact any existing log ingestion pipelines. There is no need to implement soft delete for this process. Customer can easily re-import the domain as needed. References: Remove Domain API Cluster Table","title":"Remove Domain"},{"location":"designs/domain-management/process-design/#list-imported-domains","text":"This operation is to support listing of all the imported domain along with key metrics (Cluster Health, Free Storage Space, Searchable documents). The process to import domain is described in below diagram: Design consideration: Where to get AOS metrics There are two ways of getting AOS domain metrics such as free storage space, domain health etc. One is to use AOS REST API such as GET _cluster/health , the other is to query in CloudWatch metrics. In this design, CloudWatch metrics are chosen to get domain metrics for two reasons: a) The API backend Lambda doesn't need to have VPC access. b) The CloudWatch metric data is same as what is shown in the AWS Management console. Not all calls need metrics Getting metrics from CloudWatch takes time and bring extra costs. But not all the listing scenerios requires metrics, For example, when customer is choosing an imported domain as a destionation from a list. So an option to choose whether to include metrics is provided. References: List Imported Domains API Cluster Table","title":"List Imported Domains"},{"location":"designs/domain-management/process-design/#get-domain-details","text":"This operation is to provide more details about an imported AOS domain, including nodes, volumes, networks etc. The process to Get domain details is described in below diagram: Design consideration: Same as List Imported Domain References: Get Domain Details API Cluster Table","title":"Get Domain Details"},{"location":"designs/domain-management/process-design/#proxy-for-aos","text":"This operation is to provide a proxy to access OpenSearch dashboards which is within VPC. The process to Create/Delete Proxy for AOS Domain is described in below diagram: Design consideration: Step Functions Design Use an independent CloudFormation stack to provision resources (such as EC2, ELB etc.) for proxy stacks. Create a reusable Child step function flow for orchestrating the deployment/delete of the sub-stack. When create/delete proxy is triggerred, a parent flow will trigger the child flow to run, and once child flow is completed, the parent flow will be informed will the result and update the status in Cluster table. Store Proxy information in DynamoDB. Store the related parameter key-values of proxy stack in cluster table in DynamoDB. When the proxy is created, the stack id is stored in the table as the stack id is required in order to delete the proxy stack. References: Create Proxy for AOS API Delete Proxy for AOS API Cluster Table","title":"Proxy for AOS"},{"location":"designs/domain-management/process-design/#alarm-for-aos","text":"This operation is to quicly create recommended CloudAlarms to monitor AOS. An email notification will be triggered for alarm. The process to Create/Delete Alarm for AOS Domain is described in below diagram: Design consideration: Step Functions Design Use an independent CloudFormation stack to provision resources (such as CloudWatch alarms, SNS topic etc.) for alarm stacks. Create a reusable Child step function flow for orchestrating the deployment/delete of the sub-stack. When create/delete alarm is triggerred, a parent flow will trigger the child flow to run, and once child flow is completed, the parent flow will be informed will the result and update the status in Cluster table. Store Proxy information in DynamoDB. Store the related parameter key-values of proxy stack in cluster table in DynamoDB. When the alarm is created, the stack id is stored in the table as the stack id is required in order to delete the alarm stack. References: Create Alarm for AOS API Delete Alarm for AOS API Cluster Table","title":"Alarm for AOS"},{"location":"designs/eks-log/api-design/","text":"Overview APIs EKS Cluster as log source APIs This document is about API design of EKS cluster as log source component. list EKSCluster Names Type: Query Description: Display cluster names for all regions Resolver: Lambda Parameters: Name Type Required Default Description nextToken String No The token for pagination isListAll Boolean No false Whether to show EKS clusters in all regions Simple Request & Response: Request: query example{ listEKSClusterNames(nextToken: \"\", isListAll: false) { clusters nextToken } } Response: { \"data\": { \"listEKSClusterNames\": { \"clusters\": [ \"eks-demo\", \"loghub\" ], \"nextToken\": null } } } list imported EKS Clusters Type: Query Description: List imported EKS cluster Resolver: Lambda Parameters: Name Type Required Default Description count Int No 10 page number, start from 1 page Int No 1 number of records per page Simple Request & Response: Request: query example{ listImportedEKSClusters(count: 10, page: 1) { eksClusterLogSourceList { accountId vpcId subnetIds region oidcIssuer logAgentRoleArn id endpoint eksClusterSGId eksClusterName eksClusterArn deploymentKind cri createdDt tags { key value } aosDomain { version id engine endpoint domainName } } } } Response: { \"data\": { \"listImportedEKSClusters\": { \"eksClusterLogSourceList\": [ { \"accountId\": null, \"vpcId\": \"vpc-f4d05e8c\", \"subnetIds\": [ \"subnet-96816bcb\", \"subnet-3dabc916\", \"subnet-9b948ce2\", \"subnet-a4cecbef\" ], \"region\": null, \"oidcIssuer\": \"https://oidc.eks.us-west-2.amazonaws.com/id/20E13C86999BBFC25EC76C826CFFF4FB\", \"logAgentRoleArn\": \"arn:aws:iam::783732175206:role/LogHub-EKS-LogAgent-Role-a2a5b0643c4c472abd3dacfdbf9e1463\", \"id\": \"1d431ccd7caa4c90af0d86193bf78f9a\", \"endpoint\": \"https://20E13C86999BBFC25EC76C826CFFF4FB.yl4.us-west-2.eks.amazonaws.com\", \"eksClusterSGId\": \"sg-02b491dce426c1995\", \"eksClusterName\": \"eks-demo\", \"eksClusterArn\": \"arn:aws:eks:us-west-2:783732175206:cluster/eks-demo\", \"deploymentKind\": \"DaemonSet\", \"cri\": null, \"createdDt\": \"2022-04-03T16:34:02Z\", \"tags\": [], \"aosDomain\": { \"version\": \"1.0\", \"id\": \"a80137115e9ad59cf2a7137fe0e38197\", \"engine\": \"OpenSearch\", \"endpoint\": \"vpc-workshop-os-migdv4qrxbqdrp6mbfknyyagk4.us-west-2.es.amazonaws.com\", \"domainName\": \"workshop-os\" } } ] } } } Type: Query Description: Display DaemonSet configuration by the EKS Cluster log source Id Resolver: Lambda Parameters: Name Type Required Default Description eksClusterId String Yes log source id for the imported EKS Cluster Simple Request & Response: Request: query example{ getEKSDaemonSetConfig( eksClusterId: \"1d431ccd7caa4c90af0d86193bf78f9a\" ) } Response: { \"data\": { \"getEKSDaemonSetConfig\": \"\" } } Type: Query Description: Display deployment configuration by the EKS Cluster log source Id Resolver: Lambda Parameters: Name Type Required Default Description eksClusterId String Yes log source id for the imported EKS Cluster ingestionId String Yes the Id for application log ingestion Simple Request & Response: Request: query example{ getEKSDeploymentConfig( eksClusterId: \"1d431ccd7caa4c90af0d86193bf78f9a\", ingestionId: \"2d43abe07caa4c90af0d8619323064\" ) } Response: { \"data\": { \"getEKSDeploymentConfig\": \"\" } } Import a EKS Cluster as application log source Type: Mutation Description: Create a record in DynamoDB Resolver: Lambda Parameters: Name Type Required Default Description aosDomainId String Yes The imported AOS domain id. deploymentKind String Yes The deployment type fo the log agent, DaemonSet or SideCar eksClusterName enum Yes The imported EKS cluster name. accountId enum No The account id corresponding to the imported EKS cluster. cri String No K8s container runtime. region String No The region name corresponding to the imported EKS cluster. tags K-V No Tag the EKS Cluster log source. Simple Request & Response: query example{ importEKSCluster( aosDomainId: \"7d43abe07ebb4c90af0d8619328054\", deploymentKind: \"DaemonSet\", eksClusterName: \"eks-demo-cluster\", accountId: \"20599832\", cri: \"containerd\", region: \"us-west-2\", tags: { key: \"evn\", value: \"Testing\" } ) } Response: { \"data\": { \"importEKSCluster\": \"OK\" } } Create a EKS cluster pod Log ingestion Type: Mutation Description: Create a record in DynamoDB. Resolver: Lambda Parameters: Name Type Required Default Description eksClusterId String Yes EKS cluster log source Unique ID confId String Yes Log Config Unique ID aosParas K-V Yes Selected Amazonn OpenSearch related parameters. kdsParas K-V Yes Created Kinesis Data Stream related parameters. tags K-V No Custom tags for the ingestion Simple Request & Response: Request: mutation example{ createEKSClusterPodLogIngestion( aosParas: { opensearchArn: \"arn:aws:es:us-west-2:783732175206:domain/workshop-os\", domainName: \"workshop-os\", opensearchEndpoint: \"vpc-workshop-os-migdv4qrxbqdrp6mbfknyyagk4.us-west-2.es.amazonaws.com\", indexPrefix: \"nginx-log\", warmLogTransition: 0, coldLogTransition: 0, logRetention: 0, engine: \"OpenSearch\", vpc: { vpcId: \"vpc-0c111322ef4a52f41\", securityGroupId: \"sg-0ae9e8d70d31b40d0\", privateSubnetIds: \"subnet-069c0ff066cca88cf,subnet-05839e25db2e70d8f\", publicSubnetIds: \"\" }, engine: \"OpenSearch\", opensearchArn: \"arn:aws:es:us-west-2:783732175206:domain/workshop-os\", opensearchEndpoint: \"vpc-workshop-os-migdv4qrxbqdrp6mbfknyyagk4.us-west-2.es.amazonaws.com\" }, kdsParas: { enableAutoScaling: true, maxShardNumber: 10 startShardNumber: 2 }, confId: \"deebad45-c4ad-4346-9b4e-b56f635b5c31\", eksClusterId: \"1d431ccd7caa4c90af0d86193bf78f9a\", tags: { key: \"env\", value: \"testing\" } ) } Response: { \"data\": { \"createEKSClusterPodLogIngestion\":\"1bcaedaa-1f94-4d3d-9b50-9592a0fc6d32\" } }","title":"API Design"},{"location":"designs/eks-log/api-design/#overview","text":"","title":"Overview"},{"location":"designs/eks-log/api-design/#apis","text":"","title":"APIs"},{"location":"designs/eks-log/api-design/#eks-cluster-as-log-source-apis","text":"This document is about API design of EKS cluster as log source component.","title":"EKS Cluster as log source APIs"},{"location":"designs/eks-log/api-design/#list-ekscluster-names","text":"Type: Query Description: Display cluster names for all regions Resolver: Lambda Parameters: Name Type Required Default Description nextToken String No The token for pagination isListAll Boolean No false Whether to show EKS clusters in all regions Simple Request & Response: Request: query example{ listEKSClusterNames(nextToken: \"\", isListAll: false) { clusters nextToken } } Response: { \"data\": { \"listEKSClusterNames\": { \"clusters\": [ \"eks-demo\", \"loghub\" ], \"nextToken\": null } } }","title":"list EKSCluster Names"},{"location":"designs/eks-log/api-design/#list-imported-eks-clusters","text":"Type: Query Description: List imported EKS cluster Resolver: Lambda Parameters: Name Type Required Default Description count Int No 10 page number, start from 1 page Int No 1 number of records per page Simple Request & Response: Request: query example{ listImportedEKSClusters(count: 10, page: 1) { eksClusterLogSourceList { accountId vpcId subnetIds region oidcIssuer logAgentRoleArn id endpoint eksClusterSGId eksClusterName eksClusterArn deploymentKind cri createdDt tags { key value } aosDomain { version id engine endpoint domainName } } } } Response: { \"data\": { \"listImportedEKSClusters\": { \"eksClusterLogSourceList\": [ { \"accountId\": null, \"vpcId\": \"vpc-f4d05e8c\", \"subnetIds\": [ \"subnet-96816bcb\", \"subnet-3dabc916\", \"subnet-9b948ce2\", \"subnet-a4cecbef\" ], \"region\": null, \"oidcIssuer\": \"https://oidc.eks.us-west-2.amazonaws.com/id/20E13C86999BBFC25EC76C826CFFF4FB\", \"logAgentRoleArn\": \"arn:aws:iam::783732175206:role/LogHub-EKS-LogAgent-Role-a2a5b0643c4c472abd3dacfdbf9e1463\", \"id\": \"1d431ccd7caa4c90af0d86193bf78f9a\", \"endpoint\": \"https://20E13C86999BBFC25EC76C826CFFF4FB.yl4.us-west-2.eks.amazonaws.com\", \"eksClusterSGId\": \"sg-02b491dce426c1995\", \"eksClusterName\": \"eks-demo\", \"eksClusterArn\": \"arn:aws:eks:us-west-2:783732175206:cluster/eks-demo\", \"deploymentKind\": \"DaemonSet\", \"cri\": null, \"createdDt\": \"2022-04-03T16:34:02Z\", \"tags\": [], \"aosDomain\": { \"version\": \"1.0\", \"id\": \"a80137115e9ad59cf2a7137fe0e38197\", \"engine\": \"OpenSearch\", \"endpoint\": \"vpc-workshop-os-migdv4qrxbqdrp6mbfknyyagk4.us-west-2.es.amazonaws.com\", \"domainName\": \"workshop-os\" } } ] } } }","title":"list imported EKS Clusters"},{"location":"designs/eks-log/api-design/#_1","text":"Type: Query Description: Display DaemonSet configuration by the EKS Cluster log source Id Resolver: Lambda Parameters: Name Type Required Default Description eksClusterId String Yes log source id for the imported EKS Cluster Simple Request & Response: Request: query example{ getEKSDaemonSetConfig( eksClusterId: \"1d431ccd7caa4c90af0d86193bf78f9a\" ) } Response: { \"data\": { \"getEKSDaemonSetConfig\": \"\" } }","title":""},{"location":"designs/eks-log/api-design/#_2","text":"Type: Query Description: Display deployment configuration by the EKS Cluster log source Id Resolver: Lambda Parameters: Name Type Required Default Description eksClusterId String Yes log source id for the imported EKS Cluster ingestionId String Yes the Id for application log ingestion Simple Request & Response: Request: query example{ getEKSDeploymentConfig( eksClusterId: \"1d431ccd7caa4c90af0d86193bf78f9a\", ingestionId: \"2d43abe07caa4c90af0d8619323064\" ) } Response: { \"data\": { \"getEKSDeploymentConfig\": \"\" } }","title":""},{"location":"designs/eks-log/api-design/#import-a-eks-cluster-as-application-log-source","text":"Type: Mutation Description: Create a record in DynamoDB Resolver: Lambda Parameters: Name Type Required Default Description aosDomainId String Yes The imported AOS domain id. deploymentKind String Yes The deployment type fo the log agent, DaemonSet or SideCar eksClusterName enum Yes The imported EKS cluster name. accountId enum No The account id corresponding to the imported EKS cluster. cri String No K8s container runtime. region String No The region name corresponding to the imported EKS cluster. tags K-V No Tag the EKS Cluster log source. Simple Request & Response: query example{ importEKSCluster( aosDomainId: \"7d43abe07ebb4c90af0d8619328054\", deploymentKind: \"DaemonSet\", eksClusterName: \"eks-demo-cluster\", accountId: \"20599832\", cri: \"containerd\", region: \"us-west-2\", tags: { key: \"evn\", value: \"Testing\" } ) } Response: { \"data\": { \"importEKSCluster\": \"OK\" } }","title":"Import a EKS Cluster as application log source"},{"location":"designs/eks-log/api-design/#create-a-eks-cluster-pod-log-ingestion","text":"Type: Mutation Description: Create a record in DynamoDB. Resolver: Lambda Parameters: Name Type Required Default Description eksClusterId String Yes EKS cluster log source Unique ID confId String Yes Log Config Unique ID aosParas K-V Yes Selected Amazonn OpenSearch related parameters. kdsParas K-V Yes Created Kinesis Data Stream related parameters. tags K-V No Custom tags for the ingestion Simple Request & Response: Request: mutation example{ createEKSClusterPodLogIngestion( aosParas: { opensearchArn: \"arn:aws:es:us-west-2:783732175206:domain/workshop-os\", domainName: \"workshop-os\", opensearchEndpoint: \"vpc-workshop-os-migdv4qrxbqdrp6mbfknyyagk4.us-west-2.es.amazonaws.com\", indexPrefix: \"nginx-log\", warmLogTransition: 0, coldLogTransition: 0, logRetention: 0, engine: \"OpenSearch\", vpc: { vpcId: \"vpc-0c111322ef4a52f41\", securityGroupId: \"sg-0ae9e8d70d31b40d0\", privateSubnetIds: \"subnet-069c0ff066cca88cf,subnet-05839e25db2e70d8f\", publicSubnetIds: \"\" }, engine: \"OpenSearch\", opensearchArn: \"arn:aws:es:us-west-2:783732175206:domain/workshop-os\", opensearchEndpoint: \"vpc-workshop-os-migdv4qrxbqdrp6mbfknyyagk4.us-west-2.es.amazonaws.com\" }, kdsParas: { enableAutoScaling: true, maxShardNumber: 10 startShardNumber: 2 }, confId: \"deebad45-c4ad-4346-9b4e-b56f635b5c31\", eksClusterId: \"1d431ccd7caa4c90af0d86193bf78f9a\", tags: { key: \"env\", value: \"testing\" } ) } Response: { \"data\": { \"createEKSClusterPodLogIngestion\":\"1bcaedaa-1f94-4d3d-9b50-9592a0fc6d32\" } }","title":"Create a EKS cluster pod Log ingestion"},{"location":"designs/eks-log/architecture-design/","text":"EKS Cluster Log Analytics Design Overview Considering that there are many types of logs in EKS, and different types of logs have different collection sources. But in general, it can be divided into three ways: The first type of logs is Control plane logging, which includes Audit logs, API server logs, interfacing with CloudWatch, and Controller manager logs. Such logs need to be subscribed in the log group (/aws/eks/ /cluster) , transfer the newly generated log data to the KDS generated by Log Hub EKS Cluster log Ingestion. We are currently working on Control plane logging. The second is the ELB type Ingress access log. If your ELB type is ALB, this part has been implemented in the Service Log component The last one is the application log in the EKS cluster and the system log on the Node (kube-proxy-XXX.log, aws-load-balancer-controller, aws-node- _kube-system_aws-vpc-cni- init-XXX.log, aws-node- _kube-system_aws-node-XXX.log, coredns-XXX.log). Regarding the use of Nginx as an Ingress, the Ingress access log generated is essentially an application log. Regarding such logs, we will collect the logs by deploying Fluent Bit as a log agent and send the logs to the data buffer created by Log Hub. System Architecture FAQ Q. What is the difference between the log pipeline of an EKS cluster and the log pipeline of an application? Considering whether the application is deployed in EC2 or EKS Cluster, there is usually no difference in the application log format, but the analysis methods for logs from different sources are still different. When we designed EKS Cluster log analysis, we abstracted the concept of ==log source== in the application log ingestion component. Therefore, EKS Cluster's log pipeline still uses the application log pipeline. When an EKS Cluster log pipeline is created, a log ingestion is created together Q. Which deployment mode does the logging agent support? Whether you choose the DaemonSet type or SideCar, the Log Hub supports\u3002 Q. Is the deployment of the log agent performed automatically by the system? We do not support fully automated deployment yet. Currently, the Log Hub will generate a Yaml file for deployment, so that you can make changes according to your actual scenarios. In the future we will do this through the Lambda with a Kubectl environment.","title":"Architecture Design"},{"location":"designs/eks-log/architecture-design/#eks-cluster-log-analytics-design","text":"","title":"EKS Cluster Log Analytics Design"},{"location":"designs/eks-log/architecture-design/#overview","text":"Considering that there are many types of logs in EKS, and different types of logs have different collection sources. But in general, it can be divided into three ways: The first type of logs is Control plane logging, which includes Audit logs, API server logs, interfacing with CloudWatch, and Controller manager logs. Such logs need to be subscribed in the log group (/aws/eks/ /cluster) , transfer the newly generated log data to the KDS generated by Log Hub EKS Cluster log Ingestion. We are currently working on Control plane logging. The second is the ELB type Ingress access log. If your ELB type is ALB, this part has been implemented in the Service Log component The last one is the application log in the EKS cluster and the system log on the Node (kube-proxy-XXX.log, aws-load-balancer-controller, aws-node- _kube-system_aws-vpc-cni- init-XXX.log, aws-node- _kube-system_aws-node-XXX.log, coredns-XXX.log). Regarding the use of Nginx as an Ingress, the Ingress access log generated is essentially an application log. Regarding such logs, we will collect the logs by deploying Fluent Bit as a log agent and send the logs to the data buffer created by Log Hub.","title":"Overview"},{"location":"designs/eks-log/architecture-design/#system-architecture","text":"","title":"System Architecture"},{"location":"designs/eks-log/architecture-design/#faq","text":"Q. What is the difference between the log pipeline of an EKS cluster and the log pipeline of an application? Considering whether the application is deployed in EC2 or EKS Cluster, there is usually no difference in the application log format, but the analysis methods for logs from different sources are still different. When we designed EKS Cluster log analysis, we abstracted the concept of ==log source== in the application log ingestion component. Therefore, EKS Cluster's log pipeline still uses the application log pipeline. When an EKS Cluster log pipeline is created, a log ingestion is created together Q. Which deployment mode does the logging agent support? Whether you choose the DaemonSet type or SideCar, the Log Hub supports\u3002 Q. Is the deployment of the log agent performed automatically by the system? We do not support fully automated deployment yet. Currently, the Log Hub will generate a Yaml file for deployment, so that you can make changes according to your actual scenarios. In the future we will do this through the Lambda with a Kubectl environment.","title":"FAQ"},{"location":"designs/eks-log/process-design/","text":"EKS Cluster Log Analytics Process This document is about the Process Design for Import EKS Cluster, Create EKS Cluster Log Pipeline and Ingestion . Overview Import an EKS Cluster Collect Control plane logging Request to create pipeline and ingestion for collecting EKS cluster application logs Sequence diagram: Request to create pipeline Sequence diagram: The StepFunction Process Sequence diagram: Create an ingested from an existing pipeline","title":"Process Design"},{"location":"designs/eks-log/process-design/#eks-cluster-log-analytics-process","text":"This document is about the Process Design for Import EKS Cluster, Create EKS Cluster Log Pipeline and Ingestion .","title":"EKS Cluster Log Analytics Process"},{"location":"designs/eks-log/process-design/#overview","text":"","title":"Overview"},{"location":"designs/eks-log/process-design/#import-an-eks-cluster","text":"","title":"Import an EKS Cluster"},{"location":"designs/eks-log/process-design/#collect-control-plane-logging","text":"","title":"Collect Control plane logging"},{"location":"designs/eks-log/process-design/#request-to-create-pipeline-and-ingestion-for-collecting-eks-cluster-application-logs","text":"Sequence diagram: Request to create pipeline Sequence diagram: The StepFunction Process Sequence diagram: Create an ingested from an existing pipeline","title":"Request to create pipeline and ingestion for collecting EKS cluster application logs"},{"location":"designs/service-log/api-design/","text":"Service Log Pipeline API Design Overview This document is about the API Design for Service Log Pipeline component. To learn more information about the component, refer to Component Design Service Pipeline APIs Service Pipeline APIs are a list of operations to manage end to end Log analytics pipelines for AWS services. Create Service Pipeline Type: Mutation Description: Create a record in DynamoDB, start an execution of Step function, trigger CloudFormation template to run Resolver: Lambda Parameters: Name Type Required Default Description type String Yes Allowed values: S3AccessLog, CloudTrail, CloudFront parameters K-V Yes Source info (such as S3 bucket, prefix) tags K-V No Tag the pipeline Request: { createServicePipeline( Type: S3, source: \"aws-lambda-12843845950\", target: \"dev\", tags: [{key: \"Hello\", value: \"World\"}], parameters: [ {parameterKey: \"engineType\", parameterValue: \"OpenSearch\"}, {parameterKey: \"logBucketName\", parameterValue: \"loghub-loghubloggingbucket0fa53b76-1cf5iuchzpbz8\"}, {parameterKey: \"logBucketPrefix\", parameterValue: \"AWSLogs/347283850106/s3/aws-lambda-12843845950\"}, {parameterKey: \"endpoint\", parameterValue: \"vpc-dev-ardonphnbg327lwqncuj2vps3q.eu-west-1.es.amazonaws.com\"} {parameterKey: \"domainName\", parameterValue: \"dev\"}, {parameterKey: \"indexPrefix\", parameterValue: \"aws-lambda-12843845950\"}, {parameterKey: \"createDashboard\", parameterValue: \"Yes\"}, {parameterKey: \"vpcId\", parameterValue: \"vpc-0e172e182aa53806b\"}, {parameterKey: \"subnetIds\", parameterValue: \"subnet-09f0654b6db09eb23,subnet-0b873d0b6e73c2f9c\"}, {parameterKey: \"securityGroupId\", parameterValue: \"sg-0a55e5364049a5b1d\"}, {parameterKey: \"backupBucketName\", parameterValue: \"loghub-loghubloggingbucket0fa53b76-1cf5iuchzpbz8\"}, {parameterKey: \"daysToWarm\", parameterValue: \"0\"}, {parameterKey: \"daysToCold\", parameterValue: \"0\"}, {parameterKey: \"daysToRetain\", parameterValue: \"0\"} ]) } Response: { \"data\": { \"createServicePipeline\": \"24483703-41b6-43ba-aae3-19318bdb1b4e\" } } Delete Service Pipeline Type: Mutation Description: mask the record in DynamoDB as Inactive, start an execution of Step function, trigger CloudFormation template to delete Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Pipeline Unique ID in DynamodB Simple Request & Response: Request: mutation example { deleteServicePipeline(id: \"24483703-41b6-43ba-aae3-19318bdb1b4e\") } Response: { \"data\": { \"deleteServicePipeline\": \"OK\" } } List Service Pipelines Type: Query Description: List all pipelines Resolver: DynamoDB Parameters: Name Type Required Default Description page Int No 1 page number, start from 1 count String No 20 number of records per page Simple Request & Response: Request query example { listServicePipelines(page: 1, count: 20) { pipelines { createdDt id source status target type } total } } Response: { \"data\": { \"listServicePipelines\": { \"pipelines\": [ { \"createdDt\": \"2021-09-16T04:12:06.288536\", \"id\": \"f2272d96-5cb5-4eed-9d1e-bbe545cfa181\", \"source\": \"abc-bucket\", \"status\": \"ACTIVE\", \"target\": \"dev\", \"type\": \"S3\" }, { \"createdDt\": \"2021-09-16T04:12:04.216817\", \"id\": \"f2b845fa-be44-4b94-9912-e692d2bc270d\", \"source\": \"bcd-bucket\", \"status\": \"ERROR\", \"target\": \"dev\", \"type\": \"S3\" }, ... ], \"total\": 166 } } } Get Service Pipeline Type: Query Description: Get service pipeline detail by ID Resolver: DynamoDB Parameters: Name Type Required Default Description id String Yes Unique pipeline ID Simple Request & Response: Request query example { getServicePipeline(id: \"d3b88a26-38ab-430a-9b20-1dd009586e22\") { createdDt id parameters { parameterKey parameterValue } status tags { key value } type source target error } } Response: { \"data\": { \"getServicePipeline\": { \"createdDt\": \"21-12-09T07:54:17Z\", \"id\": \"d3b88a26-38ab-430a-9b20-1dd009586e22\", \"parameters\": [ { \"parameterKey\": \"engineType\", \"parameterValue\": \"OpenSearch\" }, { \"parameterKey\": \"logBucketName\", \"parameterValue\": \"loghub-loghubloggingbucket0fa53b76-1cf5iuchzpbz8\" }, { \"parameterKey\": \"logBucketPrefix\", \"parameterValue\": \"AWSLogs/347283850106/s3/aws-lambda-12843845950\" }, { \"parameterKey\": \"endpoint\", \"parameterValue\": \"vpc-dev-ardonphnbg327lwqncuj2vps3q.eu-west-1.es.amazonaws.com\" }, { \"parameterKey\": \"domainName\", \"parameterValue\": \"dev\" }, { \"parameterKey\": \"indexPrefix\", \"parameterValue\": \"aws-lambda-12843845950\" }, { \"parameterKey\": \"createDashboard\", \"parameterValue\": \"Yes\" }, { \"parameterKey\": \"vpcId\", \"parameterValue\": \"vpc-0e172e182aa53806b\" }, { \"parameterKey\": \"subnetIds\", \"parameterValue\": \"subnet-09f0654b6db09eb23,subnet-0b873d0b6e73c2f9c\" }, { \"parameterKey\": \"securityGroupId\", \"parameterValue\": \"sg-0a55e5364049a5b1d\" }, { \"parameterKey\": \"backupLogBucketName\", \"parameterValue\": \"loghub-loghubloggingbucket0fa53b76-1cf5iuchzpbz8\" }, { \"parameterKey\": \"daysToWarm\", \"parameterValue\": \"0\" }, { \"parameterKey\": \"daysToCold\", \"parameterValue\": \"0\" }, { \"parameterKey\": \"daysToRetain\", \"parameterValue\": \"0\" } ], \"status\": \"ERROR\", \"tags\": [ { \"key\": \"Hello\", \"value\": \"World\" } ], \"type\": \"S3\", \"source\": \"aws-lambda-12843845950\", \"target\": \"dev\", \"error\": \"An error occurred (ValidationError) when calling the CreateStack operation: Parameters: [failedLogBucket] must have values\" } } }","title":"API Design"},{"location":"designs/service-log/api-design/#service-log-pipeline-api-design","text":"","title":"Service Log Pipeline API Design"},{"location":"designs/service-log/api-design/#overview","text":"This document is about the API Design for Service Log Pipeline component. To learn more information about the component, refer to Component Design","title":"Overview"},{"location":"designs/service-log/api-design/#service-pipeline-apis","text":"Service Pipeline APIs are a list of operations to manage end to end Log analytics pipelines for AWS services.","title":"Service Pipeline APIs"},{"location":"designs/service-log/api-design/#create-service-pipeline","text":"Type: Mutation Description: Create a record in DynamoDB, start an execution of Step function, trigger CloudFormation template to run Resolver: Lambda Parameters: Name Type Required Default Description type String Yes Allowed values: S3AccessLog, CloudTrail, CloudFront parameters K-V Yes Source info (such as S3 bucket, prefix) tags K-V No Tag the pipeline Request: { createServicePipeline( Type: S3, source: \"aws-lambda-12843845950\", target: \"dev\", tags: [{key: \"Hello\", value: \"World\"}], parameters: [ {parameterKey: \"engineType\", parameterValue: \"OpenSearch\"}, {parameterKey: \"logBucketName\", parameterValue: \"loghub-loghubloggingbucket0fa53b76-1cf5iuchzpbz8\"}, {parameterKey: \"logBucketPrefix\", parameterValue: \"AWSLogs/347283850106/s3/aws-lambda-12843845950\"}, {parameterKey: \"endpoint\", parameterValue: \"vpc-dev-ardonphnbg327lwqncuj2vps3q.eu-west-1.es.amazonaws.com\"} {parameterKey: \"domainName\", parameterValue: \"dev\"}, {parameterKey: \"indexPrefix\", parameterValue: \"aws-lambda-12843845950\"}, {parameterKey: \"createDashboard\", parameterValue: \"Yes\"}, {parameterKey: \"vpcId\", parameterValue: \"vpc-0e172e182aa53806b\"}, {parameterKey: \"subnetIds\", parameterValue: \"subnet-09f0654b6db09eb23,subnet-0b873d0b6e73c2f9c\"}, {parameterKey: \"securityGroupId\", parameterValue: \"sg-0a55e5364049a5b1d\"}, {parameterKey: \"backupBucketName\", parameterValue: \"loghub-loghubloggingbucket0fa53b76-1cf5iuchzpbz8\"}, {parameterKey: \"daysToWarm\", parameterValue: \"0\"}, {parameterKey: \"daysToCold\", parameterValue: \"0\"}, {parameterKey: \"daysToRetain\", parameterValue: \"0\"} ]) } Response: { \"data\": { \"createServicePipeline\": \"24483703-41b6-43ba-aae3-19318bdb1b4e\" } }","title":"Create Service Pipeline"},{"location":"designs/service-log/api-design/#delete-service-pipeline","text":"Type: Mutation Description: mask the record in DynamoDB as Inactive, start an execution of Step function, trigger CloudFormation template to delete Resolver: Lambda Parameters: Name Type Required Default Description id String Yes Pipeline Unique ID in DynamodB Simple Request & Response: Request: mutation example { deleteServicePipeline(id: \"24483703-41b6-43ba-aae3-19318bdb1b4e\") } Response: { \"data\": { \"deleteServicePipeline\": \"OK\" } }","title":"Delete Service Pipeline"},{"location":"designs/service-log/api-design/#list-service-pipelines","text":"Type: Query Description: List all pipelines Resolver: DynamoDB Parameters: Name Type Required Default Description page Int No 1 page number, start from 1 count String No 20 number of records per page Simple Request & Response: Request query example { listServicePipelines(page: 1, count: 20) { pipelines { createdDt id source status target type } total } } Response: { \"data\": { \"listServicePipelines\": { \"pipelines\": [ { \"createdDt\": \"2021-09-16T04:12:06.288536\", \"id\": \"f2272d96-5cb5-4eed-9d1e-bbe545cfa181\", \"source\": \"abc-bucket\", \"status\": \"ACTIVE\", \"target\": \"dev\", \"type\": \"S3\" }, { \"createdDt\": \"2021-09-16T04:12:04.216817\", \"id\": \"f2b845fa-be44-4b94-9912-e692d2bc270d\", \"source\": \"bcd-bucket\", \"status\": \"ERROR\", \"target\": \"dev\", \"type\": \"S3\" }, ... ], \"total\": 166 } } }","title":"List Service Pipelines"},{"location":"designs/service-log/api-design/#get-service-pipeline","text":"Type: Query Description: Get service pipeline detail by ID Resolver: DynamoDB Parameters: Name Type Required Default Description id String Yes Unique pipeline ID Simple Request & Response: Request query example { getServicePipeline(id: \"d3b88a26-38ab-430a-9b20-1dd009586e22\") { createdDt id parameters { parameterKey parameterValue } status tags { key value } type source target error } } Response: { \"data\": { \"getServicePipeline\": { \"createdDt\": \"21-12-09T07:54:17Z\", \"id\": \"d3b88a26-38ab-430a-9b20-1dd009586e22\", \"parameters\": [ { \"parameterKey\": \"engineType\", \"parameterValue\": \"OpenSearch\" }, { \"parameterKey\": \"logBucketName\", \"parameterValue\": \"loghub-loghubloggingbucket0fa53b76-1cf5iuchzpbz8\" }, { \"parameterKey\": \"logBucketPrefix\", \"parameterValue\": \"AWSLogs/347283850106/s3/aws-lambda-12843845950\" }, { \"parameterKey\": \"endpoint\", \"parameterValue\": \"vpc-dev-ardonphnbg327lwqncuj2vps3q.eu-west-1.es.amazonaws.com\" }, { \"parameterKey\": \"domainName\", \"parameterValue\": \"dev\" }, { \"parameterKey\": \"indexPrefix\", \"parameterValue\": \"aws-lambda-12843845950\" }, { \"parameterKey\": \"createDashboard\", \"parameterValue\": \"Yes\" }, { \"parameterKey\": \"vpcId\", \"parameterValue\": \"vpc-0e172e182aa53806b\" }, { \"parameterKey\": \"subnetIds\", \"parameterValue\": \"subnet-09f0654b6db09eb23,subnet-0b873d0b6e73c2f9c\" }, { \"parameterKey\": \"securityGroupId\", \"parameterValue\": \"sg-0a55e5364049a5b1d\" }, { \"parameterKey\": \"backupLogBucketName\", \"parameterValue\": \"loghub-loghubloggingbucket0fa53b76-1cf5iuchzpbz8\" }, { \"parameterKey\": \"daysToWarm\", \"parameterValue\": \"0\" }, { \"parameterKey\": \"daysToCold\", \"parameterValue\": \"0\" }, { \"parameterKey\": \"daysToRetain\", \"parameterValue\": \"0\" } ], \"status\": \"ERROR\", \"tags\": [ { \"key\": \"Hello\", \"value\": \"World\" } ], \"type\": \"S3\", \"source\": \"aws-lambda-12843845950\", \"target\": \"dev\", \"error\": \"An error occurred (ValidationError) when calling the CreateStack operation: Parameters: [failedLogBucket] must have values\" } } }","title":"Get Service Pipeline"},{"location":"designs/service-log/component-design/","text":"Service Log Pipeline Component Design Overview Service Log Analytics Pipeline, as one component of Log Hub solution, is used to collect logs for AWS services, process and ingest into Amazon OpenSearch Service (AOS). This document is to describe this component is designed. Currently, this solution supports S3 Access Logs, CloudTrail Logs, ELB Logs, CloudFront Logs, RDS Logs, WAF Logs, Lambda Logs. To learn how to extend this solution to support more service logs, please check Tutorial: Extend Service Logs Info For more information about solution overall design, refer to High Level Design . Component Design High-Level Architecture Based on different log destinations , Different architectures are used. Destination on Amazon S3 Normally the logs on Amazon S3 are not for real-time analysis. Currently, this solution supports CloudTrail logs, CloudFront Standard logs, Amazon S3 Access logs, Elastic Load Balancing (ELB) logs, VPC Flow logs, and Amazon Config logs. The process is described as below: AWS Services store logs on Amazon S3 bucket A notification is sent to Amazon SQS when new log file is created Amazon SQS triggers the Lambda (Log processor) to run The Log processor read and processes the log file and ingest the logs into Amazon OpenSearch service. For cross-account log ingestion, the AWS Services store logs on Amazon S3 bucket in one account, and other resources remain in Log Hub's Account: Destination on CloudWatch Logs Some services can only choose Amazon CloudWatch Log Group as destination. Currently, this solution supports RDS logs and Lambda Logs The process is described as below: AWS Services store logs on Amazon CloudWatch log group The CloudWatch logs is streaming to Amazon Kinesis Data Stream (KDS) via subscription. KDS triggers the Lambda (Log processor) to run The Log processor read and processes the log records and ingest the logs into Amazon OpenSearch service. For cross-account log ingestion, the AWS Services store logs on Amazon CloudWatch log group in one account, and other resources remain in Log Hub's Account: Process Design To learn more information about how the detail process are designed, please refer to Process Design API Design A list of GraphQL APIs are built on AWS Appsync service to support service pipeline management from Log Hub Web Console. To learn more information about how the backend APIs are designed, please refer to API Design Data Model Design This component uses Amazon DynamoDB as the backend NoSQL database to store information about the service log pipelines. To learn more information about how the data model is designed, please refer to Data Model Design CloudFormation Design This component can be launched independently via CloudFormation without the Solution Web Console (UI). The parameters in the CloudFormation template are listed as below: Parameter Default Description Log Bucket Name <Requires input> The S3 bucket name which stores the service logs. Log Bucket Prefix <Requires input> The S3 bucket path prefix which stores the service logs. Engine Type OpenSearch The engine type of the OpenSearch. Select OpenSearch or Elasticsearch. OpenSearch Domain Name <Requires input> The domain name of the Amazon OpenSearch cluster. OpenSearch Endpoint <Requires input> The OpenSearch endpoint URL. e.g. vpc-your_opensearch_domain_name-xcvgw6uu2o6zafsiefxubwuohe.us-east-1.es.amazonaws.com Index Prefix <requires input> The common prefix of OpenSearch index for the log. The index name will be -elb- . Create Sample Dashboard Yes Whether to create a sample OpenSearch dashboard. VPC ID <requires input> Select a VPC which has access to the OpenSearch domain. The log processing Lambda will be resides in the selected VPC. Subnet IDs <requires input> Select at leasts two subnets which has access to the OpenSearch domain. The log processing Lambda will resides in the subnets. Please make sure the subnets has access to the Amazon S3 service. Security Group ID <requires input> Select a Security Group which will be associated to the log processing Lambda. Please make sure the Security Group has access to the OpenSearch domain. Number Of Shards 5 Number of shards to distribute the index evenly across all data nodes, keep the size of each shard between 10-50 GiB. Number of Replicas 1 The number of days required to move the index into warm storage, this is only effecitve when the value is >0 and warm storage is enabled in OpenSearch. Days to Warm Storage 0 Number of replicas for OpenSearch Index. Each replica is a full copy of an index. Days to Cold Storage 0 The number of days required to move the index into cold storage, this is only effecitve when the value is >0 and cold storage is enabled in OpenSearch. Days to Retain 0 The total number of days to retain the index, if value is 0, the index will not be deleted. Appendix Service Log Output Destination Most of AWS Services output logs to Amazon CloudWatch Logs or Amazon S3, and some output to Kinesis Data Streams or Kinesis Firehose. The following table is a sample list of AWS services and their log destinations. Service log destination AWS Services Amazon S3 CloudTrail, S3 Access Log, CloudFront Standard Logs, ELB Access Log, VPC Flow Logs, WAF Log, Config Log Amazon CloudWatch Logs RDS, Lambda, Lambda@Edge, VPC Flow Logs, AppSync, API Gateway, WAF Log Kinesis Firehose WAF Log Kinesis Data Streams CloudFront Real-time logs, Amazon Pinpoint events","title":"Component Design"},{"location":"designs/service-log/component-design/#service-log-pipeline-component-design","text":"","title":"Service Log Pipeline Component Design"},{"location":"designs/service-log/component-design/#overview","text":"Service Log Analytics Pipeline, as one component of Log Hub solution, is used to collect logs for AWS services, process and ingest into Amazon OpenSearch Service (AOS). This document is to describe this component is designed. Currently, this solution supports S3 Access Logs, CloudTrail Logs, ELB Logs, CloudFront Logs, RDS Logs, WAF Logs, Lambda Logs. To learn how to extend this solution to support more service logs, please check Tutorial: Extend Service Logs Info For more information about solution overall design, refer to High Level Design .","title":"Overview"},{"location":"designs/service-log/component-design/#component-design","text":"","title":"Component Design"},{"location":"designs/service-log/component-design/#high-level-architecture","text":"Based on different log destinations , Different architectures are used. Destination on Amazon S3 Normally the logs on Amazon S3 are not for real-time analysis. Currently, this solution supports CloudTrail logs, CloudFront Standard logs, Amazon S3 Access logs, Elastic Load Balancing (ELB) logs, VPC Flow logs, and Amazon Config logs. The process is described as below: AWS Services store logs on Amazon S3 bucket A notification is sent to Amazon SQS when new log file is created Amazon SQS triggers the Lambda (Log processor) to run The Log processor read and processes the log file and ingest the logs into Amazon OpenSearch service. For cross-account log ingestion, the AWS Services store logs on Amazon S3 bucket in one account, and other resources remain in Log Hub's Account: Destination on CloudWatch Logs Some services can only choose Amazon CloudWatch Log Group as destination. Currently, this solution supports RDS logs and Lambda Logs The process is described as below: AWS Services store logs on Amazon CloudWatch log group The CloudWatch logs is streaming to Amazon Kinesis Data Stream (KDS) via subscription. KDS triggers the Lambda (Log processor) to run The Log processor read and processes the log records and ingest the logs into Amazon OpenSearch service. For cross-account log ingestion, the AWS Services store logs on Amazon CloudWatch log group in one account, and other resources remain in Log Hub's Account:","title":"High-Level Architecture"},{"location":"designs/service-log/component-design/#process-design","text":"To learn more information about how the detail process are designed, please refer to Process Design","title":"Process Design"},{"location":"designs/service-log/component-design/#api-design","text":"A list of GraphQL APIs are built on AWS Appsync service to support service pipeline management from Log Hub Web Console. To learn more information about how the backend APIs are designed, please refer to API Design","title":"API Design"},{"location":"designs/service-log/component-design/#data-model-design","text":"This component uses Amazon DynamoDB as the backend NoSQL database to store information about the service log pipelines. To learn more information about how the data model is designed, please refer to Data Model Design","title":"Data Model Design"},{"location":"designs/service-log/component-design/#cloudformation-design","text":"This component can be launched independently via CloudFormation without the Solution Web Console (UI). The parameters in the CloudFormation template are listed as below: Parameter Default Description Log Bucket Name <Requires input> The S3 bucket name which stores the service logs. Log Bucket Prefix <Requires input> The S3 bucket path prefix which stores the service logs. Engine Type OpenSearch The engine type of the OpenSearch. Select OpenSearch or Elasticsearch. OpenSearch Domain Name <Requires input> The domain name of the Amazon OpenSearch cluster. OpenSearch Endpoint <Requires input> The OpenSearch endpoint URL. e.g. vpc-your_opensearch_domain_name-xcvgw6uu2o6zafsiefxubwuohe.us-east-1.es.amazonaws.com Index Prefix <requires input> The common prefix of OpenSearch index for the log. The index name will be -elb- . Create Sample Dashboard Yes Whether to create a sample OpenSearch dashboard. VPC ID <requires input> Select a VPC which has access to the OpenSearch domain. The log processing Lambda will be resides in the selected VPC. Subnet IDs <requires input> Select at leasts two subnets which has access to the OpenSearch domain. The log processing Lambda will resides in the subnets. Please make sure the subnets has access to the Amazon S3 service. Security Group ID <requires input> Select a Security Group which will be associated to the log processing Lambda. Please make sure the Security Group has access to the OpenSearch domain. Number Of Shards 5 Number of shards to distribute the index evenly across all data nodes, keep the size of each shard between 10-50 GiB. Number of Replicas 1 The number of days required to move the index into warm storage, this is only effecitve when the value is >0 and warm storage is enabled in OpenSearch. Days to Warm Storage 0 Number of replicas for OpenSearch Index. Each replica is a full copy of an index. Days to Cold Storage 0 The number of days required to move the index into cold storage, this is only effecitve when the value is >0 and cold storage is enabled in OpenSearch. Days to Retain 0 The total number of days to retain the index, if value is 0, the index will not be deleted.","title":"CloudFormation Design"},{"location":"designs/service-log/component-design/#appendix","text":"","title":"Appendix"},{"location":"designs/service-log/component-design/#service-log-output-destination","text":"Most of AWS Services output logs to Amazon CloudWatch Logs or Amazon S3, and some output to Kinesis Data Streams or Kinesis Firehose. The following table is a sample list of AWS services and their log destinations. Service log destination AWS Services Amazon S3 CloudTrail, S3 Access Log, CloudFront Standard Logs, ELB Access Log, VPC Flow Logs, WAF Log, Config Log Amazon CloudWatch Logs RDS, Lambda, Lambda@Edge, VPC Flow Logs, AppSync, API Gateway, WAF Log Kinesis Firehose WAF Log Kinesis Data Streams CloudFront Real-time logs, Amazon Pinpoint events","title":"Service Log Output Destination"},{"location":"designs/service-log/data-model-design/","text":"Service Log Pipeline Data Model Design Overview This component uses Amazon DynamoDB as the backend NoSQL database. This document is about the Data Model Design for Service Log Pipeline component. To learn more information about the component, refer to Component Design Service Pipeline Table Service pipeline table stores information about the service log pipelines managed by this solution. The data attributes are listed as below: Attribute name Type Example Description Comments id String 06e3e64d-0958-43b1-b426-fe52ac55738f Unique ID of a Pipeline Partition key stackName String LogHub-Pipe-06e3e Service Pipeline CloudFormation Stack Name stackId String arn:aws:cloudformation:us-east-1:123456789012:stack/LogHub-Pipe-06e3e/a3d66790-6300-11ec-9ef5-0a829481a42d Service Pipeline CloudFormation Stack ID source String test-bucket Source of the Log target String dev OpenSearch domain status String ACTIVE Status of the pipeline error String Error message of the pipeline type String S3 AWS service type parameters List [{...}] Parameter key-value pairs to deploy the pipeline createdDt String 2021-12-22T08:24:53Z Creation date of the pipeline tags List [{...}] Custom tags","title":"Data Model Design"},{"location":"designs/service-log/data-model-design/#service-log-pipeline-data-model-design","text":"","title":"Service Log Pipeline Data Model Design"},{"location":"designs/service-log/data-model-design/#overview","text":"This component uses Amazon DynamoDB as the backend NoSQL database. This document is about the Data Model Design for Service Log Pipeline component. To learn more information about the component, refer to Component Design","title":"Overview"},{"location":"designs/service-log/data-model-design/#service-pipeline-table","text":"Service pipeline table stores information about the service log pipelines managed by this solution. The data attributes are listed as below: Attribute name Type Example Description Comments id String 06e3e64d-0958-43b1-b426-fe52ac55738f Unique ID of a Pipeline Partition key stackName String LogHub-Pipe-06e3e Service Pipeline CloudFormation Stack Name stackId String arn:aws:cloudformation:us-east-1:123456789012:stack/LogHub-Pipe-06e3e/a3d66790-6300-11ec-9ef5-0a829481a42d Service Pipeline CloudFormation Stack ID source String test-bucket Source of the Log target String dev OpenSearch domain status String ACTIVE Status of the pipeline error String Error message of the pipeline type String S3 AWS service type parameters List [{...}] Parameter key-value pairs to deploy the pipeline createdDt String 2021-12-22T08:24:53Z Creation date of the pipeline tags List [{...}] Custom tags","title":"Service Pipeline Table"},{"location":"designs/service-log/process-design/","text":"Service Log Pipeline Process Design Overview This document is about the Process Design for Service Log Pipeline component. To learn more information about the component, refer to Component Design Service Log Pipeline Process At a high level, an end to end log analytics pipeline consists the 4 following stages. Collect Buffer Process Visualize Different services are used in different stages. Collect Customers can enable the service logs from AWS Management Console or API calls. The log is stored in different destinations. The main services in this stage are: Amazon S3 CloudWatch Log Group Info Log Hub Solution also supports automatically enable the logs for some services, such as S3 Access Logs. Check API Design Buffer The buffering layers involves different services based on various cases. Amazon SQS For service logs that is stored in Amazon S3, SQS is used as the buffering layer to receive S3 Events. Kinesis Data Stream (KDS) KDS can be used to subscribe the log streams from CloudWatch Logs. Also, CloudFront real-time logs can only be sent to KDS. Kinesis Data Firehose (KDF) KDF can be used as a bufferring layer and sink the logs to destination such as S3 buckets or directly to OpenSearch. Process This stage uses AWS Lambda as the core service. The general purpose of a Log Processor is to parse the raw logs, filter and enrich the log info before ingest that to OpenSearch. The process includes below four steps: Decompress : This is only required if the source log file is compressed. Parse : This is to parse the raw log records such as using regex. Filter : This is to filter on the logs based on certain conditions. Enrich : This is to enrich the original log messages with extra information, such as IP to Location. Warning Currently, Filter and Enrich are not yet supported. The processed logs can then be ingested into AOS. There are several actions to be taken in OpenSearch for Log Ingestion. Create Index Template Index templates let you initialize new indices with predefined mappings and settings. For example, if you continuously index log data, you can define an index template so that all of these indices have the same number of shards and replicas. This is very important as once the data is loaded into OpenSearch, the mapping and the number of shards can't be changed. Use below OpenSearch REST API to create index template PUT _index_template/<index-template-name> Info This is just an one time action that is executed during the start of the CloudFormation deployment. Create Index State Management (ISM) Policy ISM lets you automate periodic, administrative operations by triggering them based on changes in the index age, index size, or number of documents. Using the ISM, you can define policies that automatically handle index transition (such as hot to warm, warm to cold) or deletions to fit your use case. Below OpenSearch REST API is used to check if index template exists # for OpenSearch PUT _opendistro/_ism/policies/{policy_id} # for Elasticsearch PUT _plugins/_ism/policies/{policy_id} Info This is just an one time action that is executed during the start of the CloudFormation deployment. Check if index template exists It's a good practice to have a check whether index template already exists or not before loading data into OpenSearch. Otherwise, the logs could be loaded as dirty data and it took more time to delete and reprocess the logs. Below OpenSearch REST API is used to check if index template exists HEAD _index_template/<index-template-name> Info This action is executed everytime before loading data. Bulk Load Once the index template is created, and the data is ready to load, normally the log is loaded in batches via the Bulk load API. The default batch size is 10000 records. Too many records in one single batch can result in 513 Payload too large error. Below OpenSearch REST API is used to load data in batches PUT <index-name>/_bulk Visualize Once the log data is ingested into OpenSearch, customer can then analyze and visulize the logs in OpenSearch Dashboards. This solution is shipped with simple dashboards for each services. Import pre-built dashboards Below OpenSearch Dashboards REST API is used to import pre-built dashboards. # for OpenSearch POST _dashboards/api/saved_objects/_import?createNewCopies=true # for OpenSearch POST _plugin/kibana/api/saved_objects/_import?createNewCopies=true Dashboard Design The dashboard should contains valuable data insights. Take CloudFront Log as an example, the dashboards contains information such as: PV/UV count Cache Hit/Miss Rate Bandwidth Health Status (2xx, 3xx, 4xx, 5xx) Top Request URIs Top Client IPs Pipeline Orchestration Process Customer can manage Service Log pipeline from Log Hub Web Console. Below is the high-level process that is used to orchestrate service log pipeline flow. Create Service Pipeline The process to create service log pipeline is described in below diagram: The UML diagram is shown in below: Create Service Pipeline API call is sent to Appsync Appsync invoke Lambda (pipeline handler) as resolver Lambda generate a UUID and create a new item in DynamoDB Lambda trigger Pipeline Step function to flow Pipeline Step Function execute CfnFlow step function as a Child Step CfnFlow use CloudFormation createStack api to start deployment of sub stack template CfnFlow use CloudFormation describe api to query the status of the sub stack CfnFlow check the status and repeat step 7 until the status is completed CfnFlow notify the result to parent Pipeline Step function flow Pipeline Step Function update the status to DynamoDB References: Create Service Pipeline API Service Pipeline Table Delete Service Pipeline The process to delete service log pipeline is described in below diagram: The UML diagram is shown in below: Delete Service Pipeline API call is sent to Appsync GraphQL invoke Lambda (pipeline handler) as resolver Lambda query item in DynamoDB to get sub stack ID Lambda update item in DynamoDB with status \u2018DELETING\u2019 Lambda trigger Pipeline Step function to flow Pipeline Step Function execute CfnFlow step function as a Child Step CfnFlow use CloudFormation deleteStack api to start deletion of sub stack template CfnFlow use CloudFormation describe api to query the status of the sub stack CfnFlow check the status and repeat step 8 until the status is completed CfnFlow notify the result to parent Pipeline Step function flow Pipeline Step Function update the status to DynamoDB References: Delete Service Pipeline API Service Pipeline Table","title":"Process Design"},{"location":"designs/service-log/process-design/#service-log-pipeline-process-design","text":"","title":"Service Log Pipeline Process Design"},{"location":"designs/service-log/process-design/#overview","text":"This document is about the Process Design for Service Log Pipeline component. To learn more information about the component, refer to Component Design","title":"Overview"},{"location":"designs/service-log/process-design/#service-log-pipeline-process","text":"At a high level, an end to end log analytics pipeline consists the 4 following stages. Collect Buffer Process Visualize Different services are used in different stages.","title":"Service Log Pipeline Process"},{"location":"designs/service-log/process-design/#collect","text":"Customers can enable the service logs from AWS Management Console or API calls. The log is stored in different destinations. The main services in this stage are: Amazon S3 CloudWatch Log Group Info Log Hub Solution also supports automatically enable the logs for some services, such as S3 Access Logs. Check API Design","title":"Collect"},{"location":"designs/service-log/process-design/#buffer","text":"The buffering layers involves different services based on various cases. Amazon SQS For service logs that is stored in Amazon S3, SQS is used as the buffering layer to receive S3 Events. Kinesis Data Stream (KDS) KDS can be used to subscribe the log streams from CloudWatch Logs. Also, CloudFront real-time logs can only be sent to KDS. Kinesis Data Firehose (KDF) KDF can be used as a bufferring layer and sink the logs to destination such as S3 buckets or directly to OpenSearch.","title":"Buffer"},{"location":"designs/service-log/process-design/#process","text":"This stage uses AWS Lambda as the core service. The general purpose of a Log Processor is to parse the raw logs, filter and enrich the log info before ingest that to OpenSearch. The process includes below four steps: Decompress : This is only required if the source log file is compressed. Parse : This is to parse the raw log records such as using regex. Filter : This is to filter on the logs based on certain conditions. Enrich : This is to enrich the original log messages with extra information, such as IP to Location. Warning Currently, Filter and Enrich are not yet supported. The processed logs can then be ingested into AOS. There are several actions to be taken in OpenSearch for Log Ingestion. Create Index Template Index templates let you initialize new indices with predefined mappings and settings. For example, if you continuously index log data, you can define an index template so that all of these indices have the same number of shards and replicas. This is very important as once the data is loaded into OpenSearch, the mapping and the number of shards can't be changed. Use below OpenSearch REST API to create index template PUT _index_template/<index-template-name> Info This is just an one time action that is executed during the start of the CloudFormation deployment. Create Index State Management (ISM) Policy ISM lets you automate periodic, administrative operations by triggering them based on changes in the index age, index size, or number of documents. Using the ISM, you can define policies that automatically handle index transition (such as hot to warm, warm to cold) or deletions to fit your use case. Below OpenSearch REST API is used to check if index template exists # for OpenSearch PUT _opendistro/_ism/policies/{policy_id} # for Elasticsearch PUT _plugins/_ism/policies/{policy_id} Info This is just an one time action that is executed during the start of the CloudFormation deployment. Check if index template exists It's a good practice to have a check whether index template already exists or not before loading data into OpenSearch. Otherwise, the logs could be loaded as dirty data and it took more time to delete and reprocess the logs. Below OpenSearch REST API is used to check if index template exists HEAD _index_template/<index-template-name> Info This action is executed everytime before loading data. Bulk Load Once the index template is created, and the data is ready to load, normally the log is loaded in batches via the Bulk load API. The default batch size is 10000 records. Too many records in one single batch can result in 513 Payload too large error. Below OpenSearch REST API is used to load data in batches PUT <index-name>/_bulk","title":"Process"},{"location":"designs/service-log/process-design/#visualize","text":"Once the log data is ingested into OpenSearch, customer can then analyze and visulize the logs in OpenSearch Dashboards. This solution is shipped with simple dashboards for each services. Import pre-built dashboards Below OpenSearch Dashboards REST API is used to import pre-built dashboards. # for OpenSearch POST _dashboards/api/saved_objects/_import?createNewCopies=true # for OpenSearch POST _plugin/kibana/api/saved_objects/_import?createNewCopies=true Dashboard Design The dashboard should contains valuable data insights. Take CloudFront Log as an example, the dashboards contains information such as: PV/UV count Cache Hit/Miss Rate Bandwidth Health Status (2xx, 3xx, 4xx, 5xx) Top Request URIs Top Client IPs","title":"Visualize"},{"location":"designs/service-log/process-design/#pipeline-orchestration-process","text":"Customer can manage Service Log pipeline from Log Hub Web Console. Below is the high-level process that is used to orchestrate service log pipeline flow.","title":"Pipeline Orchestration Process"},{"location":"designs/service-log/process-design/#create-service-pipeline","text":"The process to create service log pipeline is described in below diagram: The UML diagram is shown in below: Create Service Pipeline API call is sent to Appsync Appsync invoke Lambda (pipeline handler) as resolver Lambda generate a UUID and create a new item in DynamoDB Lambda trigger Pipeline Step function to flow Pipeline Step Function execute CfnFlow step function as a Child Step CfnFlow use CloudFormation createStack api to start deployment of sub stack template CfnFlow use CloudFormation describe api to query the status of the sub stack CfnFlow check the status and repeat step 7 until the status is completed CfnFlow notify the result to parent Pipeline Step function flow Pipeline Step Function update the status to DynamoDB References: Create Service Pipeline API Service Pipeline Table","title":"Create Service Pipeline"},{"location":"designs/service-log/process-design/#delete-service-pipeline","text":"The process to delete service log pipeline is described in below diagram: The UML diagram is shown in below: Delete Service Pipeline API call is sent to Appsync GraphQL invoke Lambda (pipeline handler) as resolver Lambda query item in DynamoDB to get sub stack ID Lambda update item in DynamoDB with status \u2018DELETING\u2019 Lambda trigger Pipeline Step function to flow Pipeline Step Function execute CfnFlow step function as a Child Step CfnFlow use CloudFormation deleteStack api to start deletion of sub stack template CfnFlow use CloudFormation describe api to query the status of the sub stack CfnFlow check the status and repeat step 8 until the status is completed CfnFlow notify the result to parent Pipeline Step function flow Pipeline Step Function update the status to DynamoDB References: Delete Service Pipeline API Service Pipeline Table","title":"Delete Service Pipeline"},{"location":"designs/service-log/tutorial-extend-service-log/","text":"Tutorial: Extend Service Logs Overview The purpose of this document is to describe how to extend current Log Hub solution to support more types of AWS service logs. In this guide, we will work you through a tutorial of how to add support for a new type of logs using WAF Logs as an example. If you are not from CSDC solution team, we also welcome your contributions. You can jump to How to Contribute for more details. Notice So far, this guide is only for Log Destination as S3. Check more information about AWS Service Log Destination . Pre-requisites Clone the repo Provision an OpenSearch domain in VPC with private subnets for testing Info Currently, clone the code repo from code.amazon.com, all changes need be submitted to develop branch for code review. How to Extend Follow below step by step guide to learn how to extend service logs analysis for WAF in Log Hub solution. Step 1: Update Log Processor To add a new log type for WAF Logs to Log Processor Lambda, open source/constructs/lambda/pipeline/service/log-processor/util/log_parser.py Add an implemetation of LogType for WAF logs, which basically is just to implement the method parse(line) and return a processed record(s) in Json format. class WAF ( LogType ): \"\"\"An implementation of LogType for WAF Logs\"\"\" _format = \"json\" def parse ( self , line : str ): json_record = json . loads ( line ) # Extract web acl name, host and user agent json_record [ \"webaclName\" ] = re . search ( \"[^/]/webacl/([^/]*)\" , json_record [ \"webaclId\" ] ) . group ( 1 ) headers = json_record [ \"httpRequest\" ][ \"headers\" ] for header in headers : if header [ \"name\" ] . lower () == \"host\" : json_record [ \"host\" ] = header [ \"value\" ] elif header [ \"name\" ] . lower () == \"user-agent\" : json_record [ \"userAgent\" ] = header [ \"value\" ] else : continue return json_record Info WAF Logs are in Json format, check Appendix 1: Log Type Implementation for another example for flat log files. Step 2: Add CDK Stack To generate a new CloudFormation Template for Waf Logs, Open source/constructs/bin/main.ts , add a new line as below: new ServiceLogPipelineStack ( app , 'WAFLog' , { logType : 'WAF' }); For WAF, simply reuse the common CloudFormation parameters. Open Log-hub/source/constructs/lib/pipeline/service/service-log-pipeline-stack.ts , and add \u2018WAF\u2019 to below line (This is required for all logs that is with log destination as S3): if ([ 'S3' , 'CloudTrail' , 'ELB' , 'CloudFront' , 'WAF' ]. includes ( props . logType )) { const logBucketName = new CfnParameter ( this , 'logBucketName' , { ... For some other log types, you can add more CloudFormation parameters if needed. For example, add an extra parameter of Log Format for VPC Flow Logs since the log format can be customized. Step 3: Add Index Template Index templates let you initialize new indices with predefined mappings and settings. Before logs are ingested to OpenSearch, the index template/mapping must exist, otherwise, once data is loaded, the index mapping can't be changed. Log Type is used to identify which template json file to use, Make sure the file name is same as the log type in lower case. For example, if the log Type is \u2018WAF\u2019, create a waf.json in folder source/constructs/lambda/pipeline/common/opensearch-helper/assets/index_template The template must be in a format of : { \"aliases\" : {}, \"mappings\" : { \"properties\" : { \"...\" : { \"type\" : \"...\" , ... }, ... } }, \"settings\" : { \"index\" : { \"number_of_shards\" : \"5\" , \"number_of_replicas\" : \"1\" } } } Keep aliases as blank. Make sure at least number_of_shards and number_of_replicas are in the setting section (keep 5 and 1 as the default value). The alias and setting will be overrided during deployment. Info To learn more about index template, check Official OpenSearch Document about Index Template Step 4: CDK Deploy Run cdk deploy, for example: cdk deploy WAFLog \\ --parameters vpcId=vpc-0e172e182aa53806b \\ --parameters subnetIds=subnet-06548d0c4ee34da59,subnet-0b873d0b6e73c2f9c \\ --parameters securityGroupId=sg-04b03782612cb485f \\ --parameters endpoint=vpc-dev-ardonphnbg327lwqncuj2vps3q.eu-west-1.es.amazonaws.com \\ --parameters domainName=dev \\ --parameters logBucketName=loghub-alb-loggingbucket0fa53b76 \\ --parameters logBucketPrefix=waf \\ --parameters backupBucketName=loghub-alb-loggingbucket0fa53b76 \\ --parameters createDashboard=No \\ --parameters indexPrefix=xxxxxx \\ --parameters engineType=OpenSearch To learn more about what the parameters are, check CloudFormation Design Step 5: Test and Verify Generate some log data by making some requests to WAF (For example, if WAF is for cloudfront, simply access the cloudfront link). Check S3 bucket to see if the log files are generated. Then open Lambda in AWS management console, find and open the function WAFLog-WAFLogPipelineLogProcessorFn and check the cloudwatch logs. If the ingestion is successful, you should see logs as the following: ... [INFO] 2022-01-14T05:45:14.397Z 947eb9f3-a2c6-4d59-bf63-870be02dd20a --> bulk_load response code 200 [INFO] 2022-01-14T05:45:15.165Z 947eb9f3-a2c6-4d59-bf63-870be02dd20a PUT xxxxxx-waf-2022-01-14/_bulk [INFO] 2022-01-14T05:45:16.163Z 947eb9f3-a2c6-4d59-bf63-870be02dd20a --> bulk_load response code 200 [INFO] 2022-01-14T05:45:16.229Z 947eb9f3-a2c6-4d59-bf63-870be02dd20a --> Total: 278126 Success: 278126 Fail: 0 END RequestId: 947eb9f3-a2c6-4d59-bf63-870be02dd20a You can also see error messages if the ingestion failed, check and then fix the error accordingly. Step 6: Export Sample Dashboards Once data is ingested into OpenSearch, you can then create dashboard and visualize for the logs. Follow the same naming standard. For example, if the index prefix is xxxxxx-waf-* , create everything with same prefix xxxxxx-waf- Once dashboard is completed, export the dashboard with related objects, the exported file is with file extention .ndjson . Open the export ndjson, and replace all xxxxxx-waf to %%INDEX%% , then save the file to project folder source/constructs/lambda/pipeline/common/opensearch-helper/assets/saved_objects How to Contribute If you are not one of the solution team members, and you want to contribute for new service logs, please follow the section How to Extend and get it built and tested in your account. After that, you can contact one of our team members , and submit us with below artifacts: Log Type implementation in Python Index Template file (.json) Sample Dashboard file (.ndjson) Some sample log file that we can test (Nice to have) Appendix Log Type Implementation The Log Type definition class LogType ( ABC ): \"\"\"An abstract class represents one type of Logs. Each AWS service has its own log format. Create a class for each service with an implementation of `parse(line)` to parse its service logs \"\"\" _fields = [] # list of fields _format = \"text\" # log file format, such as json, text, etc. @abstractmethod def parse ( self , line : str ): \"\"\"Parse the original raw log record, and return processed json record(s). This should be implemented in each service class. \"\"\" pass ... Below is an example of implementation for ELB (ALB) Logs class ELB ( LogType ): \"\"\"An implementation of LogType for ELB Logs\"\"\" _fields = [ \"type\" , \"timestamp\" , \"elb\" , \"client_ip\" , \"client_port\" , \"target_ip\" , ... ] def parse ( self , line : str ) -> dict : json_record = {} pattern = ( \"([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*):([0-9]*) ([^ ]*)[:-]([0-9]*) ([-.0-9]*) \" '([-.0-9]*) ([-.0-9]*) (|[-0-9]*) (-|[-0-9]*) ([-0-9]*) ([-0-9]*) \"([^ ]*) ([^ ]*) ' '(- |[^ ]*)\" \"([^\"]*)\" ([A-Z0-9-]+) ([A-Za-z0-9.-]*) ([^ ]*) \"([^\"]*)\" \"([^\"]*)\" ' '\"([^\"]*)\" ([-.0-9]*) ([^ ]*) \"([^\"]*)\" \"([^\"]*)\" \"([^ ]*)\" \"([^ ]+?)\" ' '\"([^ ]+)\" \"([^ ]*)\" \"([^ ]*)\"' ) result = re . match ( pattern , line ) if result : for i , attr in enumerate ( self . _fields ): # print(f'{attr} = {result.group(i+1)}') json_record [ attr ] = result . group ( i + 1 ) else : logger . error ( \"Unable to parse line: %s \" , line ) return json_record","title":"Tutorial: Extend Service Logs"},{"location":"designs/service-log/tutorial-extend-service-log/#tutorial-extend-service-logs","text":"","title":"Tutorial: Extend Service Logs"},{"location":"designs/service-log/tutorial-extend-service-log/#overview","text":"The purpose of this document is to describe how to extend current Log Hub solution to support more types of AWS service logs. In this guide, we will work you through a tutorial of how to add support for a new type of logs using WAF Logs as an example. If you are not from CSDC solution team, we also welcome your contributions. You can jump to How to Contribute for more details. Notice So far, this guide is only for Log Destination as S3. Check more information about AWS Service Log Destination .","title":"Overview"},{"location":"designs/service-log/tutorial-extend-service-log/#pre-requisites","text":"Clone the repo Provision an OpenSearch domain in VPC with private subnets for testing Info Currently, clone the code repo from code.amazon.com, all changes need be submitted to develop branch for code review.","title":"Pre-requisites"},{"location":"designs/service-log/tutorial-extend-service-log/#how-to-extend","text":"Follow below step by step guide to learn how to extend service logs analysis for WAF in Log Hub solution.","title":"How to Extend"},{"location":"designs/service-log/tutorial-extend-service-log/#step-1-update-log-processor","text":"To add a new log type for WAF Logs to Log Processor Lambda, open source/constructs/lambda/pipeline/service/log-processor/util/log_parser.py Add an implemetation of LogType for WAF logs, which basically is just to implement the method parse(line) and return a processed record(s) in Json format. class WAF ( LogType ): \"\"\"An implementation of LogType for WAF Logs\"\"\" _format = \"json\" def parse ( self , line : str ): json_record = json . loads ( line ) # Extract web acl name, host and user agent json_record [ \"webaclName\" ] = re . search ( \"[^/]/webacl/([^/]*)\" , json_record [ \"webaclId\" ] ) . group ( 1 ) headers = json_record [ \"httpRequest\" ][ \"headers\" ] for header in headers : if header [ \"name\" ] . lower () == \"host\" : json_record [ \"host\" ] = header [ \"value\" ] elif header [ \"name\" ] . lower () == \"user-agent\" : json_record [ \"userAgent\" ] = header [ \"value\" ] else : continue return json_record Info WAF Logs are in Json format, check Appendix 1: Log Type Implementation for another example for flat log files.","title":"Step 1: Update Log Processor"},{"location":"designs/service-log/tutorial-extend-service-log/#step-2-add-cdk-stack","text":"To generate a new CloudFormation Template for Waf Logs, Open source/constructs/bin/main.ts , add a new line as below: new ServiceLogPipelineStack ( app , 'WAFLog' , { logType : 'WAF' }); For WAF, simply reuse the common CloudFormation parameters. Open Log-hub/source/constructs/lib/pipeline/service/service-log-pipeline-stack.ts , and add \u2018WAF\u2019 to below line (This is required for all logs that is with log destination as S3): if ([ 'S3' , 'CloudTrail' , 'ELB' , 'CloudFront' , 'WAF' ]. includes ( props . logType )) { const logBucketName = new CfnParameter ( this , 'logBucketName' , { ... For some other log types, you can add more CloudFormation parameters if needed. For example, add an extra parameter of Log Format for VPC Flow Logs since the log format can be customized.","title":"Step 2: Add CDK Stack"},{"location":"designs/service-log/tutorial-extend-service-log/#step-3-add-index-template","text":"Index templates let you initialize new indices with predefined mappings and settings. Before logs are ingested to OpenSearch, the index template/mapping must exist, otherwise, once data is loaded, the index mapping can't be changed. Log Type is used to identify which template json file to use, Make sure the file name is same as the log type in lower case. For example, if the log Type is \u2018WAF\u2019, create a waf.json in folder source/constructs/lambda/pipeline/common/opensearch-helper/assets/index_template The template must be in a format of : { \"aliases\" : {}, \"mappings\" : { \"properties\" : { \"...\" : { \"type\" : \"...\" , ... }, ... } }, \"settings\" : { \"index\" : { \"number_of_shards\" : \"5\" , \"number_of_replicas\" : \"1\" } } } Keep aliases as blank. Make sure at least number_of_shards and number_of_replicas are in the setting section (keep 5 and 1 as the default value). The alias and setting will be overrided during deployment. Info To learn more about index template, check Official OpenSearch Document about Index Template","title":"Step 3: Add Index Template"},{"location":"designs/service-log/tutorial-extend-service-log/#step-4-cdk-deploy","text":"Run cdk deploy, for example: cdk deploy WAFLog \\ --parameters vpcId=vpc-0e172e182aa53806b \\ --parameters subnetIds=subnet-06548d0c4ee34da59,subnet-0b873d0b6e73c2f9c \\ --parameters securityGroupId=sg-04b03782612cb485f \\ --parameters endpoint=vpc-dev-ardonphnbg327lwqncuj2vps3q.eu-west-1.es.amazonaws.com \\ --parameters domainName=dev \\ --parameters logBucketName=loghub-alb-loggingbucket0fa53b76 \\ --parameters logBucketPrefix=waf \\ --parameters backupBucketName=loghub-alb-loggingbucket0fa53b76 \\ --parameters createDashboard=No \\ --parameters indexPrefix=xxxxxx \\ --parameters engineType=OpenSearch To learn more about what the parameters are, check CloudFormation Design","title":"Step 4: CDK Deploy"},{"location":"designs/service-log/tutorial-extend-service-log/#step-5-test-and-verify","text":"Generate some log data by making some requests to WAF (For example, if WAF is for cloudfront, simply access the cloudfront link). Check S3 bucket to see if the log files are generated. Then open Lambda in AWS management console, find and open the function WAFLog-WAFLogPipelineLogProcessorFn and check the cloudwatch logs. If the ingestion is successful, you should see logs as the following: ... [INFO] 2022-01-14T05:45:14.397Z 947eb9f3-a2c6-4d59-bf63-870be02dd20a --> bulk_load response code 200 [INFO] 2022-01-14T05:45:15.165Z 947eb9f3-a2c6-4d59-bf63-870be02dd20a PUT xxxxxx-waf-2022-01-14/_bulk [INFO] 2022-01-14T05:45:16.163Z 947eb9f3-a2c6-4d59-bf63-870be02dd20a --> bulk_load response code 200 [INFO] 2022-01-14T05:45:16.229Z 947eb9f3-a2c6-4d59-bf63-870be02dd20a --> Total: 278126 Success: 278126 Fail: 0 END RequestId: 947eb9f3-a2c6-4d59-bf63-870be02dd20a You can also see error messages if the ingestion failed, check and then fix the error accordingly.","title":"Step 5:  Test and Verify"},{"location":"designs/service-log/tutorial-extend-service-log/#step-6-export-sample-dashboards","text":"Once data is ingested into OpenSearch, you can then create dashboard and visualize for the logs. Follow the same naming standard. For example, if the index prefix is xxxxxx-waf-* , create everything with same prefix xxxxxx-waf- Once dashboard is completed, export the dashboard with related objects, the exported file is with file extention .ndjson . Open the export ndjson, and replace all xxxxxx-waf to %%INDEX%% , then save the file to project folder source/constructs/lambda/pipeline/common/opensearch-helper/assets/saved_objects","title":"Step 6: Export Sample Dashboards"},{"location":"designs/service-log/tutorial-extend-service-log/#how-to-contribute","text":"If you are not one of the solution team members, and you want to contribute for new service logs, please follow the section How to Extend and get it built and tested in your account. After that, you can contact one of our team members , and submit us with below artifacts: Log Type implementation in Python Index Template file (.json) Sample Dashboard file (.ndjson) Some sample log file that we can test (Nice to have)","title":"How to Contribute"},{"location":"designs/service-log/tutorial-extend-service-log/#appendix","text":"","title":"Appendix"},{"location":"designs/service-log/tutorial-extend-service-log/#log-type-implementation","text":"The Log Type definition class LogType ( ABC ): \"\"\"An abstract class represents one type of Logs. Each AWS service has its own log format. Create a class for each service with an implementation of `parse(line)` to parse its service logs \"\"\" _fields = [] # list of fields _format = \"text\" # log file format, such as json, text, etc. @abstractmethod def parse ( self , line : str ): \"\"\"Parse the original raw log record, and return processed json record(s). This should be implemented in each service class. \"\"\" pass ... Below is an example of implementation for ELB (ALB) Logs class ELB ( LogType ): \"\"\"An implementation of LogType for ELB Logs\"\"\" _fields = [ \"type\" , \"timestamp\" , \"elb\" , \"client_ip\" , \"client_port\" , \"target_ip\" , ... ] def parse ( self , line : str ) -> dict : json_record = {} pattern = ( \"([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*):([0-9]*) ([^ ]*)[:-]([0-9]*) ([-.0-9]*) \" '([-.0-9]*) ([-.0-9]*) (|[-0-9]*) (-|[-0-9]*) ([-0-9]*) ([-0-9]*) \"([^ ]*) ([^ ]*) ' '(- |[^ ]*)\" \"([^\"]*)\" ([A-Z0-9-]+) ([A-Za-z0-9.-]*) ([^ ]*) \"([^\"]*)\" \"([^\"]*)\" ' '\"([^\"]*)\" ([-.0-9]*) ([^ ]*) \"([^\"]*)\" \"([^\"]*)\" \"([^ ]*)\" \"([^ ]+?)\" ' '\"([^ ]+)\" \"([^ ]*)\" \"([^ ]*)\"' ) result = re . match ( pattern , line ) if result : for i , attr in enumerate ( self . _fields ): # print(f'{attr} = {result.group(i+1)}') json_record [ attr ] = result . group ( i + 1 ) else : logger . error ( \"Unable to parse line: %s \" , line ) return json_record","title":"Log Type Implementation"},{"location":"designs/solution/high-level-design/","text":"Log Hub Solution High Level Design Overview Log Hub is a solution that enables customer to easliy and quickly build end-to-end log analytics pipelines on top of Amazon OpenSearch Service (AOS). A log pipeline includes a series of log processing steps, including collecting logs from source, processing and sending them to OpenSearch as destination for further analysis. This solution provides a web management console from which customer can easliy manage log analytics pipelines and gain valuable data insights for both AWS service logs and application logs with out of the box visualization dashboards without worring about the underling technical complexity. The purpose of this document is to descibe how Log Hub solution is technical designed from high level perspective. Requirements Functional Requirements This solution is designed with below functional requirements: A centralized web console for customer to manage all the tasks to reduce operational complexities. Supports both AWS service logs and application logs Supports automatically creating visualization dashboards Supports log lifecycle management Supports cross accounts/cross regions log management Supports both China and Global regions Non-Functional Requirements The design must meet below non-functional requirements: Security : Authentication and Authorization is required to protect unexpected access. Scalability : The design must be able to support different scales of logs. Stability : The design must support auto-retries for recoverable errors. Cost Effective : Use serverless architecture design whenever possible, and support log life-cycle management to reduce the overall costs. Assumptions The design is based on below assumptions: Customers who use this solution must be with administrator access on AWS to be able to perform related functions, as this solution will provision different resources such as Lambda, DynamoDB, etc in the AWS account. Customers must understand their business requirments for log analysis, such as the volume of the logs, the days to retain logs etc. High-Level Architecture Below is the high level architecture diagram: This solution deploys the following infrastructure in your AWS Cloud account: Amazon CloudFront to distribute the frontend web UI assets hosted in Amazon S3 bucket. AWS AppSync to provide the backend GraphQL APIs. Amazon Cognito user pool to provide authentication and authorization for frontend and backend. Amazon DynamoDB as backend database to store the solution related information. AWS Lambda to interact with other AWS Services to execute core logic including managing log pipelines or managing log agents and get the information updated in DynamoDB tables. AWS Step Functions to orchestrate on-demand AWS CloudFormation deployment of a set of predefined stacks for log pipeline management. The log pipeline stacks deploys separate AWS resources and are used to collect and process logs and ingest them into Amazon OpenSearch Service for further analysis and visualiztion. AWS Systems Manager and Amazon EventBridge to manage log agent for collecting logs from Application Servers, such as installing log agents (fluentbit) to Application servers and monitoring the health status of the agents. Component Definition This solution consists of below main components: Domain Management This solution uses Amazon OpenSearch Service as the underlying engine to store and analyze logs. This Domain Management component consists a list of operations on top of existing AOS domains, such as importing an existing AOS domain for log ingestion, providing a proxy for access the AOS dashboards which is within VPC, etc. Info To learn more about how this component is designed, please refer to Domain Management Component Design Warning Provision of AOS domain is not in scope of this component. Customer needs to create AOS domain before using this component. Service Log Pipeline This solution supports out of the box log analysis for many AWS service logs, such as Amazon S3 access logs, ELB access logs, etc. This Service Log Pipeline component is designed to reduce the complexisities of building log analytics pipelines for different AWS services with different formats. Customer can collect and process AWS service logs without writing any codes, as well as gain data insights using out of the box visualization dashboards. Info To learn more about how this component is designed, please refer to Service Log Pipeline Component Design Application Log Pipeline This solution supports out of the box log analysis for application logs, such as Nginx/Apache logs or general application logs via regex parser. This Application Log Pipeline component uses Fluent Bit as the underlying log agent to collect logs from the application servers, and allow customers to easily install log agent and monitor the healthy of the agent via System Manager.","title":"High Level Design"},{"location":"designs/solution/high-level-design/#log-hub-solution-high-level-design","text":"","title":"Log Hub Solution High Level Design"},{"location":"designs/solution/high-level-design/#overview","text":"Log Hub is a solution that enables customer to easliy and quickly build end-to-end log analytics pipelines on top of Amazon OpenSearch Service (AOS). A log pipeline includes a series of log processing steps, including collecting logs from source, processing and sending them to OpenSearch as destination for further analysis. This solution provides a web management console from which customer can easliy manage log analytics pipelines and gain valuable data insights for both AWS service logs and application logs with out of the box visualization dashboards without worring about the underling technical complexity. The purpose of this document is to descibe how Log Hub solution is technical designed from high level perspective.","title":"Overview"},{"location":"designs/solution/high-level-design/#requirements","text":"","title":"Requirements"},{"location":"designs/solution/high-level-design/#functional-requirements","text":"This solution is designed with below functional requirements: A centralized web console for customer to manage all the tasks to reduce operational complexities. Supports both AWS service logs and application logs Supports automatically creating visualization dashboards Supports log lifecycle management Supports cross accounts/cross regions log management Supports both China and Global regions","title":"Functional Requirements"},{"location":"designs/solution/high-level-design/#non-functional-requirements","text":"The design must meet below non-functional requirements: Security : Authentication and Authorization is required to protect unexpected access. Scalability : The design must be able to support different scales of logs. Stability : The design must support auto-retries for recoverable errors. Cost Effective : Use serverless architecture design whenever possible, and support log life-cycle management to reduce the overall costs.","title":"Non-Functional Requirements"},{"location":"designs/solution/high-level-design/#assumptions","text":"The design is based on below assumptions: Customers who use this solution must be with administrator access on AWS to be able to perform related functions, as this solution will provision different resources such as Lambda, DynamoDB, etc in the AWS account. Customers must understand their business requirments for log analysis, such as the volume of the logs, the days to retain logs etc.","title":"Assumptions"},{"location":"designs/solution/high-level-design/#high-level-architecture","text":"Below is the high level architecture diagram: This solution deploys the following infrastructure in your AWS Cloud account: Amazon CloudFront to distribute the frontend web UI assets hosted in Amazon S3 bucket. AWS AppSync to provide the backend GraphQL APIs. Amazon Cognito user pool to provide authentication and authorization for frontend and backend. Amazon DynamoDB as backend database to store the solution related information. AWS Lambda to interact with other AWS Services to execute core logic including managing log pipelines or managing log agents and get the information updated in DynamoDB tables. AWS Step Functions to orchestrate on-demand AWS CloudFormation deployment of a set of predefined stacks for log pipeline management. The log pipeline stacks deploys separate AWS resources and are used to collect and process logs and ingest them into Amazon OpenSearch Service for further analysis and visualiztion. AWS Systems Manager and Amazon EventBridge to manage log agent for collecting logs from Application Servers, such as installing log agents (fluentbit) to Application servers and monitoring the health status of the agents.","title":"High-Level Architecture"},{"location":"designs/solution/high-level-design/#component-definition","text":"This solution consists of below main components: Domain Management This solution uses Amazon OpenSearch Service as the underlying engine to store and analyze logs. This Domain Management component consists a list of operations on top of existing AOS domains, such as importing an existing AOS domain for log ingestion, providing a proxy for access the AOS dashboards which is within VPC, etc. Info To learn more about how this component is designed, please refer to Domain Management Component Design Warning Provision of AOS domain is not in scope of this component. Customer needs to create AOS domain before using this component. Service Log Pipeline This solution supports out of the box log analysis for many AWS service logs, such as Amazon S3 access logs, ELB access logs, etc. This Service Log Pipeline component is designed to reduce the complexisities of building log analytics pipelines for different AWS services with different formats. Customer can collect and process AWS service logs without writing any codes, as well as gain data insights using out of the box visualization dashboards. Info To learn more about how this component is designed, please refer to Service Log Pipeline Component Design Application Log Pipeline This solution supports out of the box log analysis for application logs, such as Nginx/Apache logs or general application logs via regex parser. This Application Log Pipeline component uses Fluent Bit as the underlying log agent to collect logs from the application servers, and allow customers to easily install log agent and monitor the healthy of the agent via System Manager.","title":"Component Definition"},{"location":"implementation-guide/","text":"Analytics Pipelines Log Hub supports server-side application log ingestion and AWS Service log ingestion. Supported AWS Services The following table lists the supported AWS services and the correspondence features. AWS Service Log Type Log Location Automatic Ingestion Build-in Dashboard Amazon CloudTrail Standard S3 Yes Yes Amazon S3 Access log S3 Yes Yes Amazon RDS/Aurora Slow query log CloudWatch Logs Yes Yes Amazon RDS/Aurora Error log CloudWatch Logs Yes Yes Amazon CloudFront Standard access log S3 Yes Yes Application Load Balancer Access log S3 Yes Yes AWS WAF Standard log S3 Yes Yes AWS Lambda Standard CloudWatch Logs Yes No Automatic Ingestion . Automatic ingestion means Log Hub will detect the log location of the resource automatically and then read the log. Templated Dashboard . An out-of-box dashboard for the specified AWS service. The Log Hub solution will automatically ingest a dashboard into the AOS.","title":"Analytics Pipelines"},{"location":"implementation-guide/#analytics-pipelines","text":"Log Hub supports server-side application log ingestion and AWS Service log ingestion.","title":"Analytics Pipelines"},{"location":"implementation-guide/#supported-aws-services","text":"The following table lists the supported AWS services and the correspondence features. AWS Service Log Type Log Location Automatic Ingestion Build-in Dashboard Amazon CloudTrail Standard S3 Yes Yes Amazon S3 Access log S3 Yes Yes Amazon RDS/Aurora Slow query log CloudWatch Logs Yes Yes Amazon RDS/Aurora Error log CloudWatch Logs Yes Yes Amazon CloudFront Standard access log S3 Yes Yes Application Load Balancer Access log S3 Yes Yes AWS WAF Standard log S3 Yes Yes AWS Lambda Standard CloudWatch Logs Yes No Automatic Ingestion . Automatic ingestion means Log Hub will detect the log location of the resource automatically and then read the log. Templated Dashboard . An out-of-box dashboard for the specified AWS service. The Log Hub solution will automatically ingest a dashboard into the AOS.","title":"Supported AWS Services"},{"location":"implementation-guide/architecture/","text":"Deploying this solution with the default parameters builds the following environment in the AWS Cloud. Figure 1: Log Hub on AWS architecture This solution deploys the AWS CloudFormation template in your AWS Cloud account and completes the following settings. Amazon CloudFront distributes the frontend web UI assets hosted in Amazon S3 bucket. Amazon Cognito user pool or OpenID Connector (OIDC) can be used for authentication. AWS AppSync provides the backend GraphQL APIs. Amazon DynamoDB stores the solution related information as backend database. AWS Lambda interacts with other AWS Services to process core logic of managing log pipelines or log agents, and obtains information updated in DynamoDB tables. AWS Step Functions orchestrates on-demand AWS CloudFormation deployment of a set of predefined stacks for log pipeline management. The log pipeline stacks deploy separate AWS resources and are used to collect and process logs and ingest them into Amazon OpenSearch Service for further analysis and visualization. Service Log Pipeline or Application Log Pipeline are provisioned on demand via Log Hub console. AWS Systems Manager and Amazon EventBridge manage log agents for collecting logs from Application Servers, such as installing log agents (Fluent Bit) for Application servers and monitoring the health status of the agents. Amazon EC2 or Amazon EKS installs Fluent Bit agents, and uploads log data to Application Log Pipeline. Application Log Pipelines read, parse, process application logs and ingest them into Amazon OpenSearch. Service Log Pipelines read, parse, process AWS service logs and ingest them into Amazon OpenSearch. This solution supports two types of log pipelines: Service Log Analytics Pipeline and Application Log Analytics Pipeline . Service Log Analytics Pipeline Log Hub supports log analysis for AWS services, such as Amazon S3 access logs, and Application Load Balancer access logs. For a complete list of supported AWS services, refer to Supported AWS Services . AWS services output logs to different destinations, including Amazon S3 bucket, CloudWatch log groups, Kinesis Data Streams, and Kinesis Firehose. The solution ingests those logs using different workflows. Note Log Hub supports cross-account log ingestion . If you want to ingest the logs from another AWS account, the resources in the Sources group in the architecture diagram will be in another account. Logs in Amazon S3 Some services use Amazon S3 as the destination, and the logs in Amazon S3 are generally not for real-time analysis. Figure 2: Amazon S3 based service log pipeline architecture The log pipeline runs the following workflow: AWS services store logs in Amazon S3 bucket (Log Bucket). An S3 Event Notification is sent to Amazon SQS when a new log file is created. Amazon SQS triggers the Lambda (Log Processor) to run. The log processor reads and processes the log file and ingests the logs into AOS. The logs failed to be processed are exported to Amazon S3 bucket (Backup Bucket). For cross-account ingestion, the AWS Services store logs in Amazon S3 bucket in the member account, and other resources remain in Log Hub. Logs in Amazon CloudWatch Some services use Amazon CloudWatch log group as the destination. Figure 3: Amazon CloudWatch based service log pipeline architecture The log pipeline runs the following workflow: AWS Services store logs in Amazon CloudWatch log group. The CloudWatch logs is streaming to Amazon Kinesis Data Stream (KDS) via subscription. KDS triggers the Lambda (Log Processor) to run. The log processor reads and processes the log records and ingests the logs into AOS. The logs failed to be processed are exported to Amazon S3 bucket (Backup Bucket). For cross-account ingestion, the AWS Services store logs on Amazon CloudWatch log group in the member account, and other resources remain in Log Hub. Application Log Analytics Pipeline Log Hub supports log analysis for application logs, such as Nginx/Apache HTTP Server logs or custom application logs. Note Log Hub supports cross-account log ingestion . If you want to ingest logs from the same account, the resources in the Sources group will be in the same account as your Log Hub account. Otherwise, they will be in another AWS account. Logs from EC2 Figure 4: Application log pipeline architecture for EC2 The log pipeline runs the following workflow: Fluent Bit works as the underlying log agent to collect logs from application servers and send them to Kinesis Data Streams (KDS). KDS triggers the Lambda (Log Processor) to run. The log processor reads and processes the log records and ingests the logs into AOS. The logs failed to be processed are exported to Amazon S3 bucket (Backup Bucket). Logs from EKS Important If your EKS cluster and OpenSearch cluster are not in the same VPC, you need to use VPC Peering Connection or Transit Gateway to connect these VPCs, and adjust the OpenSearch Security group if needed. Figure 5: Application log pipeline architecture for EKS Fluent Bit works as the underlying log agent to collect logs and send them to the OpenSearch cluster.","title":"Architecture Overview"},{"location":"implementation-guide/architecture/#service-log-analytics-pipeline","text":"Log Hub supports log analysis for AWS services, such as Amazon S3 access logs, and Application Load Balancer access logs. For a complete list of supported AWS services, refer to Supported AWS Services . AWS services output logs to different destinations, including Amazon S3 bucket, CloudWatch log groups, Kinesis Data Streams, and Kinesis Firehose. The solution ingests those logs using different workflows. Note Log Hub supports cross-account log ingestion . If you want to ingest the logs from another AWS account, the resources in the Sources group in the architecture diagram will be in another account.","title":"Service Log Analytics Pipeline"},{"location":"implementation-guide/architecture/#logs-in-amazon-s3","text":"Some services use Amazon S3 as the destination, and the logs in Amazon S3 are generally not for real-time analysis. Figure 2: Amazon S3 based service log pipeline architecture The log pipeline runs the following workflow: AWS services store logs in Amazon S3 bucket (Log Bucket). An S3 Event Notification is sent to Amazon SQS when a new log file is created. Amazon SQS triggers the Lambda (Log Processor) to run. The log processor reads and processes the log file and ingests the logs into AOS. The logs failed to be processed are exported to Amazon S3 bucket (Backup Bucket). For cross-account ingestion, the AWS Services store logs in Amazon S3 bucket in the member account, and other resources remain in Log Hub.","title":"Logs in Amazon S3"},{"location":"implementation-guide/architecture/#logs-in-amazon-cloudwatch","text":"Some services use Amazon CloudWatch log group as the destination. Figure 3: Amazon CloudWatch based service log pipeline architecture The log pipeline runs the following workflow: AWS Services store logs in Amazon CloudWatch log group. The CloudWatch logs is streaming to Amazon Kinesis Data Stream (KDS) via subscription. KDS triggers the Lambda (Log Processor) to run. The log processor reads and processes the log records and ingests the logs into AOS. The logs failed to be processed are exported to Amazon S3 bucket (Backup Bucket). For cross-account ingestion, the AWS Services store logs on Amazon CloudWatch log group in the member account, and other resources remain in Log Hub.","title":"Logs in Amazon CloudWatch"},{"location":"implementation-guide/architecture/#application-log-analytics-pipeline","text":"Log Hub supports log analysis for application logs, such as Nginx/Apache HTTP Server logs or custom application logs. Note Log Hub supports cross-account log ingestion . If you want to ingest logs from the same account, the resources in the Sources group will be in the same account as your Log Hub account. Otherwise, they will be in another AWS account.","title":"Application Log Analytics Pipeline"},{"location":"implementation-guide/architecture/#logs-from-ec2","text":"Figure 4: Application log pipeline architecture for EC2 The log pipeline runs the following workflow: Fluent Bit works as the underlying log agent to collect logs from application servers and send them to Kinesis Data Streams (KDS). KDS triggers the Lambda (Log Processor) to run. The log processor reads and processes the log records and ingests the logs into AOS. The logs failed to be processed are exported to Amazon S3 bucket (Backup Bucket).","title":"Logs from EC2"},{"location":"implementation-guide/architecture/#logs-from-eks","text":"Important If your EKS cluster and OpenSearch cluster are not in the same VPC, you need to use VPC Peering Connection or Transit Gateway to connect these VPCs, and adjust the OpenSearch Security group if needed. Figure 5: Application log pipeline architecture for EKS Fluent Bit works as the underlying log agent to collect logs and send them to the OpenSearch cluster.","title":"Logs from EKS"},{"location":"implementation-guide/considerations/","text":"Considerations Regional deployments This solution uses services which may not be currently available in all AWS Regions. Launch this solution in an AWS Region where required services are available. For the most current availability by Region, refer to the AWS Regional Services List . Log Hub provides two types of authentication, Cognito User Pool and OpenID Connect (OIDC) Provider . You need to choose to launch the solution with OpenID Connect if one of the following cases occurs: Cognito User Pool is not available in your AWS region. You already have an OpenID Connect Provider. Supported regions for deployment Region Name Launch with Cognito User Pool Launch with OpenID Connect US East (N. Virginia) US East (Ohio) US West (N. California) US West (Oregon) Africa (Cape Town) Asia Pacific (Hong Kong) Asia Pacific (Jakarta) Asia Pacific (Mumbai) Asia Pacific (Osaka) Asia Pacific (Seoul) Asia Pacific (Singapore) Asia Pacific (Sydney) Asia Pacific (Tokyo) Canada (Central) Europe (Frankfurt) Europe (Ireland) Europe (London) Europe (Milan) Europe (Paris) Europe (Stockholm) Middle East (Bahrain) South America (Sao Paulo) China (Beijing) Region Operated by Sinnet China (Ningxia) Regions operated by NWCD Restrictions You can have only one active Log Hub solution stack in one region. If your deployment failed, make sure you have deleted the failed stack before retrying the deployment.","title":"Considerations"},{"location":"implementation-guide/considerations/#considerations","text":"","title":"Considerations"},{"location":"implementation-guide/considerations/#regional-deployments","text":"This solution uses services which may not be currently available in all AWS Regions. Launch this solution in an AWS Region where required services are available. For the most current availability by Region, refer to the AWS Regional Services List . Log Hub provides two types of authentication, Cognito User Pool and OpenID Connect (OIDC) Provider . You need to choose to launch the solution with OpenID Connect if one of the following cases occurs: Cognito User Pool is not available in your AWS region. You already have an OpenID Connect Provider. Supported regions for deployment Region Name Launch with Cognito User Pool Launch with OpenID Connect US East (N. Virginia) US East (Ohio) US West (N. California) US West (Oregon) Africa (Cape Town) Asia Pacific (Hong Kong) Asia Pacific (Jakarta) Asia Pacific (Mumbai) Asia Pacific (Osaka) Asia Pacific (Seoul) Asia Pacific (Singapore) Asia Pacific (Sydney) Asia Pacific (Tokyo) Canada (Central) Europe (Frankfurt) Europe (Ireland) Europe (London) Europe (Milan) Europe (Paris) Europe (Stockholm) Middle East (Bahrain) South America (Sao Paulo) China (Beijing) Region Operated by Sinnet China (Ningxia) Regions operated by NWCD","title":"Regional deployments"},{"location":"implementation-guide/considerations/#restrictions","text":"You can have only one active Log Hub solution stack in one region. If your deployment failed, make sure you have deleted the failed stack before retrying the deployment.","title":"Restrictions"},{"location":"implementation-guide/cost/","text":"Cost Estimation Important The cost estimation described in this section are just examples, which are calculated based on assumptions, and may vary in your environment. You will be responsible for the cost of the AWS services used when running the solution. As of October 2022, the main factors affecting the solution cost include: Type of logs to be ingested Volume of logs to be ingested/processed Size of the log message Location of logs Additional features The following examples will demonstrate the cost estimation of 10/100/1000 GB daily log ingestion. The total cost is composed of Amazon OpenSearch Cost , Processing Cost , and Additional Features Cost . Note All the cost estimation is based on the AWS service price in AWS N. Virginia Region (us-east-1). Amazon OpenSearch Cost OD : On Demand AURI_1 : All Upfront Reserved Instance 1 Year Tiering : The days stored in each tier. For example, 7H + 23W + 60C indicates that the log is stored in hot tier for 7 days, warm tier for 23 days, and cold tier for 60 days. Replica : The number of shard replicas. Daily log Volume (GB) Retention (days) Tiering Replica OD Monthly ($) AURI_1 Monthly ($) Dedicated Master Data Node EBS (GB) UltraWarm Nodes UltraWarm/Cold S3 Storage (GB) OD cost per GB ($) AURI_1 cost per GB ($) 10 30 30H 0 216.28 158.54 N/A c6g.large[2] 380 N/A 0 0.72093 0.52847 10 30 30H 1 289.35 223.94 N/A m6g.large[2] 760 N/A 0 0.9645 0.74647 100 30 7H + 23W 0 989.49 825.97 m6g.large[3] m6g.large[2] 886 medium[2] 0 0.32983 0.27532 100 30 7H + 23W 1 1295.85 1066.92 m6g.large[3] m6g.large[4] 1772 medium[2] 0 0.43195 0.35564 100 90 7H + 23W + 60C 0 1133.49 969.97 m6g.large[3] m6g.large[2] 886 medium[2] 8300 0.12594 0.10777 100 90 7H + 23W + 60C 1 1439.85 1210.92 m6g.large[3] m6g.large[4] 1772 medium[2] 8300 0.15998 0.13455 100 180 7H + 23W + 150C 0 1349.49 1185.97 m6g.large[3] m6g.large[2] 886 medium[2] 17300 0.07497 0.06589 100 180 7H + 23W + 150C 1 1655.85 1426.92 m6g.large[3] m6g.large[4] 1772 medium[2] 17300 0.09199 0.07927 1000 30 7H + 23W 0 6101.15 5489.48 m6g.large[3] r6g.xlarge[6] 8856 medium[15] 23000 0.20337 0.18298 1000 30 7H + 23W 1 8759.49 7635.8 m6g.large[3] r6g.2xlarge[6] 17712 medium[15] 23000 0.29198 0.25453 1000 90 7H + 23W + 60C 0 8027.33 7245.45 m6g.large[3] r6g.xlarge[6] 8856 medium[15] 83000 0.08919 0.0805 1000 90 7H + 23W + 60C 1 10199.49 9075.8 m6g.large[3] r6g.2xlarge[6] 17712 medium[15] 83000 0.11333 0.10084 1000 180 7H + 23W + 150C 0 9701.15 9089.48 m6g.large[3] r6g.xlarge[6] 8856 medium[15] 173000 0.0539 0.0505 1000 180 7H + 23W + 150C 1 12644.19 11420.86 m6g.large[3] r6g.2xlarge[6] 17712 medium[15] 173000 0.07025 0.06345 Processing Cost AWS Service Logs Depending on the log location, the cost of ingesting and processing service logs may vary. Logs in Amazon S3 Note Ingesting AWS service logs from S3 will incur SQS and S3 request fees which are very low, usually within the AWS Free Tier. Here are the assumptions: AWS Services save logs to Amazon S3 every 5 minutes in gzip format (most of AWS services output logs in gzip). A 4MB compressed log file in S3 is roughly 100MB in raw log size. A Lambda with 1GB memory takes about 26 seconds to process a 4MB log file, namely 260 ms per MB raw logs. The maximum compressed log file size is 5MB. You have N GB raw log per day, and the daily cost estimation is as follows: Lambda Cost = 260 ms per MB x 1024 MB x N GB/day x $0.0000000167 per ms S3 Storage Cost = $0.023 per GB x N GB/day * 4% (compression) The total monthly cost for ingesting AWS service logs is: Total Monthly Cost = (Lambda Cost + S3 Storage Cost) x 30 days Daily Log Volume Daily Lambda Cost ($) Daily S3 Storage Cost ($) Monthly Cost ($) 10 0.044 0.009 1.610 100 0.445 0.092 16.099 1000 4.446 0.920 160.986 Application Logs Depending on the log location, the cost of ingesting and processing application logs may vary. Ingest logs from Amazon EC2 Important If you have multiple log formats (index), you need to make cost estimation for each of them. The cost estimation is based on the following assumptions and facts: The average log message size is 1 KB. The Lambda processor memory is 1024 MB. Every Lambda invocation processes 1 MB logs. One Lambda invocation processes one shard of Kinesis, and Lambda can scale up to more concurrent innovations to process multiple shards. The Lambda runtime to process log less than 5 MB is 500ms. One Kinesis shard intake log size is = 1 MB /second x 3600 seconds per hour x 24 hours x 0.7 = 60.48 GB/day. 30% additional shards are provided to handle traffic jitter. The daily log volume is X GB. The desired Kinesis Shard number S is = Round_up_to_next_integer(Daily log volume X / 60.48). Based on the above assumptions, here is the daily cost estimation formula: Kinesis Shard Hour Cost = $0.015 / shard hour x 24 hours per day x S shards Kinesis PUT Payload Unit Cost = $0.014 per million units * 1 millions per GB x X GB per day Lambda Cost = $0.0000000167 per 1ms x 500 ms per invocation x 1,000 invocations per GB x X GB per day Total Monthly Cost = (Kinesis Shard Hour Cost + Kinesis PUT Payload Unit Cost + Lambda Cost) x 30 days Daily Log Volume (GB) Shards Daily Kinesis Shard Hour Cost ($) Daily Kinesis PUT Payload Unit Cost ($) Daily Lambda Cost ($) Monthly Cost ($) 10 1 0.36 0.14 0.0835 17.505 100 2 0.72 1.4 0.835 88.65 1000 17 6.12 14 8.35 854.1 Ingest logs from Amazon EKS Currently, there is no buffer layer between EKS and Amazon OpenSearch, and there is no additional cost. Additional Features Cost Note You will not be charged if you choose not to use the additional features in the Log Hub console. Access Proxy If you deploy the Access Proxy through Log Hub, the following charges will apply. EC2 Cost = t3.large 1Y RI All Upfront $426.612 x 2 / 12 months = $71.1/month EBS Cost = $0.1 GB/month x 8 GB x 2 = $1.6/month Elastic Load Balancer Cost = $0.0225 per ALB-hour x 720 hours/month = $16.2/month Total Monthly Cost = $71.1 EC2 Cost + $1.6 EBS Cost + $16.2 Elastic Load Balancer Cost = $88.9 Alarms If you deploy the Alarms through Log Hub, the CloudWatch Price will apply.","title":"Cost"},{"location":"implementation-guide/cost/#cost-estimation","text":"Important The cost estimation described in this section are just examples, which are calculated based on assumptions, and may vary in your environment. You will be responsible for the cost of the AWS services used when running the solution. As of October 2022, the main factors affecting the solution cost include: Type of logs to be ingested Volume of logs to be ingested/processed Size of the log message Location of logs Additional features The following examples will demonstrate the cost estimation of 10/100/1000 GB daily log ingestion. The total cost is composed of Amazon OpenSearch Cost , Processing Cost , and Additional Features Cost . Note All the cost estimation is based on the AWS service price in AWS N. Virginia Region (us-east-1).","title":"Cost Estimation"},{"location":"implementation-guide/cost/#amazon-opensearch-cost","text":"OD : On Demand AURI_1 : All Upfront Reserved Instance 1 Year Tiering : The days stored in each tier. For example, 7H + 23W + 60C indicates that the log is stored in hot tier for 7 days, warm tier for 23 days, and cold tier for 60 days. Replica : The number of shard replicas. Daily log Volume (GB) Retention (days) Tiering Replica OD Monthly ($) AURI_1 Monthly ($) Dedicated Master Data Node EBS (GB) UltraWarm Nodes UltraWarm/Cold S3 Storage (GB) OD cost per GB ($) AURI_1 cost per GB ($) 10 30 30H 0 216.28 158.54 N/A c6g.large[2] 380 N/A 0 0.72093 0.52847 10 30 30H 1 289.35 223.94 N/A m6g.large[2] 760 N/A 0 0.9645 0.74647 100 30 7H + 23W 0 989.49 825.97 m6g.large[3] m6g.large[2] 886 medium[2] 0 0.32983 0.27532 100 30 7H + 23W 1 1295.85 1066.92 m6g.large[3] m6g.large[4] 1772 medium[2] 0 0.43195 0.35564 100 90 7H + 23W + 60C 0 1133.49 969.97 m6g.large[3] m6g.large[2] 886 medium[2] 8300 0.12594 0.10777 100 90 7H + 23W + 60C 1 1439.85 1210.92 m6g.large[3] m6g.large[4] 1772 medium[2] 8300 0.15998 0.13455 100 180 7H + 23W + 150C 0 1349.49 1185.97 m6g.large[3] m6g.large[2] 886 medium[2] 17300 0.07497 0.06589 100 180 7H + 23W + 150C 1 1655.85 1426.92 m6g.large[3] m6g.large[4] 1772 medium[2] 17300 0.09199 0.07927 1000 30 7H + 23W 0 6101.15 5489.48 m6g.large[3] r6g.xlarge[6] 8856 medium[15] 23000 0.20337 0.18298 1000 30 7H + 23W 1 8759.49 7635.8 m6g.large[3] r6g.2xlarge[6] 17712 medium[15] 23000 0.29198 0.25453 1000 90 7H + 23W + 60C 0 8027.33 7245.45 m6g.large[3] r6g.xlarge[6] 8856 medium[15] 83000 0.08919 0.0805 1000 90 7H + 23W + 60C 1 10199.49 9075.8 m6g.large[3] r6g.2xlarge[6] 17712 medium[15] 83000 0.11333 0.10084 1000 180 7H + 23W + 150C 0 9701.15 9089.48 m6g.large[3] r6g.xlarge[6] 8856 medium[15] 173000 0.0539 0.0505 1000 180 7H + 23W + 150C 1 12644.19 11420.86 m6g.large[3] r6g.2xlarge[6] 17712 medium[15] 173000 0.07025 0.06345","title":"Amazon OpenSearch Cost"},{"location":"implementation-guide/cost/#processing-cost","text":"","title":"Processing Cost"},{"location":"implementation-guide/cost/#aws-service-logs","text":"Depending on the log location, the cost of ingesting and processing service logs may vary.","title":"AWS Service Logs"},{"location":"implementation-guide/cost/#logs-in-amazon-s3","text":"Note Ingesting AWS service logs from S3 will incur SQS and S3 request fees which are very low, usually within the AWS Free Tier. Here are the assumptions: AWS Services save logs to Amazon S3 every 5 minutes in gzip format (most of AWS services output logs in gzip). A 4MB compressed log file in S3 is roughly 100MB in raw log size. A Lambda with 1GB memory takes about 26 seconds to process a 4MB log file, namely 260 ms per MB raw logs. The maximum compressed log file size is 5MB. You have N GB raw log per day, and the daily cost estimation is as follows: Lambda Cost = 260 ms per MB x 1024 MB x N GB/day x $0.0000000167 per ms S3 Storage Cost = $0.023 per GB x N GB/day * 4% (compression) The total monthly cost for ingesting AWS service logs is: Total Monthly Cost = (Lambda Cost + S3 Storage Cost) x 30 days Daily Log Volume Daily Lambda Cost ($) Daily S3 Storage Cost ($) Monthly Cost ($) 10 0.044 0.009 1.610 100 0.445 0.092 16.099 1000 4.446 0.920 160.986","title":"Logs in Amazon S3"},{"location":"implementation-guide/cost/#application-logs","text":"Depending on the log location, the cost of ingesting and processing application logs may vary.","title":"Application Logs"},{"location":"implementation-guide/cost/#ingest-logs-from-amazon-ec2","text":"Important If you have multiple log formats (index), you need to make cost estimation for each of them. The cost estimation is based on the following assumptions and facts: The average log message size is 1 KB. The Lambda processor memory is 1024 MB. Every Lambda invocation processes 1 MB logs. One Lambda invocation processes one shard of Kinesis, and Lambda can scale up to more concurrent innovations to process multiple shards. The Lambda runtime to process log less than 5 MB is 500ms. One Kinesis shard intake log size is = 1 MB /second x 3600 seconds per hour x 24 hours x 0.7 = 60.48 GB/day. 30% additional shards are provided to handle traffic jitter. The daily log volume is X GB. The desired Kinesis Shard number S is = Round_up_to_next_integer(Daily log volume X / 60.48). Based on the above assumptions, here is the daily cost estimation formula: Kinesis Shard Hour Cost = $0.015 / shard hour x 24 hours per day x S shards Kinesis PUT Payload Unit Cost = $0.014 per million units * 1 millions per GB x X GB per day Lambda Cost = $0.0000000167 per 1ms x 500 ms per invocation x 1,000 invocations per GB x X GB per day Total Monthly Cost = (Kinesis Shard Hour Cost + Kinesis PUT Payload Unit Cost + Lambda Cost) x 30 days Daily Log Volume (GB) Shards Daily Kinesis Shard Hour Cost ($) Daily Kinesis PUT Payload Unit Cost ($) Daily Lambda Cost ($) Monthly Cost ($) 10 1 0.36 0.14 0.0835 17.505 100 2 0.72 1.4 0.835 88.65 1000 17 6.12 14 8.35 854.1","title":"Ingest logs from Amazon EC2"},{"location":"implementation-guide/cost/#ingest-logs-from-amazon-eks","text":"Currently, there is no buffer layer between EKS and Amazon OpenSearch, and there is no additional cost.","title":"Ingest logs from Amazon EKS"},{"location":"implementation-guide/cost/#additional-features-cost","text":"Note You will not be charged if you choose not to use the additional features in the Log Hub console.","title":"Additional Features Cost"},{"location":"implementation-guide/cost/#access-proxy","text":"If you deploy the Access Proxy through Log Hub, the following charges will apply. EC2 Cost = t3.large 1Y RI All Upfront $426.612 x 2 / 12 months = $71.1/month EBS Cost = $0.1 GB/month x 8 GB x 2 = $1.6/month Elastic Load Balancer Cost = $0.0225 per ALB-hour x 720 hours/month = $16.2/month Total Monthly Cost = $71.1 EC2 Cost + $1.6 EBS Cost + $16.2 Elastic Load Balancer Cost = $88.9","title":"Access Proxy"},{"location":"implementation-guide/cost/#alarms","text":"If you deploy the Alarms through Log Hub, the CloudWatch Price will apply.","title":"Alarms"},{"location":"implementation-guide/faq/","text":"Frequently Asked Questions General Q: What is Log Hub solution? Log Hub is an AWS Solution that simplifies the building of log analytics pipelines. It provides to customers, as complementary of Amazon OpenSearch Service, capabilities to ingest and process both application logs and AWS service logs without writing code, and create visualization dashboards from out-of-box templates. Log Hub automatically assembles the underlying AWS services, and provides you a web console to manage log analytics pipelines. Q: What are the supported logs in this solution? Log Hub supports both AWS service logs and EC2/EKS application logs. Refer to the supported AWS services , and the supported application log formats and sources for more details. Q: Does Log Hub support ingesting logs from multiple AWS accounts? Yes. Starting from v1.1.0, Log Hub supports ingesting AWS service logs and application logs from a different AWS account in the same region. For more information, see cross-account ingestion . Q: Does Log Hub support ingesting logs from multiple AWS Regions? Currently, Log Hub does not automate the log ingestion from a different AWS Region. You need to ingest logs from other regions into pipelines provisioned by Log Hub. For AWS services which store the logs in S3 bucket, you can leverage the S3 Cross-Region Replication to copy the logs to the Log Hub deployed region, and import incremental logs using the manual mode by specifying the log location in the S3 bucket. For application logs on EC2 and EKS, you need to set up the networking (for example, Kinesis VPC endpoint, VPC Peering), install agents, and configure the agents to ingest logs to Log Hub pipelines. Q: What is the license of this solution? This solution is provided under the Apache-2.0 license . It is a permissive free software license written by the Apache Software Foundation. It allows users to use the software for any purpose, to distribute it, to modify it, and to distribute modified versions of the software under the terms of the license, without concern for royalties. Q: How can I find the roadmap of this solution? This solution uses GitHub project to manage the roadmap. You can find the roadmap here . Q: How can I submit a feature request or bug report? You can submit feature requests and bug report through the GitHub issues. Here are the templates for feature request , bug report . Setup and configuration Q: Can I deploy Log Hub on AWS in any AWS Region? Log Hub provides two deployment options: option 1 with Cognito User Pool, and option 2 with OpenID Connect. For option 1, customers can deploy the solution in AWS Regions where Amazon Cognito User Pool, AWS AppSync, Amazon Kinesis Data Firehose (optional) are available. For option 2, customers can deploy the solution in AWS Regions where AWS AppSync, Amazon Kinesis Data Firehose (optional) are available. Refer to supported regions for deployment for more information. Q: What are the prerequisites of deploying this solution? Log Hub does not provision Amazon OpenSearch clusters, and you need to import existing OpenSearch clusters through the web console. The cluster must meet the requirements specified in prerequisites . Q: Why do I need a domain name with ICP recordal when deploy the solution in AWS China Regions? The Log Hub console is served via CloudFront distribution which is considered as an Internet information service. According to the local regulations, any Internet information service must bind to a domain name with ICP recordal . Q: What versions of OpenSearch does the solution work with? Log Hub supports Amazon OpenSearch Service, with engine version Elasticsearch 7.10 and later, Amazon OpenSearch 1.0 and later. Q: Can I deploy the solution in an existing VPC? Yes. You can either launch the solution with a new VPC or launch the solution with an existing VPC. When using an existing VPC, you need to select the VPC and the corresponding subnets. Refer to launch with Cognito User Pool or launch with OpenID Connect for more details. Pricing Q: How will I be charged and billed for the use of this solution? The solution is free to use, and you are responsible for the cost of AWS services used while running this solution. You pay only for what you use, and there are no minimum or setup fees. Refer to the Log Hub Cost section for detailed cost estimation. Q: Will there be additional cost for cross-account ingestion? No. The cost will be same as ingesting logs within the same AWS account. Log Ingestion Q: What is the log agent used in the Log Hub solution? Log Hub uses AWS for Fluent Bit , a distribution of Fluent Bit maintained by AWS. The solution uses this distribution to ingest logs from Amazon EC2 and Amazon EKS. Q: I have already stored the AWS service logs of member accounts in a centralized logging account. How should I create service log ingestion for member accounts? In this case, you need to deploy the Log Hub solution in the centralized logging account, and ingest AWS service logs using the Manual mode from the logging account. Refer to this guide for ingesting Application Load Balancer logs with Manual mode. You can do the same with other supported AWS services which output logs to S3. Q: Why there are some duplicated records in OpenSearch when ingesting logs via Kinesis Data Streams? This is usually because there is no enough Kinesis Shards to handle the incoming requests. When threshold error occurs in Kinesis, the Fluent Bit agent will retry that chunk . To avoid this issue, you need to estimate your log throughput and set a proper Kinesis shard number. Please refer to the Kinesis Data Streams quotas and limits . Log Hub provides a built-in feature to scale-out and scale-in the Kinesis shards, and it would take a couple of minutes to scale out to the desired number. Log Visualization Q. How can I find the built-in dashboards in OpenSearch? Please refer to the AWS Service Logs and Application Logs to find out if there is a built-in dashboard supported. You also need to turn on the Sample Dashboard option when creating a log analytics pipeline. The dashboard will be inserted into the AOS under Global Tenant . You can switch to the Global Tenant from the top right coder of the OpenSearch Dashboards. Upgrades Q: How can I upgrade the solution? You can use the latest CloudFormation template link to upgrade the Log Hub. Follow the upgrade steps here . Q: Will I lose any data during the upgrading? No. Upgrading will only update the Log Hub console, and it will not affect any existing log ingestion pipelines. Q: How long does the upgrade take? It depends on the Log Hub versions. In most cases, the upgrade will take less than 30 minutes to complete. Q: Can I upgrade to the latest version from any version? You can upgrade to the latest version from last two versions without changes. For example, you can upgrade from v1.0.X or v1.1.X to v1.2.X . If you are not able to upgrade to the latest version, you may need to upgrade to some intermediate versions first.","title":"FAQ"},{"location":"implementation-guide/faq/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"implementation-guide/faq/#general","text":"Q: What is Log Hub solution? Log Hub is an AWS Solution that simplifies the building of log analytics pipelines. It provides to customers, as complementary of Amazon OpenSearch Service, capabilities to ingest and process both application logs and AWS service logs without writing code, and create visualization dashboards from out-of-box templates. Log Hub automatically assembles the underlying AWS services, and provides you a web console to manage log analytics pipelines. Q: What are the supported logs in this solution? Log Hub supports both AWS service logs and EC2/EKS application logs. Refer to the supported AWS services , and the supported application log formats and sources for more details. Q: Does Log Hub support ingesting logs from multiple AWS accounts? Yes. Starting from v1.1.0, Log Hub supports ingesting AWS service logs and application logs from a different AWS account in the same region. For more information, see cross-account ingestion . Q: Does Log Hub support ingesting logs from multiple AWS Regions? Currently, Log Hub does not automate the log ingestion from a different AWS Region. You need to ingest logs from other regions into pipelines provisioned by Log Hub. For AWS services which store the logs in S3 bucket, you can leverage the S3 Cross-Region Replication to copy the logs to the Log Hub deployed region, and import incremental logs using the manual mode by specifying the log location in the S3 bucket. For application logs on EC2 and EKS, you need to set up the networking (for example, Kinesis VPC endpoint, VPC Peering), install agents, and configure the agents to ingest logs to Log Hub pipelines. Q: What is the license of this solution? This solution is provided under the Apache-2.0 license . It is a permissive free software license written by the Apache Software Foundation. It allows users to use the software for any purpose, to distribute it, to modify it, and to distribute modified versions of the software under the terms of the license, without concern for royalties. Q: How can I find the roadmap of this solution? This solution uses GitHub project to manage the roadmap. You can find the roadmap here . Q: How can I submit a feature request or bug report? You can submit feature requests and bug report through the GitHub issues. Here are the templates for feature request , bug report .","title":"General"},{"location":"implementation-guide/faq/#setup-and-configuration","text":"Q: Can I deploy Log Hub on AWS in any AWS Region? Log Hub provides two deployment options: option 1 with Cognito User Pool, and option 2 with OpenID Connect. For option 1, customers can deploy the solution in AWS Regions where Amazon Cognito User Pool, AWS AppSync, Amazon Kinesis Data Firehose (optional) are available. For option 2, customers can deploy the solution in AWS Regions where AWS AppSync, Amazon Kinesis Data Firehose (optional) are available. Refer to supported regions for deployment for more information. Q: What are the prerequisites of deploying this solution? Log Hub does not provision Amazon OpenSearch clusters, and you need to import existing OpenSearch clusters through the web console. The cluster must meet the requirements specified in prerequisites . Q: Why do I need a domain name with ICP recordal when deploy the solution in AWS China Regions? The Log Hub console is served via CloudFront distribution which is considered as an Internet information service. According to the local regulations, any Internet information service must bind to a domain name with ICP recordal . Q: What versions of OpenSearch does the solution work with? Log Hub supports Amazon OpenSearch Service, with engine version Elasticsearch 7.10 and later, Amazon OpenSearch 1.0 and later. Q: Can I deploy the solution in an existing VPC? Yes. You can either launch the solution with a new VPC or launch the solution with an existing VPC. When using an existing VPC, you need to select the VPC and the corresponding subnets. Refer to launch with Cognito User Pool or launch with OpenID Connect for more details.","title":"Setup and configuration"},{"location":"implementation-guide/faq/#pricing","text":"Q: How will I be charged and billed for the use of this solution? The solution is free to use, and you are responsible for the cost of AWS services used while running this solution. You pay only for what you use, and there are no minimum or setup fees. Refer to the Log Hub Cost section for detailed cost estimation. Q: Will there be additional cost for cross-account ingestion? No. The cost will be same as ingesting logs within the same AWS account.","title":"Pricing"},{"location":"implementation-guide/faq/#log-ingestion","text":"Q: What is the log agent used in the Log Hub solution? Log Hub uses AWS for Fluent Bit , a distribution of Fluent Bit maintained by AWS. The solution uses this distribution to ingest logs from Amazon EC2 and Amazon EKS. Q: I have already stored the AWS service logs of member accounts in a centralized logging account. How should I create service log ingestion for member accounts? In this case, you need to deploy the Log Hub solution in the centralized logging account, and ingest AWS service logs using the Manual mode from the logging account. Refer to this guide for ingesting Application Load Balancer logs with Manual mode. You can do the same with other supported AWS services which output logs to S3. Q: Why there are some duplicated records in OpenSearch when ingesting logs via Kinesis Data Streams? This is usually because there is no enough Kinesis Shards to handle the incoming requests. When threshold error occurs in Kinesis, the Fluent Bit agent will retry that chunk . To avoid this issue, you need to estimate your log throughput and set a proper Kinesis shard number. Please refer to the Kinesis Data Streams quotas and limits . Log Hub provides a built-in feature to scale-out and scale-in the Kinesis shards, and it would take a couple of minutes to scale out to the desired number.","title":"Log Ingestion"},{"location":"implementation-guide/faq/#log-visualization","text":"Q. How can I find the built-in dashboards in OpenSearch? Please refer to the AWS Service Logs and Application Logs to find out if there is a built-in dashboard supported. You also need to turn on the Sample Dashboard option when creating a log analytics pipeline. The dashboard will be inserted into the AOS under Global Tenant . You can switch to the Global Tenant from the top right coder of the OpenSearch Dashboards.","title":"Log Visualization"},{"location":"implementation-guide/faq/#upgrades","text":"Q: How can I upgrade the solution? You can use the latest CloudFormation template link to upgrade the Log Hub. Follow the upgrade steps here . Q: Will I lose any data during the upgrading? No. Upgrading will only update the Log Hub console, and it will not affect any existing log ingestion pipelines. Q: How long does the upgrade take? It depends on the Log Hub versions. In most cases, the upgrade will take less than 30 minutes to complete. Q: Can I upgrade to the latest version from any version? You can upgrade to the latest version from last two versions without changes. For example, you can upgrade from v1.0.X or v1.1.X to v1.2.X . If you are not able to upgrade to the latest version, you may need to upgrade to some intermediate versions first.","title":"Upgrades"},{"location":"implementation-guide/release-notes/","text":"Release Notes 1.1.0 August 26, 2022 What's New Support the ingestion of VPC Flow logs with an optional dashboard template. #14 Support the ingestion of AWS Config logs with an optional dashboard template. #15 Add support for ingestion of sampled AWS WAF logs. #16 Support of ingest AWS service logs from other AWS accounts in the same region. #17 Support of ingest application logs from other AWS accounts in the same region. #18 Launch the solution in an existing VPC. #19 Add an article of how to deploy the solution with other region's Cognito User Pool. #20 Add an article of how to deploy the solution with ADFS. #21 Add support for ingesting EKS pod logs directly into OpenSearch #25 Update Upgrade the Lambda runtime from nodejs12.X to newer version. You will not receive the Lambda runtime deprecation warning emails anymore. Upgrade the Lambda runtime from python3.6 to newer version. Upgrade the CDK version to CDK 2.36.0 Bug Fixes OpenSearch cluster details page now can show information for instances with gp3 type of EBS. 1.0.0 June 6, 2022 What's New Support of Amazon CloudTrail logs. Support of Amazon S3 Access logs. Support of Amazon RDS/Aurora MySQL logs (audit, general, error, slow query). Support of Amazon CloudFront standard logs. Support of AWS Lambda logs. Support of Application Load Balancer access logs. Support of AWS WAF logs. Support ingest logs from EC2 and EKS, including Apache HTTP Server, Nginx, Single-line Text, Multi-line Text, JSON format. Support ingest incremental logs from S3, including JSON and single-line text format.","title":"Release Notes"},{"location":"implementation-guide/release-notes/#release-notes","text":"","title":"Release Notes"},{"location":"implementation-guide/release-notes/#110","text":"August 26, 2022 What's New Support the ingestion of VPC Flow logs with an optional dashboard template. #14 Support the ingestion of AWS Config logs with an optional dashboard template. #15 Add support for ingestion of sampled AWS WAF logs. #16 Support of ingest AWS service logs from other AWS accounts in the same region. #17 Support of ingest application logs from other AWS accounts in the same region. #18 Launch the solution in an existing VPC. #19 Add an article of how to deploy the solution with other region's Cognito User Pool. #20 Add an article of how to deploy the solution with ADFS. #21 Add support for ingesting EKS pod logs directly into OpenSearch #25 Update Upgrade the Lambda runtime from nodejs12.X to newer version. You will not receive the Lambda runtime deprecation warning emails anymore. Upgrade the Lambda runtime from python3.6 to newer version. Upgrade the CDK version to CDK 2.36.0 Bug Fixes OpenSearch cluster details page now can show information for instances with gp3 type of EBS.","title":"1.1.0"},{"location":"implementation-guide/release-notes/#100","text":"June 6, 2022 What's New Support of Amazon CloudTrail logs. Support of Amazon S3 Access logs. Support of Amazon RDS/Aurora MySQL logs (audit, general, error, slow query). Support of Amazon CloudFront standard logs. Support of AWS Lambda logs. Support of Application Load Balancer access logs. Support of AWS WAF logs. Support ingest logs from EC2 and EKS, including Apache HTTP Server, Nginx, Single-line Text, Multi-line Text, JSON format. Support ingest incremental logs from S3, including JSON and single-line text format.","title":"1.0.0"},{"location":"implementation-guide/security/","text":"Security When you build systems on AWS infrastructure, security responsibilities are shared between you and AWS. This shared model reduces your operational burden because AWS operates, manages, and controls the components including the host operating system, the virtualization layer, and the physical security of the facilities in which the services operate. For more information about AWS security, see AWS Cloud Security . IAM Roles AWS Identity and Access Management (IAM) roles allow customers to assign granular access policies and permissions to services and users on the AWS Cloud. This solution creates IAM roles that grant the solution\u2019s AWS Lambda functions, AWS AppSync and Amazon Cognito access to create regional resources. Security Groups The security groups created in this solution are designed to control and isolate network traffic between the solution components. We recommend that you review the security groups and further restrict access as needed once the deployment is up and running. Amazon CloudFront This solution deploys a web console hosted in an Amazon Simple Storage Service (Amazon S3) bucket. To help reduce latency and improve security, this solution includes an Amazon CloudFront distribution with an origin access identity, which is a CloudFront user that provides public access to the solution\u2019s website bucket contents. For more information, refer to Restricting Access to Amazon S3 Content by Using an Origin Access Identity in the Amazon CloudFront Developer Guide.","title":"Security"},{"location":"implementation-guide/security/#security","text":"When you build systems on AWS infrastructure, security responsibilities are shared between you and AWS. This shared model reduces your operational burden because AWS operates, manages, and controls the components including the host operating system, the virtualization layer, and the physical security of the facilities in which the services operate. For more information about AWS security, see AWS Cloud Security .","title":"Security"},{"location":"implementation-guide/security/#iam-roles","text":"AWS Identity and Access Management (IAM) roles allow customers to assign granular access policies and permissions to services and users on the AWS Cloud. This solution creates IAM roles that grant the solution\u2019s AWS Lambda functions, AWS AppSync and Amazon Cognito access to create regional resources.","title":"IAM Roles"},{"location":"implementation-guide/security/#security-groups","text":"The security groups created in this solution are designed to control and isolate network traffic between the solution components. We recommend that you review the security groups and further restrict access as needed once the deployment is up and running.","title":"Security Groups"},{"location":"implementation-guide/security/#amazon-cloudfront","text":"This solution deploys a web console hosted in an Amazon Simple Storage Service (Amazon S3) bucket. To help reduce latency and improve security, this solution includes an Amazon CloudFront distribution with an origin access identity, which is a CloudFront user that provides public access to the solution\u2019s website bucket contents. For more information, refer to Restricting Access to Amazon S3 Content by Using an Origin Access Identity in the Amazon CloudFront Developer Guide.","title":"Amazon CloudFront"},{"location":"implementation-guide/solution-components/","text":"The solution consists of the following components: Domain Management This solution uses Amazon OpenSearch Service (AOS) as the underlying engine to store and analyze logs. You can import an existing AOS domain for log ingestion, and provide an access proxy to the AOS dashboards within VPC. Moreover, you can set up recommended CloudWatch alarms for AOS. Analytics Pipelines A log pipeline includes a series of log processing steps, including collecting logs from sources, processing and sending them to Amazon OpenSearch Service for further analysis. Log Hub supports AWS Service log ingestion and server-side application log ingestion. Service Log Pipeline This solution supports out of the box log analysis for AWS service logs, such as Amazon S3 access logs, and ELB access logs. The component is designed to reduce the complexities of building log analytics pipelines for different AWS services with different formats. Application Log Pipeline This solution supports out of the box log analysis for application logs, such as Nginx/Apache logs or general application logs via regex parser. The component uses Fluent Bit as the underlying log agent to collect logs from application servers, and allows you to easily install log agent and monitor the agent health via System Manager.","title":"Solution components"},{"location":"implementation-guide/solution-components/#domain-management","text":"This solution uses Amazon OpenSearch Service (AOS) as the underlying engine to store and analyze logs. You can import an existing AOS domain for log ingestion, and provide an access proxy to the AOS dashboards within VPC. Moreover, you can set up recommended CloudWatch alarms for AOS.","title":"Domain Management"},{"location":"implementation-guide/solution-components/#analytics-pipelines","text":"A log pipeline includes a series of log processing steps, including collecting logs from sources, processing and sending them to Amazon OpenSearch Service for further analysis. Log Hub supports AWS Service log ingestion and server-side application log ingestion.","title":"Analytics Pipelines"},{"location":"implementation-guide/solution-components/#service-log-pipeline","text":"This solution supports out of the box log analysis for AWS service logs, such as Amazon S3 access logs, and ELB access logs. The component is designed to reduce the complexities of building log analytics pipelines for different AWS services with different formats.","title":"Service Log Pipeline"},{"location":"implementation-guide/solution-components/#application-log-pipeline","text":"This solution supports out of the box log analysis for application logs, such as Nginx/Apache logs or general application logs via regex parser. The component uses Fluent Bit as the underlying log agent to collect logs from application servers, and allows you to easily install log agent and monitor the agent health via System Manager.","title":"Application Log Pipeline"},{"location":"implementation-guide/trouble-shooting/","text":"Troubleshooting Errors in Log Hub The following help you to fix errors or problems that you might encounter when using Log Hub. Error: Failed to assume service-linked role arn:x:x:x:/AWSServiceRoleForAppSync The reason for this error is that the account has never used the AWS AppSync service. You can deploy the solution's CloudFormation template again. AWS has already created the role automatically when you encountered the error. You can also go to AWS CloudShell or the local terminal and run the following AWS CLI command to Link AppSync Role aws iam create-service-linked-role --aws-service-name appsync.amazonaws.com Error: Unable to add backend role Log Hub only supports AOS domain with Fine-grained access control enabled. You need to go to AOS console, and edit the Access policy for the AOS domain. Error\uff1aUser xxx is not authorized to perform sts:AssumeRole on resource If you see this error, please make sure you have entered the correct information during cross account setup , and then please wait for several minutes. Log Hub uses AssumeRole for cross-account access. This is the best practice to temporary access the AWS resources in your sub-account. However, these roles created during cross account setup take seconds or minutes to be affective. Error: PutRecords API responded with error='InvalidSignatureException' Fluent-bit agent reports PutRecords API responded with error='InvalidSignatureException', message='The request signature we calculated does not match the signature you provided. Check your AWS Secret Access Key and signing method. Consult the service documentation for details.' Please restart the fluent-bit agent. Eg. on EC2 with Amazon Linux2, run command: sudo service fluent-bit restart Error: PutRecords API responded with error='AccessDeniedException' Fluent-bit agent deployed on EKS Cluster reports \"AccessDeniedException\" when sending records to Kinesis. Verify that the IAM role trust relations are correctly set. With the Log Hub console: Open the Log Hub console. In the left sidebar, under Log Source , choose EKS Clusters . Choose the EKS Cluster that you want to check. Click the IAM Role ARN which will open the IAM Role in AWS Console. Choose the Trust relationships to verify that the OIDC Provider, the service account namespace and conditions are correctly set. You can get more information from Amazon EKS IAM role configuration My CloudFormation stack is stuck on deleting an AWS::Lambda::Function resource when I update the stack. How to resolve it? The Lambda function resides in a VPC, and you need to wait for the associated ENI resource to be deleted. The agent status is offline after I restart the EC2 instance, how can I make it auto start on instance restart? This usually happens if you have installed the logging agent, but restart the instance before you create any Log Ingestion. The Logging Agent will auto restart if there is at least one Log Ingestion. If you have a log ingestion, but the problem still exists, you can use systemctl status fluent-bit to check its status inside the instance. I have switched to Global tenant. However, I still cannot find the dashboard in OpenSearch. This is usually because Log Hub received 403 error from OpenSearch when creating the index template and dashboard. This can be fixed by re-run the Lambda function manually by following the steps below: With the Log Hub console: Open the Log Hub console, and find the AWS Service Log pipeline which has this issue. Copy the first 5 characters from the ID section. Eg. you should copy c169c from ID c169cb23-88f3-4a7e-90d7-4ab4bc18982c Go to AWS Console > Lambda. Paste in function filters. This will filter in all the lambda function created for this AWS Service Log ingestion. Click the Lambda function whose name contains \"OpenSearchHelperFn\". In the Test tab, create a new event with any Event name. Click the Test button to trigger the Lambda, and wait the lambda function to complete. The dashboard should be available in OpenSearch","title":"Troubleshooting"},{"location":"implementation-guide/trouble-shooting/#troubleshooting-errors-in-log-hub","text":"The following help you to fix errors or problems that you might encounter when using Log Hub.","title":"Troubleshooting Errors in Log Hub"},{"location":"implementation-guide/trouble-shooting/#error-failed-to-assume-service-linked-role-arnxxxawsserviceroleforappsync","text":"The reason for this error is that the account has never used the AWS AppSync service. You can deploy the solution's CloudFormation template again. AWS has already created the role automatically when you encountered the error. You can also go to AWS CloudShell or the local terminal and run the following AWS CLI command to Link AppSync Role aws iam create-service-linked-role --aws-service-name appsync.amazonaws.com","title":"Error: Failed to assume service-linked role arn:x:x:x:/AWSServiceRoleForAppSync"},{"location":"implementation-guide/trouble-shooting/#error-unable-to-add-backend-role","text":"Log Hub only supports AOS domain with Fine-grained access control enabled. You need to go to AOS console, and edit the Access policy for the AOS domain.","title":"Error: Unable to add backend role"},{"location":"implementation-guide/trouble-shooting/#erroruser-xxx-is-not-authorized-to-perform-stsassumerole-on-resource","text":"If you see this error, please make sure you have entered the correct information during cross account setup , and then please wait for several minutes. Log Hub uses AssumeRole for cross-account access. This is the best practice to temporary access the AWS resources in your sub-account. However, these roles created during cross account setup take seconds or minutes to be affective.","title":"Error\uff1aUser xxx is not authorized to perform sts:AssumeRole on resource"},{"location":"implementation-guide/trouble-shooting/#error-putrecords-api-responded-with-errorinvalidsignatureexception","text":"Fluent-bit agent reports PutRecords API responded with error='InvalidSignatureException', message='The request signature we calculated does not match the signature you provided. Check your AWS Secret Access Key and signing method. Consult the service documentation for details.' Please restart the fluent-bit agent. Eg. on EC2 with Amazon Linux2, run command: sudo service fluent-bit restart","title":"Error: PutRecords API responded with error='InvalidSignatureException'"},{"location":"implementation-guide/trouble-shooting/#error-putrecords-api-responded-with-erroraccessdeniedexception","text":"Fluent-bit agent deployed on EKS Cluster reports \"AccessDeniedException\" when sending records to Kinesis. Verify that the IAM role trust relations are correctly set. With the Log Hub console: Open the Log Hub console. In the left sidebar, under Log Source , choose EKS Clusters . Choose the EKS Cluster that you want to check. Click the IAM Role ARN which will open the IAM Role in AWS Console. Choose the Trust relationships to verify that the OIDC Provider, the service account namespace and conditions are correctly set. You can get more information from Amazon EKS IAM role configuration","title":"Error: PutRecords API responded with error='AccessDeniedException'"},{"location":"implementation-guide/trouble-shooting/#my-cloudformation-stack-is-stuck-on-deleting-an-awslambdafunction-resource-when-i-update-the-stack-how-to-resolve-it","text":"The Lambda function resides in a VPC, and you need to wait for the associated ENI resource to be deleted.","title":"My CloudFormation stack is stuck on deleting an AWS::Lambda::Function resource when I update the stack. How to resolve it?"},{"location":"implementation-guide/trouble-shooting/#the-agent-status-is-offline-after-i-restart-the-ec2-instance-how-can-i-make-it-auto-start-on-instance-restart","text":"This usually happens if you have installed the logging agent, but restart the instance before you create any Log Ingestion. The Logging Agent will auto restart if there is at least one Log Ingestion. If you have a log ingestion, but the problem still exists, you can use systemctl status fluent-bit to check its status inside the instance.","title":"The agent status is offline after I restart the EC2 instance, how can I make it auto start on instance restart?"},{"location":"implementation-guide/trouble-shooting/#i-have-switched-to-global-tenant-however-i-still-cannot-find-the-dashboard-in-opensearch","text":"This is usually because Log Hub received 403 error from OpenSearch when creating the index template and dashboard. This can be fixed by re-run the Lambda function manually by following the steps below: With the Log Hub console: Open the Log Hub console, and find the AWS Service Log pipeline which has this issue. Copy the first 5 characters from the ID section. Eg. you should copy c169c from ID c169cb23-88f3-4a7e-90d7-4ab4bc18982c Go to AWS Console > Lambda. Paste in function filters. This will filter in all the lambda function created for this AWS Service Log ingestion. Click the Lambda function whose name contains \"OpenSearchHelperFn\". In the Test tab, create a new event with any Event name. Click the Test button to trigger the Lambda, and wait the lambda function to complete. The dashboard should be available in OpenSearch","title":"I have switched to Global tenant. However, I still cannot find the dashboard in OpenSearch."},{"location":"implementation-guide/uninstall/","text":"Uninstall the Log Hub Warning You will encounter IAM role missing error if you delete the Log Hub main stack before you delete the log pipelines. Log Hub console launches additional CloudFormation stacks to ingest logs. If you want to uninstall the Log Hub solution. We recommend you to delete log pipelines (incl. AWS Service log pipelines and application log pipelines) before uninstall the solution. Step 1. Delete Application Log Pipelines Important Please delete all the log ingestion before deleting an application log pipeline. Go to the Log Hub console, in the left sidebar, choose Application Log . Click the application log pipeline to view details. In the ingestion tab, delete all the application log ingestion in the pipeline. Uninstall/Disable the Fluent Bit agent. EC2 (Optional): after removing the log ingestion from EC2 instance group. Fluent Bit will automatically stop ship logs, it is optional for you to stop the Fluent Bit in your instances. Here are the command for stopping Fluent Bit agent. sudo service fluent-bit stop sudo systemctl disable fluent-bit.service EKS DaemonSet (Mandatory): if you have chosen to deploy the Fluent Bit agent using DaemonSet, you need to delete your Fluent Bit agent. Otherwise, the agent will continue ship logs to Log Hub pipelines. kubectl delete -f ~/fluent-bit-logging.yaml EKS SideCar (Mandatory): please remove the fluent-bit agent in your .yaml file, and restart your pod. Delete the Application Log pipeline. Repeat step 2 to Step 5 to delete all your application log pipelines. Step 2. Delete AWS Service Log Pipelines Go to the Log Hub console, in the left sidebar, choose AWS Service Log . Select and delete the AWS Service Log Pipeline one by one. Step 3. Clean up imported OpenSearch domains Delete Access Proxy , if you have created the proxy using Log Hub console. Delete Alarms , if you have created alarms using Log Hub console. Delete VPC peering Connection between Log Hub's VPC and OpenSearch's VPC. Go to AWS VPC Console Click Peering connections in left sidebar. Find and delete the VPC peering connection between the Log Hub's VPC and OpenSearch's VPC. You may not have Peering Connections if you did not use the \"Automatic\" mode when importing OpenSearch domains. (Optional) Remove imported OpenSearch Domains. (This will not delete the Amazon OpenSearch domain in the AWS account.) Step 4. Delete Log Hub stack Go to the CloudFormation console . Find CloudFormation Stack of the Log Hub solution. (Optional) Delete S3 buckets created by Log Hub. Important The S3 bucket whose name contains LoggingBucket is the centralized bucket for your AWS service log. You might have enabled AWS Services to send logs to this S3 bucket. Deleting this bucket will cause AWS Services failed to send logs. Click the CloudFormation stack of the Log Hub solution, and click Resources tab. In search bar, enter AWS::S3::Bucket . This will show all the S3 buckets created by Log Hub solution, and the Physical ID field is the S3 bucket name Go to S3 console, and find the S3 bucket using the bucket name. Empty and Delete the S3 bucket. Delete the CloudFormation Stack of the Log Hub solution","title":"Uninstalling the solution"},{"location":"implementation-guide/uninstall/#uninstall-the-log-hub","text":"Warning You will encounter IAM role missing error if you delete the Log Hub main stack before you delete the log pipelines. Log Hub console launches additional CloudFormation stacks to ingest logs. If you want to uninstall the Log Hub solution. We recommend you to delete log pipelines (incl. AWS Service log pipelines and application log pipelines) before uninstall the solution.","title":"Uninstall the Log Hub"},{"location":"implementation-guide/uninstall/#step-1-delete-application-log-pipelines","text":"Important Please delete all the log ingestion before deleting an application log pipeline. Go to the Log Hub console, in the left sidebar, choose Application Log . Click the application log pipeline to view details. In the ingestion tab, delete all the application log ingestion in the pipeline. Uninstall/Disable the Fluent Bit agent. EC2 (Optional): after removing the log ingestion from EC2 instance group. Fluent Bit will automatically stop ship logs, it is optional for you to stop the Fluent Bit in your instances. Here are the command for stopping Fluent Bit agent. sudo service fluent-bit stop sudo systemctl disable fluent-bit.service EKS DaemonSet (Mandatory): if you have chosen to deploy the Fluent Bit agent using DaemonSet, you need to delete your Fluent Bit agent. Otherwise, the agent will continue ship logs to Log Hub pipelines. kubectl delete -f ~/fluent-bit-logging.yaml EKS SideCar (Mandatory): please remove the fluent-bit agent in your .yaml file, and restart your pod. Delete the Application Log pipeline. Repeat step 2 to Step 5 to delete all your application log pipelines.","title":"Step 1. Delete Application Log Pipelines"},{"location":"implementation-guide/uninstall/#step-2-delete-aws-service-log-pipelines","text":"Go to the Log Hub console, in the left sidebar, choose AWS Service Log . Select and delete the AWS Service Log Pipeline one by one.","title":"Step 2. Delete AWS Service Log Pipelines"},{"location":"implementation-guide/uninstall/#step-3-clean-up-imported-opensearch-domains","text":"Delete Access Proxy , if you have created the proxy using Log Hub console. Delete Alarms , if you have created alarms using Log Hub console. Delete VPC peering Connection between Log Hub's VPC and OpenSearch's VPC. Go to AWS VPC Console Click Peering connections in left sidebar. Find and delete the VPC peering connection between the Log Hub's VPC and OpenSearch's VPC. You may not have Peering Connections if you did not use the \"Automatic\" mode when importing OpenSearch domains. (Optional) Remove imported OpenSearch Domains. (This will not delete the Amazon OpenSearch domain in the AWS account.)","title":"Step 3. Clean up imported OpenSearch domains"},{"location":"implementation-guide/uninstall/#step-4-delete-log-hub-stack","text":"Go to the CloudFormation console . Find CloudFormation Stack of the Log Hub solution. (Optional) Delete S3 buckets created by Log Hub. Important The S3 bucket whose name contains LoggingBucket is the centralized bucket for your AWS service log. You might have enabled AWS Services to send logs to this S3 bucket. Deleting this bucket will cause AWS Services failed to send logs. Click the CloudFormation stack of the Log Hub solution, and click Resources tab. In search bar, enter AWS::S3::Bucket . This will show all the S3 buckets created by Log Hub solution, and the Physical ID field is the S3 bucket name Go to S3 console, and find the S3 bucket using the bucket name. Empty and Delete the S3 bucket. Delete the CloudFormation Stack of the Log Hub solution","title":"Step 4. Delete Log Hub stack"},{"location":"implementation-guide/upgrade/","text":"Upgrade Log Hub Time to upgrade : Approximately 20 minutes Upgrade Overview Use the following steps to upgrade the solution on AWS console. Step 1. Update the CloudFormation Stack Step 2. Trigger Lambda to refresh web config Step 3. Create an invalidation on CloudFront Step 4. Refresh the web console Step 1. Update the CloudFormation stack Go to the AWS CloudFormation console . Select the Log Hub main stack, and click the Update button. Choose Replace current template , and enter the specific Amazon S3 URL according to your initial deployment type. Refer to Deployment Overview for more details. Type Link Launch with Cogito User Pool & New VPC https://aws-gcr-solutions.s3.amazonaws.com/log-hub/latest/LogHub.template Launch with Cognito User Pool & Existing VPC https://aws-gcr-solutions.s3.amazonaws.com/log-hub/latest/LogHubFromExistingVPC.template Launch with OpenID Connect & New VPC https://aws-gcr-solutions.s3.amazonaws.com/log-hub/latest/LogHubWithOIDC.template Launch with OpenID Connect & Existing VPC https://aws-gcr-solutions.s3.amazonaws.com/log-hub/latest/LogHubFromExistingVPCWithOIDC.template Under Parameters , review the parameters for the template and modify them as necessary. Choose Next . On Configure stack options page, choose Next . On Review page, review and confirm the settings. Check the box I acknowledge that AWS CloudFormation might create IAM resources . Choose Update stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a UPDATE_COMPLETE status in approximately 15 minutes. Step 2. Generate new web console configuration file After the stack is successfully updated, you need to generate the console configuration. Log Hub uses a preset Lambda to generate the configuration file. Go to the AWS Lambda console . Search for a Lambda with WebConsoleWebConfig in the name. The Lambda Function Name is in the format of <StackName>-WebConsoleWebConfigXXXXX-XXXX . In the Test page, create a new event with any Event name. Click the Test button to trigger the Lambda, and ensure that you can see the Put config file to S3 and Put config file to S3 completed. log message. Step 3. Create an invalidation on CloudFront CloudFront has cached an old version of Log Hub console at its pop locations. We need to create an invalidation on the CloudFront console to force the deletion of cache. You must do this after thew console configuration file being generated. Go to the AWS CloudFront console . Choose the Distribution of Log Hub. The Description is like SolutionName - Web Console Distribution (RegionName) . On the Invalidation page, click Create invalidation , and create an invalidation with /* . Step 4. Refresh the web console Now you have completed all the upgrade steps. Please click the refresh button in your browser. You can check the new version number in the bottom right corner of the Log Hub console. Upgrade Notice Application Logs from EC2 Log Hub has an updated IAM policy after v1.1.0. If you have created an Application Log Pipeline in Log Hub V1.0.X, and want to create a new Application Log Ingestion in v1.1.0 or later versions, you will receive an upgrade notice popup: Click the Upgrade button to upgrade your Application Log Pipeline to the current version, This upgrade will not affect your existing log ingestion which were created in Log Hub V1.0.X. However, please make sure you have updated IAM Policy to the EC2 instance profile before creating a new ingestion . Application Logs from EKS Log Hub has updated the default architecture for ingesting application logs from EKS. In Log Hub V1.1.0 or later version, by default, Log Hub ingests EKS pod logs directly into Amazon OpenSearch. This upgrade will not affect your existing log ingestion created in Log Hub V1.0.x. For example, if you have log ingestion created in Log Hub V1.0.x, and have created a new log ingestion in Log Hub V1.1.0. Log Hub will send the logs ingested in V1.0.x to OpenSearch through Amazon Kinesis Data Stream, and send the logs ingested in V1.1.0 to OpenSearch directly.","title":"Upgrading the solution"},{"location":"implementation-guide/upgrade/#upgrade-log-hub","text":"Time to upgrade : Approximately 20 minutes","title":"Upgrade Log Hub"},{"location":"implementation-guide/upgrade/#upgrade-overview","text":"Use the following steps to upgrade the solution on AWS console. Step 1. Update the CloudFormation Stack Step 2. Trigger Lambda to refresh web config Step 3. Create an invalidation on CloudFront Step 4. Refresh the web console","title":"Upgrade Overview"},{"location":"implementation-guide/upgrade/#step-1-update-the-cloudformation-stack","text":"Go to the AWS CloudFormation console . Select the Log Hub main stack, and click the Update button. Choose Replace current template , and enter the specific Amazon S3 URL according to your initial deployment type. Refer to Deployment Overview for more details. Type Link Launch with Cogito User Pool & New VPC https://aws-gcr-solutions.s3.amazonaws.com/log-hub/latest/LogHub.template Launch with Cognito User Pool & Existing VPC https://aws-gcr-solutions.s3.amazonaws.com/log-hub/latest/LogHubFromExistingVPC.template Launch with OpenID Connect & New VPC https://aws-gcr-solutions.s3.amazonaws.com/log-hub/latest/LogHubWithOIDC.template Launch with OpenID Connect & Existing VPC https://aws-gcr-solutions.s3.amazonaws.com/log-hub/latest/LogHubFromExistingVPCWithOIDC.template Under Parameters , review the parameters for the template and modify them as necessary. Choose Next . On Configure stack options page, choose Next . On Review page, review and confirm the settings. Check the box I acknowledge that AWS CloudFormation might create IAM resources . Choose Update stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a UPDATE_COMPLETE status in approximately 15 minutes.","title":"Step 1. Update the CloudFormation stack"},{"location":"implementation-guide/upgrade/#step-2-generate-new-web-console-configuration-file","text":"After the stack is successfully updated, you need to generate the console configuration. Log Hub uses a preset Lambda to generate the configuration file. Go to the AWS Lambda console . Search for a Lambda with WebConsoleWebConfig in the name. The Lambda Function Name is in the format of <StackName>-WebConsoleWebConfigXXXXX-XXXX . In the Test page, create a new event with any Event name. Click the Test button to trigger the Lambda, and ensure that you can see the Put config file to S3 and Put config file to S3 completed. log message.","title":"Step 2. Generate new web console configuration file"},{"location":"implementation-guide/upgrade/#step-3-create-an-invalidation-on-cloudfront","text":"CloudFront has cached an old version of Log Hub console at its pop locations. We need to create an invalidation on the CloudFront console to force the deletion of cache. You must do this after thew console configuration file being generated. Go to the AWS CloudFront console . Choose the Distribution of Log Hub. The Description is like SolutionName - Web Console Distribution (RegionName) . On the Invalidation page, click Create invalidation , and create an invalidation with /* .","title":"Step 3. Create an invalidation on CloudFront"},{"location":"implementation-guide/upgrade/#step-4-refresh-the-web-console","text":"Now you have completed all the upgrade steps. Please click the refresh button in your browser. You can check the new version number in the bottom right corner of the Log Hub console.","title":"Step 4. Refresh the web console"},{"location":"implementation-guide/upgrade/#upgrade-notice","text":"","title":"Upgrade Notice"},{"location":"implementation-guide/upgrade/#application-logs-from-ec2","text":"Log Hub has an updated IAM policy after v1.1.0. If you have created an Application Log Pipeline in Log Hub V1.0.X, and want to create a new Application Log Ingestion in v1.1.0 or later versions, you will receive an upgrade notice popup: Click the Upgrade button to upgrade your Application Log Pipeline to the current version, This upgrade will not affect your existing log ingestion which were created in Log Hub V1.0.X. However, please make sure you have updated IAM Policy to the EC2 instance profile before creating a new ingestion .","title":"Application Logs from EC2"},{"location":"implementation-guide/upgrade/#application-logs-from-eks","text":"Log Hub has updated the default architecture for ingesting application logs from EKS. In Log Hub V1.1.0 or later version, by default, Log Hub ingests EKS pod logs directly into Amazon OpenSearch. This upgrade will not affect your existing log ingestion created in Log Hub V1.0.x. For example, if you have log ingestion created in Log Hub V1.0.x, and have created a new log ingestion in Log Hub V1.1.0. Log Hub will send the logs ingested in V1.0.x to OpenSearch through Amazon Kinesis Data Stream, and send the logs ingested in V1.1.0 to OpenSearch directly.","title":"Application Logs from EKS"},{"location":"implementation-guide/applications/","text":"Macro Syntax Error Line 11 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-supported-app-logs.md\"","title":"Overview"},{"location":"implementation-guide/applications/#macro-syntax-error","text":"Line 11 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-supported-app-logs.md\"","title":"Macro Syntax Error"},{"location":"implementation-guide/applications/apache/","text":"Macro Syntax Error Line 6 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-prerequisites.md\"","title":"Apache HTTP Server"},{"location":"implementation-guide/applications/apache/#macro-syntax-error","text":"Line 6 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-prerequisites.md\"","title":"Macro Syntax Error"},{"location":"implementation-guide/applications/create-applog-pipeline/","text":"Sign in to the Log Hub Console. In the left sidebar, under Log Analytics Pipelines , choose Application Log . Click the Create a pipeline . Specify Index name in lowercase. In the Buffer(Amazon Kinesis Data Streams) section, specify the initial shard number. Important You may observe duplicated logs in OpenSearch if there is threshold error occurs in Kinesis Data Streams (KDS). This is because the Fluent Bit log agent uploads logs in chunk (contains multiple records), and will retry the chunk if upload failed. Each KDS shard can support up to 1,000 records per second for writes, up to a maximum total data write rate of 1 MB per second. Please estimate your log volume and choose an appropriate shard number. (Optional) Select Yes to enable auto scaling of the Kinesis Data Streams shards based on the input logs traffic by and specify maximum shard number. Choose Next . In the Specify OpenSearch domain section, select an imported domain for Amazon OpenSearch domain . In the Log Lifecycle section, input the number of days to manage the AOS index lifecycle. The Log Hub will create the associated Index State Management (ISM) policy automatically for this pipeline. Choose Next . Add tags if needed. Choose Create . Wait for the application pipeline turning to \"Active\" state.","title":"Create an application pipeline"},{"location":"implementation-guide/applications/create-log-ingestion/","text":"Instance Group as Log Source Sign in to the Log Hub Console. In the left sidebar, under Log Analytics Pipelines , choose Application Log . Click on the application pipeline that has been created during the Prerequisites . Go to Permission tab and copy the provided JSON policy. Go to AWS Console > IAM > Policies on the left column, and Click Create Policy , choose JSON and replace all the content inside the text block. Remember to substitute <YOUR ACCOUNT ID> with your account id. Choose Next , Next , then enter the name for this policy. For example: loghub-ec2-policy . Attach the policy to your EC2 instances role to allow the log agent have permissions to send logs to the application log pipeline. Click the Create an Ingestion dropdown menu, and select From Instance Group . Select Choose exists and choose Next . Select the instance group you have created during the Prerequisites and choose Next . Select Choose exists and select the log config created in previous setup. Choose Next , then choose Create . EKS Cluster as Log Source Sign in to the Log Hub Console. In the left sidebar, under Log Source , choose EKS Clusters . Click the EKS Cluster that has been imported as Log Source during the Prerequisites . Go to App Log Ingestion tab and click Create an Ingestion . Select Choose exists and choose the application pipeline that has been created during the Prerequisites . Choose Next . Select the log config created in previous setup, and choose Next . Add tags as needed, then choose Create to finish creating an ingestion. Deploy Fluent-bit logging agent following the guide generated by Log Hub. Select the App Log Ingestion just created. Follow DaemonSet or Sidecar Guide to deploy the logging agent. S3 Bucket as Log Source Sign in to the Log Hub Console. In the left sidebar, under Log Analytics Pipelines , choose Application Log . Click on the application pipeline that has been created during the Prerequisites . Click the Create an Ingestion dropdown menu, and select From S3 Bucket . Fill in all the form fields to specify S3 Log Source. Choose Next . Select the log config created in previous setup, and choose Next . Add tags as needed, then choose Create to finish creating an ingestion.","title":"Create log ingestion"},{"location":"implementation-guide/applications/create-log-ingestion/#instance-group-as-log-source","text":"Sign in to the Log Hub Console. In the left sidebar, under Log Analytics Pipelines , choose Application Log . Click on the application pipeline that has been created during the Prerequisites . Go to Permission tab and copy the provided JSON policy. Go to AWS Console > IAM > Policies on the left column, and Click Create Policy , choose JSON and replace all the content inside the text block. Remember to substitute <YOUR ACCOUNT ID> with your account id. Choose Next , Next , then enter the name for this policy. For example: loghub-ec2-policy . Attach the policy to your EC2 instances role to allow the log agent have permissions to send logs to the application log pipeline. Click the Create an Ingestion dropdown menu, and select From Instance Group . Select Choose exists and choose Next . Select the instance group you have created during the Prerequisites and choose Next . Select Choose exists and select the log config created in previous setup. Choose Next , then choose Create .","title":"Instance Group as Log Source"},{"location":"implementation-guide/applications/create-log-ingestion/#eks-cluster-as-log-source","text":"Sign in to the Log Hub Console. In the left sidebar, under Log Source , choose EKS Clusters . Click the EKS Cluster that has been imported as Log Source during the Prerequisites . Go to App Log Ingestion tab and click Create an Ingestion . Select Choose exists and choose the application pipeline that has been created during the Prerequisites . Choose Next . Select the log config created in previous setup, and choose Next . Add tags as needed, then choose Create to finish creating an ingestion. Deploy Fluent-bit logging agent following the guide generated by Log Hub. Select the App Log Ingestion just created. Follow DaemonSet or Sidecar Guide to deploy the logging agent.","title":"EKS Cluster as Log Source"},{"location":"implementation-guide/applications/create-log-ingestion/#s3-bucket-as-log-source","text":"Sign in to the Log Hub Console. In the left sidebar, under Log Analytics Pipelines , choose Application Log . Click on the application pipeline that has been created during the Prerequisites . Click the Create an Ingestion dropdown menu, and select From S3 Bucket . Fill in all the form fields to specify S3 Log Source. Choose Next . Select the log config created in previous setup, and choose Next . Add tags as needed, then choose Create to finish creating an ingestion.","title":"S3 Bucket as Log Source"},{"location":"implementation-guide/applications/create-log-source/","text":"You need to create a log source first before collecting application logs. Log Hub supports the following log sources: EC2 instance group EKS cluster Amazon S3 For more information, see concepts . Create an EC2 instance group as the log source An instance group means a group of EC2 Linux instances which host the same application. It is a way to associate a Log Config with a group of EC2 instances. Log Hub uses Systems Manager Agent(SSM Agent) to install/configure Fluent Bit agent, and sends log data to Kinesis Data Streams . Prerequisites Make sure the instances meet the following requirements: SSM agent is installed on instances. Refer to install SSM agent on EC2 instances for Linux for more details. The AmazonSSMManagedInstanceCore policy is being associated with the instances. The OpenSSL 1.1 or later is installed. Refer to OpenSSL Installation for more details. The instances have network access to AWS Systems Manager. The instances have network access to Amazon Kinesis Data Streams. The operating system of the instances are supported by Fluent Bit. Refer to Supported Platform . Steps Sign in to the Log Hub Console. In the left sidebar, under Log Source , choose Instance Group . Click the Create an instance group button. In the Settings section, specify a group name. In the Instances section, select the instance from which you want to collect logs. You can add up to 5 tags to filter instances. Verify that all the selected instances \"Pending Status\" is Online . (Optional) If the selected instances \"Pending Status\" are empty, click the Install log agent button and wait for \"Pending Status\" to become Online . (Optional) If you want to ingest logs from another account, select a linked account in the Account Settings section to create an instance group log source from another account. Choose Create . Known issue Use the Log Hub console to install Fluent Bit agent on Ubuntu instances in Beijing (cn-north-1) and Ningxia (cn-northwest-1) Region will cause installation error. The Fluent Bit assets cannot be downloaded successfully. You need to install the Fluent Bit agent by yourself. Import an EKS cluster as the log source The EKS Cluster in Log Hub refers to the Amazon Elastic Kubernetes Service (Amazon EKS) from which you want to collect pod logs. Log Hub will guide you to deploy the logging agent as a DaemonSet or Sidecar in the EKS Cluster. Important Log Hub does not support sending logs in one EKS cluster to more than one Amazon OpenSearch domain at same time. VPC peering connection between the log source EKS and the log destination OpenSearch is required if they are in different VPCs. Important Please make sure your EKS cluster's VPC is connected to AOS cluster' VPC so that log can be ingested. Refer to VPC Connectivity for more details regarding approaches to connect VPCs. Sign in to the Log Hub Console. In the left sidebar, under Log Source , choose EKS Cluster . Click the Import a Cluster button. Choose the EKS Cluster where Log Hub collects logs from. (Optional) If you want to ingest logs from another account, select a linked account from the Account dropdown to import an EKS log source from another account. Select DaemonSet or Sidecar as logging agent's deployment pattern. Choose Next . Specify the Amazon OpenSearch where Log Hub sends the logs to. Follow the guidance to establish a VPC peering connection between EKS's VPC and OpenSearch's VPC. Create and accept VPC peering connections Update your route tables for a VPC peering connection Update your security groups to reference peer VPC groups Choose Next . Add tags if needed. Choose Create . Amazon S3 as the log source Note The Amazon S3 bucket must be in the same region as your Log Hub region. An Amazon S3 bucket in Log Hub refers to a bucket where your application log are stored. You do not need to create a specific log source from Log Hub Console.","title":"Create a Log Source"},{"location":"implementation-guide/applications/create-log-source/#create-an-ec2-instance-group-as-the-log-source","text":"An instance group means a group of EC2 Linux instances which host the same application. It is a way to associate a Log Config with a group of EC2 instances. Log Hub uses Systems Manager Agent(SSM Agent) to install/configure Fluent Bit agent, and sends log data to Kinesis Data Streams .","title":"Create an EC2 instance group as the log source"},{"location":"implementation-guide/applications/create-log-source/#prerequisites","text":"Make sure the instances meet the following requirements: SSM agent is installed on instances. Refer to install SSM agent on EC2 instances for Linux for more details. The AmazonSSMManagedInstanceCore policy is being associated with the instances. The OpenSSL 1.1 or later is installed. Refer to OpenSSL Installation for more details. The instances have network access to AWS Systems Manager. The instances have network access to Amazon Kinesis Data Streams. The operating system of the instances are supported by Fluent Bit. Refer to Supported Platform .","title":"Prerequisites"},{"location":"implementation-guide/applications/create-log-source/#steps","text":"Sign in to the Log Hub Console. In the left sidebar, under Log Source , choose Instance Group . Click the Create an instance group button. In the Settings section, specify a group name. In the Instances section, select the instance from which you want to collect logs. You can add up to 5 tags to filter instances. Verify that all the selected instances \"Pending Status\" is Online . (Optional) If the selected instances \"Pending Status\" are empty, click the Install log agent button and wait for \"Pending Status\" to become Online . (Optional) If you want to ingest logs from another account, select a linked account in the Account Settings section to create an instance group log source from another account. Choose Create . Known issue Use the Log Hub console to install Fluent Bit agent on Ubuntu instances in Beijing (cn-north-1) and Ningxia (cn-northwest-1) Region will cause installation error. The Fluent Bit assets cannot be downloaded successfully. You need to install the Fluent Bit agent by yourself.","title":"Steps"},{"location":"implementation-guide/applications/create-log-source/#import-an-eks-cluster-as-the-log-source","text":"The EKS Cluster in Log Hub refers to the Amazon Elastic Kubernetes Service (Amazon EKS) from which you want to collect pod logs. Log Hub will guide you to deploy the logging agent as a DaemonSet or Sidecar in the EKS Cluster. Important Log Hub does not support sending logs in one EKS cluster to more than one Amazon OpenSearch domain at same time. VPC peering connection between the log source EKS and the log destination OpenSearch is required if they are in different VPCs. Important Please make sure your EKS cluster's VPC is connected to AOS cluster' VPC so that log can be ingested. Refer to VPC Connectivity for more details regarding approaches to connect VPCs. Sign in to the Log Hub Console. In the left sidebar, under Log Source , choose EKS Cluster . Click the Import a Cluster button. Choose the EKS Cluster where Log Hub collects logs from. (Optional) If you want to ingest logs from another account, select a linked account from the Account dropdown to import an EKS log source from another account. Select DaemonSet or Sidecar as logging agent's deployment pattern. Choose Next . Specify the Amazon OpenSearch where Log Hub sends the logs to. Follow the guidance to establish a VPC peering connection between EKS's VPC and OpenSearch's VPC. Create and accept VPC peering connections Update your route tables for a VPC peering connection Update your security groups to reference peer VPC groups Choose Next . Add tags if needed. Choose Create .","title":"Import an EKS cluster as the log source"},{"location":"implementation-guide/applications/create-log-source/#amazon-s3-as-the-log-source","text":"Note The Amazon S3 bucket must be in the same region as your Log Hub region. An Amazon S3 bucket in Log Hub refers to a bucket where your application log are stored. You do not need to create a specific log source from Log Hub Console.","title":"Amazon S3 as the log source"},{"location":"implementation-guide/applications/fluent-bit-install-guide/","text":"Fluent-bit installation guide Currently, Log hub uses fluent-bit as the logging agent. The prerequisites for different operating system are different. Amazon Linux 2 sudo yum install openssl11 CentOS 7 cd /tmp sudo yum install -y unzip gcc perl curl -SL https://github.com/openssl/openssl/archive/OpenSSL_1_1_1-stable.zip -o OpenSSL_1_1_1-stable.zip unzip OpenSSL_1_1_1-stable.zip cd openssl-OpenSSL_1_1_1-stable/ ./config sudo make install sudo echo \"/usr/local/lib64/\" >> /etc/ld.so.conf sudo ldconfig Ubuntu Ubuntu 20.04 ln -s /usr/lib/x86_64-linux-gnu/libsasl2.so /usr/lib/libsasl2.so.3 Ubuntu 18.04 ln -s /usr/lib/x86_64-linux-gnu/libsasl2.so.2 /usr/lib/libsasl2.so.3 Red Hat Enterprise Linux 8.5 None Debian Debian GNU/10 ln -s /usr/lib/x86_64-linux-gnu/libsasl2.so.2 /usr/lib/libsasl2.so.3 Debian GNU/11 ln -s /usr/lib/x86_64-linux-gnu/libsasl2.so.2 /usr/lib/libsasl2.so.3 SUSE Linux Enterprise Server 15 None","title":"Fluent-bit installation guide"},{"location":"implementation-guide/applications/fluent-bit-install-guide/#fluent-bit-installation-guide","text":"Currently, Log hub uses fluent-bit as the logging agent. The prerequisites for different operating system are different.","title":"Fluent-bit installation guide"},{"location":"implementation-guide/applications/fluent-bit-install-guide/#amazon-linux-2","text":"sudo yum install openssl11","title":"Amazon Linux 2"},{"location":"implementation-guide/applications/fluent-bit-install-guide/#centos-7","text":"cd /tmp sudo yum install -y unzip gcc perl curl -SL https://github.com/openssl/openssl/archive/OpenSSL_1_1_1-stable.zip -o OpenSSL_1_1_1-stable.zip unzip OpenSSL_1_1_1-stable.zip cd openssl-OpenSSL_1_1_1-stable/ ./config sudo make install sudo echo \"/usr/local/lib64/\" >> /etc/ld.so.conf sudo ldconfig","title":"CentOS 7"},{"location":"implementation-guide/applications/fluent-bit-install-guide/#ubuntu","text":"","title":"Ubuntu"},{"location":"implementation-guide/applications/fluent-bit-install-guide/#ubuntu-2004","text":"ln -s /usr/lib/x86_64-linux-gnu/libsasl2.so /usr/lib/libsasl2.so.3","title":"Ubuntu 20.04"},{"location":"implementation-guide/applications/fluent-bit-install-guide/#ubuntu-1804","text":"ln -s /usr/lib/x86_64-linux-gnu/libsasl2.so.2 /usr/lib/libsasl2.so.3","title":"Ubuntu 18.04"},{"location":"implementation-guide/applications/fluent-bit-install-guide/#red-hat-enterprise-linux-85","text":"None","title":"Red Hat Enterprise Linux 8.5"},{"location":"implementation-guide/applications/fluent-bit-install-guide/#debian","text":"","title":"Debian"},{"location":"implementation-guide/applications/fluent-bit-install-guide/#debian-gnu10","text":"ln -s /usr/lib/x86_64-linux-gnu/libsasl2.so.2 /usr/lib/libsasl2.so.3","title":"Debian GNU/10"},{"location":"implementation-guide/applications/fluent-bit-install-guide/#debian-gnu11","text":"ln -s /usr/lib/x86_64-linux-gnu/libsasl2.so.2 /usr/lib/libsasl2.so.3","title":"Debian GNU/11"},{"location":"implementation-guide/applications/fluent-bit-install-guide/#suse-linux-enterprise-server-15","text":"None","title":"SUSE Linux Enterprise Server 15"},{"location":"implementation-guide/applications/include-prerequisites/","text":"Make sure you have done the following: Import an AOS domain . Create a log source . Create an application log pipeline .","title":"Include prerequisites"},{"location":"implementation-guide/applications/include-supported-app-logs/","text":"Log Format EC2 Instance Group EKS Cluster S3 Bucket Nginx Yes Yes No Apache HTTP Server Yes Yes No JSON Yes Yes Yes Single-line Text Yes Yes Yes Multi-line Text Yes Yes No Multi-line Text (Spring Boot) Yes Yes No","title":"Include supported app logs"},{"location":"implementation-guide/applications/json/","text":"Macro Syntax Error Line 7 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-prerequisites.md\"","title":"JSON"},{"location":"implementation-guide/applications/json/#macro-syntax-error","text":"Line 7 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-prerequisites.md\"","title":"Macro Syntax Error"},{"location":"implementation-guide/applications/multi-line-text/","text":"Macro Syntax Error Line 8 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-prerequisites.md\"","title":"Multiline-line Text"},{"location":"implementation-guide/applications/multi-line-text/#macro-syntax-error","text":"Line 8 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-prerequisites.md\"","title":"Macro Syntax Error"},{"location":"implementation-guide/applications/nginx/","text":"Macro Syntax Error Line 6 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-prerequisites.md\"","title":"Nginx"},{"location":"implementation-guide/applications/nginx/#macro-syntax-error","text":"Line 6 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-prerequisites.md\"","title":"Macro Syntax Error"},{"location":"implementation-guide/applications/single-line-text/","text":"Macro Syntax Error Line 8 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-prerequisites.md\"","title":"Single-line Text"},{"location":"implementation-guide/applications/single-line-text/#macro-syntax-error","text":"Line 8 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-prerequisites.md\"","title":"Macro Syntax Error"},{"location":"implementation-guide/aws-services/","text":"Macro Syntax Error Line 16 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-supported-service-logs.md\"","title":"Overview"},{"location":"implementation-guide/aws-services/#macro-syntax-error","text":"Line 16 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-supported-service-logs.md\"","title":"Macro Syntax Error"},{"location":"implementation-guide/aws-services/cloudfront/","text":"Macro Syntax Error Line 39 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-cfn-common.md\"","title":"Amazon CloudFront"},{"location":"implementation-guide/aws-services/cloudfront/#macro-syntax-error","text":"Line 39 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-cfn-common.md\"","title":"Macro Syntax Error"},{"location":"implementation-guide/aws-services/cloudtrail/","text":"Macro Syntax Error Line 34 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-cfn-common.md\"","title":"Amazon CloudTrail"},{"location":"implementation-guide/aws-services/cloudtrail/#macro-syntax-error","text":"Line 34 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-cfn-common.md\"","title":"Macro Syntax Error"},{"location":"implementation-guide/aws-services/config/","text":"Macro Syntax Error Line 40 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-cfn-common.md\"","title":"AWS Config"},{"location":"implementation-guide/aws-services/config/#macro-syntax-error","text":"Line 40 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-cfn-common.md\"","title":"Macro Syntax Error"},{"location":"implementation-guide/aws-services/elb/","text":"Macro Syntax Error Line 41 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-cfn-common.md\"","title":"Elastic Load Balancing"},{"location":"implementation-guide/aws-services/elb/#macro-syntax-error","text":"Line 41 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-cfn-common.md\"","title":"Macro Syntax Error"},{"location":"implementation-guide/aws-services/include-cfn-common/","text":"Log in to the AWS Management Console and select above button to launch the AWS CloudFormation template. You can also download the template as a starting point for your own implementation. To launch the stack in a different AWS Region, use the Region selector in the console navigation bar. On the Create stack page, verify that the correct template URL shows in the Amazon S3 URL text box and choose Next . On the Specify stack details page, assign a name to your solution stack. Under Parameters , review the parameters for the template and modify them as necessary. This solution uses the following parameters. Parameter Default Description Log Bucket Name <Requires input> The S3 bucket name which stores the logs. Log Bucket Prefix <Requires input> The S3 bucket path prefix which stores the logs. Log Source Account ID <Optional input> The AWS Account ID of the S3 bucket. Required for cross-account log ingestion (Please link an account first). By default, the Account ID you logged in at Step 1 will be used. Log Source Region <Optional input> The AWS Region of the S3 bucket. By default, the Region you selected at Step 2 will be used. Log Source Account Assume Role <Optional input> The IAM Role ARN used for cross-account log ingestion. Required for cross-account log ingestion (Please link an account first). Engine Type OpenSearch The engine type of the OpenSearch. Select OpenSearch or Elasticsearch. OpenSearch Domain Name <Requires input> The domain name of the Amazon OpenSearch cluster. OpenSearch Endpoint <Requires input> The OpenSearch endpoint URL. For example, vpc-your_opensearch_domain_name-xcvgw6uu2o6zafsiefxubwuohe.us-east-1.es.amazonaws.com Index Prefix <Requires input> The common prefix of OpenSearch index for the log. The index name will be <Index Prefix>-<log-type>-<YYYY-MM-DD> . Create Sample Dashboard Yes Whether to create a sample OpenSearch dashboard. VPC ID <Requires input> Select a VPC which has access to the OpenSearch domain. The log processing Lambda will reside in the selected VPC. Subnet IDs <Requires input> Select at least two subnets which have access to the OpenSearch domain. The log processing Lambda will reside in the subnets. Make sure the subnets have access to the Amazon S3 service. Security Group ID <Requires input> Select a Security Group which will be associated with the log processing Lambda. Make sure the Security Group has access to the OpenSearch domain. S3 Backup Bucket <Requires input> The S3 backup bucket name to store the failed ingestion logs. Number Of Shards 5 Number of shards to distribute the index evenly across all data nodes. Keep the size of each shard between 10-50 GiB. Number of Replicas 1 Number of replicas for OpenSearch Index. Each replica is a full copy of an index. Days to Warm Storage 0 The number of days required to move the index into warm storage. This takes effect only when the value is larger than 0 and warm storage is enabled in OpenSearch. Days to Cold Storage 0 The number of days required to move the index into cold storage. This takes effect only when the value is larger than 0 and cold storage is enabled in OpenSearch. Days to Retain 0 The total number of days to retain the index. If value is 0, the index will not be deleted. Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template creates AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a CREATE_COMPLETE status in approximately 10 minutes.","title":"Include cfn common"},{"location":"implementation-guide/aws-services/include-cw-cfn-common/","text":"Log in to the AWS Management Console and select the button to launch the AWS CloudFormation template. You can also download the template as a starting point for your own implementation. To launch the Log Hub in a different AWS Region, use the Region selector in the console navigation bar. On the Create stack page, verify that the correct template URL shows in the Amazon S3 URL text box and choose Next . On the Specify stack details page, assign a name to your solution stack. Under Parameters , review the parameters for the template and modify them as necessary. This solution uses the following parameters. Parameter Default Description LogGroupNames <Requires input> The names of the CloudWatch log group for the logs. Log Bucket Name <Requires input> A S3 bucket name to export the the logs. Log Bucket Prefix <Requires input> The S3 bucket path prefix which stores the the logs. Log Source Account ID <Optional input> The AWS Account ID of the CloudWatch log group. Required for cross-account log ingestion (Please link an account first). By default, the Account ID you logged in at Step 1 will be used. Log Source Region <Optional input> The AWS Region of the CloudWatch log group. By default, the Region you selected at Step 2 will be used. Log Source Account Assume Role <Optional input> The IAM Role ARN used for cross-account log ingestion. Required for cross-account log ingestion (Please link an account first). KDSShardNumber 1 The shard number of Kinesis Data Streams which will subscribe to the CloudWatch log groups. KDSRetentionHours 48 The retention hours of Kinesis Data Streams. Engine Type OpenSearch The engine type of the OpenSearch. Select OpenSearch or Elasticsearch. OpenSearch Domain Name <Requires input> The domain name of the Amazon OpenSearch cluster. OpenSearch Endpoint <Requires input> The OpenSearch endpoint URL. For example, vpc-your_opensearch_domain_name-xcvgw6uu2o6zafsiefxubwuohe.us-east-1.es.amazonaws.com Index Prefix <requires input> The common prefix of OpenSearch index for the log. The index name will be <Index Prefix>-<log-type>-<YYYY-MM-DD> . Create Sample Dashboard Yes Whether to create a sample OpenSearch dashboard. VPC ID <requires input> Select a VPC which has access to the OpenSearch domain. The log processing Lambda will be resides in the selected VPC. Subnet IDs <requires input> Select at least two subnets which has access to the OpenSearch domain. The log processing Lambda will resides in the subnets. Please make sure the subnets has access to the Amazon S3 service. Security Group ID <requires input> Select a Security Group which will be associated to the log processing Lambda. Please make sure the Security Group has access to the OpenSearch domain. S3 Backup Bucket <Requires input> The S3 backup bucket name to store the failed ingestion logs. Number Of Shards 5 Number of shards to distribute the index evenly across all data nodes. Keep the size of each shard between 10-50 GiB. Number of Replicas 1 Number of replicas for OpenSearch Index. Each replica is a full copy of an index. Days to Warm Storage 0 The number of days required to move the index into warm storage. This takes effect only when the value is larger than 0 and warm storage is enabled in OpenSearch. Days to Cold Storage 0 The number of days required to move the index into cold storage. This takes effect only when the value is larger than 0 and cold storage is enabled in OpenSearch. Days to Retain 0 The total number of days to retain the index. If value is 0, the index will not be deleted. Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template creates AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a CREATE_COMPLETE status in approximately 15 minutes.","title":"Include cw cfn common"},{"location":"implementation-guide/aws-services/include-dashboard/","text":"You can access the built-in dashboard in Amazon OpenSearch to view log data. For more information, see View Dashboard . You can click the below image to view the high-resolution sample dashboard.","title":"Include dashboard"},{"location":"implementation-guide/aws-services/include-index-pattern/","text":"Click the Stack Management in the left sidebar, and select Index Patterns . Choose Create index pattern , and type in the index pattern name. Click Next step . Specify time field, and click Create index pattern .","title":"Include index pattern"},{"location":"implementation-guide/aws-services/include-supported-service-logs/","text":"The following table lists the supported AWS services and the corresponding features. AWS Service Log Type Log Location Automatic Ingestion Built-in Dashboard Amazon CloudTrail N/A S3 Yes Yes Amazon S3 Access logs S3 Yes Yes Amazon RDS/Aurora MySQL Logs CloudWatch Logs Yes Yes Amazon CloudFront Standard access logs S3 Yes Yes Application Load Balancer Access logs S3 Yes Yes AWS WAF Web ACL logs S3 Yes Yes AWS Lambda N/A CloudWatch Logs Yes Yes Amazon VPC Flow logs S3 Yes Yes AWS Config N/A S3 Yes Yes Automatic Ingestion : The solution detects the log location of the resource automatically and then reads the logs. Built-in Dashboard : An out-of-box dashboard for the specified AWS service. The solution will automatically ingest a dashboard into the AOS.","title":"Include supported service logs"},{"location":"implementation-guide/aws-services/lambda/","text":"Macro Syntax Error Line 35 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-cw-cfn-common.md\"","title":"AWS Lambda"},{"location":"implementation-guide/aws-services/lambda/#macro-syntax-error","text":"Line 35 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-cw-cfn-common.md\"","title":"Macro Syntax Error"},{"location":"implementation-guide/aws-services/rds/","text":"Macro Syntax Error Line 55 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-cw-cfn-common.md\"","title":"Amazon RDS/Aurora"},{"location":"implementation-guide/aws-services/rds/#macro-syntax-error","text":"Line 55 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-cw-cfn-common.md\"","title":"Macro Syntax Error"},{"location":"implementation-guide/aws-services/s3/","text":"Macro Syntax Error Line 37 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-cfn-common.md\"","title":"Amazon S3"},{"location":"implementation-guide/aws-services/s3/#macro-syntax-error","text":"Line 37 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-cfn-common.md\"","title":"Macro Syntax Error"},{"location":"implementation-guide/aws-services/vpc/","text":"Macro Syntax Error Line 39 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-cfn-common.md\"","title":"VPC Flow Log"},{"location":"implementation-guide/aws-services/vpc/#macro-syntax-error","text":"Line 39 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-cfn-common.md\"","title":"Macro Syntax Error"},{"location":"implementation-guide/aws-services/waf/","text":"Macro Syntax Error Line 86 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-dashboard.md\"","title":"AWS WAF"},{"location":"implementation-guide/aws-services/waf/#macro-syntax-error","text":"Line 86 in Markdown file: expected token 'end of statement block', got 'string' include - markdown \"include-dashboard.md\"","title":"Macro Syntax Error"},{"location":"implementation-guide/deployment/","text":"Overview Before you launch the solution, review the architecture, supported regions, and other considerations discussed in this guide. Follow the step-by-step instructions in this section to configure and deploy the solution into your account. Prerequisites Review all the considerations and make sure you have the following in the target region you want to deploy the solution: At least one vacancy to create new VPCs, if you choose to launch with new VPC. At least two Elastic IP (EIP) addresses, if you choose to launch with new VPC. At least eight S3 buckets. Deployment in AWS Standard Regions Log Hub provides two ways to authenticate and log into the Log Hub console. For some AWS regions where Cognito User Pool is not available (for example, Hong Kong), you need to launch the solution with OpenID Connect provider. Launch with Cognito User Pool Launch with OpenID Connect For more information about supported regions, see Regional deployments . Deployment in AWS China Regions AWS China Regions do not have Cognito User Pool. You need to launch the solution with OpenID Connect. Launch with OpenID Connect","title":"Overview"},{"location":"implementation-guide/deployment/#overview","text":"Before you launch the solution, review the architecture, supported regions, and other considerations discussed in this guide. Follow the step-by-step instructions in this section to configure and deploy the solution into your account.","title":"Overview"},{"location":"implementation-guide/deployment/#prerequisites","text":"Review all the considerations and make sure you have the following in the target region you want to deploy the solution: At least one vacancy to create new VPCs, if you choose to launch with new VPC. At least two Elastic IP (EIP) addresses, if you choose to launch with new VPC. At least eight S3 buckets.","title":"Prerequisites"},{"location":"implementation-guide/deployment/#deployment-in-aws-standard-regions","text":"Log Hub provides two ways to authenticate and log into the Log Hub console. For some AWS regions where Cognito User Pool is not available (for example, Hong Kong), you need to launch the solution with OpenID Connect provider. Launch with Cognito User Pool Launch with OpenID Connect For more information about supported regions, see Regional deployments .","title":"Deployment in AWS Standard Regions"},{"location":"implementation-guide/deployment/#deployment-in-aws-china-regions","text":"AWS China Regions do not have Cognito User Pool. You need to launch the solution with OpenID Connect. Launch with OpenID Connect","title":"Deployment in AWS China Regions"},{"location":"implementation-guide/deployment/with-cognito/","text":"Launch with Cognito User Pool Time to deploy : Approximately 15 minutes Deployment Overview Use the following steps to deploy this solution on AWS. Step 1. Launch the stack Step 2. Launch the web console Step 1. Launch the stack This AWS CloudFormation template automatically deploys the Log Hub solution on AWS. Sign in to the AWS Management Console and select the button to launch the log-hub AWS CloudFormation template. Launch in AWS Console Launch with a new VPC Launch with an existing VPC The template is launched in the default region after you log in to the console. To launch the Log Hub solution in a different AWS Region, use the Region selector in the console navigation bar. On the Create stack page, verify that the correct template URL is shown in the Amazon S3 URL text box and choose Next . On the Specify stack details page, assign a name to your solution stack. For information about naming character limitations, refer to IAM and STS Limits in the AWS Identity and Access Management User Guide . Under Parameters , review the parameters for the template and modify them as necessary. If you are launching the solution in a new VPC, this solution uses the following parameters: Parameter Default Description Admin User Email <Requires input> Specify the email of the Administrator. This email address will receive a temporary password to access the Log Hub web console. You can create more users directly in the provisioned Cognito User Pool after launching the solution. If you are launching the solution in an existing VPC, this solution uses the following parameters: Parameter Default Description Admin User Email <Requires input> Specify the email of the Administrator. This email address will receive a temporary password to access the Log Hub web console. You can create more users directly in the provisioned Cognito User Pool after launching the solution. VPC ID <Requires input> Specify the existing VPC ID in which you are launching the Log Hub solution. Public Subnet IDs <Requires input> Specify the two public subnets in the selected VPC. Private Subnet IDs <Requires input> Specify the two private subnets in the selected VPC. Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template creates AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a CREATE_COMPLETE status in approximately 15 minutes. Step 2. Launch the web Console After the stack is successfully created, this solution generates a CloudFront domain name that gives you access to the Log Hub web console. Meanwhile, an auto-generated temporary password (excluding the last digit . ) will be sent to your email address. Sign in to the AWS CloudFormation console . On the Stacks page, select the solution\u2019s stack. Choose the Outputs tab and record the domain name. Open the WebConsoleUrl using a web browser, and navigate to a sign-in page. Enter the Email and the temporary password. a. Set a new account password. b. (Optional) Verify your email address for account recovery. After the verification is complete, the system opens the Log Hub web console. Once you have logged into the Log Hub console, you can import an AOS domain and build log analytics pipelines.","title":"Launch with Cognito User Pool"},{"location":"implementation-guide/deployment/with-cognito/#launch-with-cognito-user-pool","text":"Time to deploy : Approximately 15 minutes","title":"Launch with Cognito User Pool"},{"location":"implementation-guide/deployment/with-cognito/#deployment-overview","text":"Use the following steps to deploy this solution on AWS. Step 1. Launch the stack Step 2. Launch the web console","title":"Deployment Overview"},{"location":"implementation-guide/deployment/with-cognito/#step-1-launch-the-stack","text":"This AWS CloudFormation template automatically deploys the Log Hub solution on AWS. Sign in to the AWS Management Console and select the button to launch the log-hub AWS CloudFormation template. Launch in AWS Console Launch with a new VPC Launch with an existing VPC The template is launched in the default region after you log in to the console. To launch the Log Hub solution in a different AWS Region, use the Region selector in the console navigation bar. On the Create stack page, verify that the correct template URL is shown in the Amazon S3 URL text box and choose Next . On the Specify stack details page, assign a name to your solution stack. For information about naming character limitations, refer to IAM and STS Limits in the AWS Identity and Access Management User Guide . Under Parameters , review the parameters for the template and modify them as necessary. If you are launching the solution in a new VPC, this solution uses the following parameters: Parameter Default Description Admin User Email <Requires input> Specify the email of the Administrator. This email address will receive a temporary password to access the Log Hub web console. You can create more users directly in the provisioned Cognito User Pool after launching the solution. If you are launching the solution in an existing VPC, this solution uses the following parameters: Parameter Default Description Admin User Email <Requires input> Specify the email of the Administrator. This email address will receive a temporary password to access the Log Hub web console. You can create more users directly in the provisioned Cognito User Pool after launching the solution. VPC ID <Requires input> Specify the existing VPC ID in which you are launching the Log Hub solution. Public Subnet IDs <Requires input> Specify the two public subnets in the selected VPC. Private Subnet IDs <Requires input> Specify the two private subnets in the selected VPC. Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template creates AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a CREATE_COMPLETE status in approximately 15 minutes.","title":"Step 1. Launch the stack"},{"location":"implementation-guide/deployment/with-cognito/#step-2-launch-the-web-console","text":"After the stack is successfully created, this solution generates a CloudFront domain name that gives you access to the Log Hub web console. Meanwhile, an auto-generated temporary password (excluding the last digit . ) will be sent to your email address. Sign in to the AWS CloudFormation console . On the Stacks page, select the solution\u2019s stack. Choose the Outputs tab and record the domain name. Open the WebConsoleUrl using a web browser, and navigate to a sign-in page. Enter the Email and the temporary password. a. Set a new account password. b. (Optional) Verify your email address for account recovery. After the verification is complete, the system opens the Log Hub web console. Once you have logged into the Log Hub console, you can import an AOS domain and build log analytics pipelines.","title":"Step 2. Launch the web Console"},{"location":"implementation-guide/deployment/with-oidc/","text":"Launch with OpenID Connect (OIDC) Time to deploy : Approximately 30 minutes Prerequisites Important The Log Hub console is served via CloudFront distribution which is considered as an Internet information service. If you are deploying the solution in AWS China Regions , the domain must have a valid ICP Recordal . A domain. You will use this domain to access the Log Hub console. An SSL certificate in AWS IAM. The SSL must be associated with the given domain. Follow this guide to upload SSL certificate to IAM. Deployment Overview Use the following steps to deploy this solution on AWS. Step 1. Create OIDC client Step 2. Launch the stack Step 3. Setup DNS Resolver Step 4. Launch the web console Step 1. Create OIDC client You can use different kinds of OpenID Connector (OIDC) providers. This section introduces Option 1 to Option 4. (Option 1) Using Amazon Cognito from another region as OIDC provider. (Option 2) Authing , which is an example of a third-party authentication provider. (Option 3) Keycloak , which is a solution maintained by AWS and can serve as an authentication identity provider. (Option 4) ADFS , which is a service offered by Microsoft. (Option 5) Other third-party authentication platforms such as Auth0 . Follow the steps below to create an OIDC client, and obtain the client_id and issuer . (Option 1) Using Cognito User Pool from another region You can leverage the Cognito User Pool in a supported AWS Standard Region as the OIDC provider. Go to the Amazon Cognito console in an AWS Standard Region. Set up the hosted UI with the Amazon Cognito console based on this guide . Note that there is a new UX design for the Amazon Cognito console. If you are using the new UX of Amazon Cognito console, make sure you are following the instruction of New console . Moreover, For New Amazon Cognito Console : make sure that Public client is chosen when selecting the App type . For Original Amazon Cognito Console : make sure that the option Generate client secret is unchecked when adding an app client. It is checked by default. Enter the Callback URL and Sign out URL using your domain name for Log Hub console. If your hosted UI is set up, you should be able to see something like below: For New Amazon Cognito Console , the hosted UI is Available : For Original Amazon Cognito Console , the Launch Hosted UI link is available: Save the App client ID, User pool ID and the AWS Region to a file, which will be used later. For New Amazon Cognito Console : For Original Amazon Cognito Console : In Step 2. Launch the stack , the OidcClientID is the App client ID , and OidcProvider is https://cognito-idp.${REGION}.amazonaws.com/${USER_POOL_ID} . (Option 2) Authing.cn OIDC client Go to the Authing console . Create a user pool if you don't have one. Select the user pool. On the left navigation bar, select Self-built App under Applications . Click the Create button. Enter the Application Name , and Subdomain . Save the App ID (that is, client_id ) and Issuer to a text file from Endpoint Information, which will be used later. Update the Login Callback URL and Logout Callback URL to your IPC recorded domain name. Set the Authorization Configuration. You have successfully created an authing self-built application. (Option 3) Keycloak OIDC client Deploy the Keycloak solution in AWS China Regions following this guide . Make sure you can log in to the Keycloak console. On the left navigation bar, select Add realm . Skip this step if you already have a realm. Go to the realm setting page. Choose Endpoints , and then OpenID Endpoint Configuration from the list. In the JSON file that opens up in your browser, record the issuer value which will be used later. Go back to Keycloak console and select Clients on the left navigation bar, and choose Create . Enter a Client ID, which must contain 24 letters (case-insensitive) or numbers. Record the Client ID which will be used later. Change client settings. Enter https://<Log Hub Console domain> in Valid Redirect URIs \uff0cand enter * and + in Web Origins , as shown below. In the Advanced Settings, set the Access Token Lifespan to at least 5 minutes. Select Users on the left navigation bar. Click Add user and enter Username . After the user is created, select Credentials , and enter Password . The issuer value is https://<KEYCLOAK_DOMAIN_NAME>/auth/realms/<REALM_NAME> . (Option 4) ADFS OpenID Connect Client Make sure your ADFS is installed. For information about how to install ADFS, refer to this guide . Make sure you can log in to the ADFS Sign On page. The URL should be https://adfs.domain.com/adfs/ls/idpinitiatedSignOn.aspx , and you need to replace adfs.domain.com with your real ADFS domain. Log on your Domain Controller , and open Active Directory Users and Computers . Create a Security Group for Log Hub Users, and add your planned Log Hub users to this Security Group. Log on to ADFS server, and open ADFS Management . Right click Application Groups , click Application Group , and enter the name for the Application Group, such as LogHub. Select Web browser accessing a web application option under Client-Server Applications , and click Next . Record the Client Identifier ( client_id ) under Redirect URI , enter your Log Hub domain (for example, loghub.domain.com ), and click Add , and then click Next . In the Choose Access Control Policy window, select Permit specific group , click parameters under Policy part, add the created Security Group in Step 4, then click Next . You can configure other access control policy based on your requirements. Under Summary window, click Next , and click Close . Open the Windows PowerShell on ADFS Server, and run the following commands to configure ADFS to allow CORS for your planned LogHub URL. Set-AdfsResponseHeaders -EnableCORS $true Set-AdfsResponseHeaders -CORSTrustedOrigins https://<your-loghub-domain> Under Windows PowerShell on ADFS server, run the following command to get the Issuer ( issuer ) of ADFS, which is similar to https://adfs.domain.com/adfs . Get-ADFSProperties | Select IdTokenIssuer Step 2. Launch the stack Important You can only have one active Log Hub solution stack in one region of an AWS account. If your deployment failed (for example, not meeting the requirements in prerequisites ), make sure you have deleted the failed stack before retrying the deployment. Sign in to the AWS Management Console and use the button below to launch the log-hub AWS CloudFormation template. Launch in AWS Console Launch with a new VPC in standard regions Launch with an existing VPC in standard regions Launch with a new VPC in China Regions Launch with an existing VPC in China Regions The template is launched in the default region after you log in to the console. To launch the Log Hub solution in a different AWS Region, use the Region selector in the console navigation bar. On the Create stack page, verify that the correct template URL shows in the Amazon S3 URL text box and choose Next . On the Specify stack details page, assign a name to your solution stack. For information about naming character limitations, refer to IAM and STS Limits in the AWS Identity and Access Management User Guide . Under Parameters , review the parameters for the template and modify them as necessary. If you are launching the solution in a new VPC, this solution uses the following parameters: Parameter Default Description OidcClientId <Requires input> OpenID Connector client Id. OidcProvider <Requires input> OpenID Connector provider issuer. The issuer must begin with https:// Domain <Requires input> Custom domain for Log Hub console. Do NOT add http(s) prefix. IamCertificateID <Requires input> The ID of the SSL certificate in IAM. The ID is composed of 21 characters of capital letters and digits. Use the list-server-certificates command to retrieve the ID. If you are launching the solution in an existing VPC, this solution uses the following parameters: Parameter Default Description OidcClientId <Requires input> OpenID Connector client Id. OidcProvider <Requires input> OpenID Connector provider issuer. The issuer must begin with https:// Domain <Requires input> Custom domain for Log Hub console. Do NOT add http(s) prefix. IamCertificateID <Requires input> The ID of the SSL certificate in IAM. The ID is composed of 21 characters of capital letters and digits. Use the list-server-certificates command to retrieve the ID. VPC ID <Requires input> Specify the existing VPC ID which you are launching the Log Hub solution in. Public Subnet IDs <Requires input> Specify the two public subnets in the selected VPC. Private Subnet IDs <Requires input> Specify the two private subnets in the selected VPC. Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template creates AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a CREATE_COMPLETE status in approximately 15 minutes. Step 3. Setup DNS Resolver This solution provisions a CloudFront distribution that gives you access to the Log Hub console. Sign in to the AWS CloudFormation console . Select the solution's stack. Choose the Outputs tab. Obtain the WebConsoleUrl as the endpoint. Create a CNAME record in DNS resolver, which points to the endpoint address. Step 4. Launch the web console Important You login credentials (username & password) is managed by the OIDC provider. Before signing in to the Log Hub console, make sure you have created at least one user in the OIDC provider's user pool. Use the previous assigned CNAME to open the OIDC Customer Domain URL using a web browser. Choose Sign in to Log Hub , and navigate to OIDC provider. Enter username and password. You may be asked to change your default password for first-time login, which depends on your OIDC provider's policy. After the verification is complete, the system opens the Log Hub web console. Once you have logged into the Log Hub console, you can import an AOS domain and build log analytics pipelines.","title":"Launch with OpenID Connect"},{"location":"implementation-guide/deployment/with-oidc/#launch-with-openid-connect-oidc","text":"Time to deploy : Approximately 30 minutes","title":"Launch with OpenID Connect (OIDC)"},{"location":"implementation-guide/deployment/with-oidc/#prerequisites","text":"Important The Log Hub console is served via CloudFront distribution which is considered as an Internet information service. If you are deploying the solution in AWS China Regions , the domain must have a valid ICP Recordal . A domain. You will use this domain to access the Log Hub console. An SSL certificate in AWS IAM. The SSL must be associated with the given domain. Follow this guide to upload SSL certificate to IAM.","title":"Prerequisites"},{"location":"implementation-guide/deployment/with-oidc/#deployment-overview","text":"Use the following steps to deploy this solution on AWS. Step 1. Create OIDC client Step 2. Launch the stack Step 3. Setup DNS Resolver Step 4. Launch the web console","title":"Deployment Overview"},{"location":"implementation-guide/deployment/with-oidc/#step-1-create-oidc-client","text":"You can use different kinds of OpenID Connector (OIDC) providers. This section introduces Option 1 to Option 4. (Option 1) Using Amazon Cognito from another region as OIDC provider. (Option 2) Authing , which is an example of a third-party authentication provider. (Option 3) Keycloak , which is a solution maintained by AWS and can serve as an authentication identity provider. (Option 4) ADFS , which is a service offered by Microsoft. (Option 5) Other third-party authentication platforms such as Auth0 . Follow the steps below to create an OIDC client, and obtain the client_id and issuer .","title":"Step 1. Create OIDC client"},{"location":"implementation-guide/deployment/with-oidc/#option-1-using-cognito-user-pool-from-another-region","text":"You can leverage the Cognito User Pool in a supported AWS Standard Region as the OIDC provider. Go to the Amazon Cognito console in an AWS Standard Region. Set up the hosted UI with the Amazon Cognito console based on this guide . Note that there is a new UX design for the Amazon Cognito console. If you are using the new UX of Amazon Cognito console, make sure you are following the instruction of New console . Moreover, For New Amazon Cognito Console : make sure that Public client is chosen when selecting the App type . For Original Amazon Cognito Console : make sure that the option Generate client secret is unchecked when adding an app client. It is checked by default. Enter the Callback URL and Sign out URL using your domain name for Log Hub console. If your hosted UI is set up, you should be able to see something like below: For New Amazon Cognito Console , the hosted UI is Available : For Original Amazon Cognito Console , the Launch Hosted UI link is available: Save the App client ID, User pool ID and the AWS Region to a file, which will be used later. For New Amazon Cognito Console : For Original Amazon Cognito Console : In Step 2. Launch the stack , the OidcClientID is the App client ID , and OidcProvider is https://cognito-idp.${REGION}.amazonaws.com/${USER_POOL_ID} .","title":"(Option 1) Using Cognito User Pool from another region"},{"location":"implementation-guide/deployment/with-oidc/#option-2-authingcn-oidc-client","text":"Go to the Authing console . Create a user pool if you don't have one. Select the user pool. On the left navigation bar, select Self-built App under Applications . Click the Create button. Enter the Application Name , and Subdomain . Save the App ID (that is, client_id ) and Issuer to a text file from Endpoint Information, which will be used later. Update the Login Callback URL and Logout Callback URL to your IPC recorded domain name. Set the Authorization Configuration. You have successfully created an authing self-built application.","title":"(Option 2) Authing.cn OIDC client"},{"location":"implementation-guide/deployment/with-oidc/#option-3-keycloak-oidc-client","text":"Deploy the Keycloak solution in AWS China Regions following this guide . Make sure you can log in to the Keycloak console. On the left navigation bar, select Add realm . Skip this step if you already have a realm. Go to the realm setting page. Choose Endpoints , and then OpenID Endpoint Configuration from the list. In the JSON file that opens up in your browser, record the issuer value which will be used later. Go back to Keycloak console and select Clients on the left navigation bar, and choose Create . Enter a Client ID, which must contain 24 letters (case-insensitive) or numbers. Record the Client ID which will be used later. Change client settings. Enter https://<Log Hub Console domain> in Valid Redirect URIs \uff0cand enter * and + in Web Origins , as shown below. In the Advanced Settings, set the Access Token Lifespan to at least 5 minutes. Select Users on the left navigation bar. Click Add user and enter Username . After the user is created, select Credentials , and enter Password . The issuer value is https://<KEYCLOAK_DOMAIN_NAME>/auth/realms/<REALM_NAME> .","title":"(Option 3) Keycloak OIDC client"},{"location":"implementation-guide/deployment/with-oidc/#option-4-adfs-openid-connect-client","text":"Make sure your ADFS is installed. For information about how to install ADFS, refer to this guide . Make sure you can log in to the ADFS Sign On page. The URL should be https://adfs.domain.com/adfs/ls/idpinitiatedSignOn.aspx , and you need to replace adfs.domain.com with your real ADFS domain. Log on your Domain Controller , and open Active Directory Users and Computers . Create a Security Group for Log Hub Users, and add your planned Log Hub users to this Security Group. Log on to ADFS server, and open ADFS Management . Right click Application Groups , click Application Group , and enter the name for the Application Group, such as LogHub. Select Web browser accessing a web application option under Client-Server Applications , and click Next . Record the Client Identifier ( client_id ) under Redirect URI , enter your Log Hub domain (for example, loghub.domain.com ), and click Add , and then click Next . In the Choose Access Control Policy window, select Permit specific group , click parameters under Policy part, add the created Security Group in Step 4, then click Next . You can configure other access control policy based on your requirements. Under Summary window, click Next , and click Close . Open the Windows PowerShell on ADFS Server, and run the following commands to configure ADFS to allow CORS for your planned LogHub URL. Set-AdfsResponseHeaders -EnableCORS $true Set-AdfsResponseHeaders -CORSTrustedOrigins https://<your-loghub-domain> Under Windows PowerShell on ADFS server, run the following command to get the Issuer ( issuer ) of ADFS, which is similar to https://adfs.domain.com/adfs . Get-ADFSProperties | Select IdTokenIssuer","title":"(Option 4) ADFS OpenID Connect Client"},{"location":"implementation-guide/deployment/with-oidc/#step-2-launch-the-stack","text":"Important You can only have one active Log Hub solution stack in one region of an AWS account. If your deployment failed (for example, not meeting the requirements in prerequisites ), make sure you have deleted the failed stack before retrying the deployment. Sign in to the AWS Management Console and use the button below to launch the log-hub AWS CloudFormation template. Launch in AWS Console Launch with a new VPC in standard regions Launch with an existing VPC in standard regions Launch with a new VPC in China Regions Launch with an existing VPC in China Regions The template is launched in the default region after you log in to the console. To launch the Log Hub solution in a different AWS Region, use the Region selector in the console navigation bar. On the Create stack page, verify that the correct template URL shows in the Amazon S3 URL text box and choose Next . On the Specify stack details page, assign a name to your solution stack. For information about naming character limitations, refer to IAM and STS Limits in the AWS Identity and Access Management User Guide . Under Parameters , review the parameters for the template and modify them as necessary. If you are launching the solution in a new VPC, this solution uses the following parameters: Parameter Default Description OidcClientId <Requires input> OpenID Connector client Id. OidcProvider <Requires input> OpenID Connector provider issuer. The issuer must begin with https:// Domain <Requires input> Custom domain for Log Hub console. Do NOT add http(s) prefix. IamCertificateID <Requires input> The ID of the SSL certificate in IAM. The ID is composed of 21 characters of capital letters and digits. Use the list-server-certificates command to retrieve the ID. If you are launching the solution in an existing VPC, this solution uses the following parameters: Parameter Default Description OidcClientId <Requires input> OpenID Connector client Id. OidcProvider <Requires input> OpenID Connector provider issuer. The issuer must begin with https:// Domain <Requires input> Custom domain for Log Hub console. Do NOT add http(s) prefix. IamCertificateID <Requires input> The ID of the SSL certificate in IAM. The ID is composed of 21 characters of capital letters and digits. Use the list-server-certificates command to retrieve the ID. VPC ID <Requires input> Specify the existing VPC ID which you are launching the Log Hub solution in. Public Subnet IDs <Requires input> Specify the two public subnets in the selected VPC. Private Subnet IDs <Requires input> Specify the two private subnets in the selected VPC. Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template creates AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a CREATE_COMPLETE status in approximately 15 minutes.","title":"Step 2. Launch the stack"},{"location":"implementation-guide/deployment/with-oidc/#step-3-setup-dns-resolver","text":"This solution provisions a CloudFront distribution that gives you access to the Log Hub console. Sign in to the AWS CloudFormation console . Select the solution's stack. Choose the Outputs tab. Obtain the WebConsoleUrl as the endpoint. Create a CNAME record in DNS resolver, which points to the endpoint address.","title":"Step 3. Setup DNS Resolver"},{"location":"implementation-guide/deployment/with-oidc/#step-4-launch-the-web-console","text":"Important You login credentials (username & password) is managed by the OIDC provider. Before signing in to the Log Hub console, make sure you have created at least one user in the OIDC provider's user pool. Use the previous assigned CNAME to open the OIDC Customer Domain URL using a web browser. Choose Sign in to Log Hub , and navigate to OIDC provider. Enter username and password. You may be asked to change your default password for first-time login, which depends on your OIDC provider's policy. After the verification is complete, the system opens the Log Hub web console. Once you have logged into the Log Hub console, you can import an AOS domain and build log analytics pipelines.","title":"Step 4. Launch the web console"},{"location":"implementation-guide/domains/","text":"This chapter describes how to manage Amazon OpenSearch Service (AOS) domains on the Log Hub console. An AOS domain is synonymous with an AOS cluster. In this chapter, you will learn: Import & remove an AOS Domain Create an access proxy Create recommended alarms You can read the Getting Started chapter first and walk through the basic steps for using the Log Hub solution.","title":"Overview"},{"location":"implementation-guide/domains/alarms/","text":"Recommended Alarms Amazon OpenSearch provides a set of recommended CloudWatch alarms to monitor the health of AOS domains. Log Hub helps you to create the alarms automatically, and send notification to your email (or SMS) via SNS. Create alarms Using the Log Hub console Log in to the Log Hub console. In the navigation pane, under Domains , choose OpenSearch domains . Select the domain from the table. Under General configuration , choose Enable at the Alarms label. Enter the Email . Choose the alarms you want to create and adjust the settings if necessary. Choose Create . Using the CloudFormation stack This automated AWS CloudFormation template deploys the Log Hub - Alarms solution in the AWS Cloud. Log in to the AWS Management Console and select the button to launch the log-hub-alarms AWS CloudFormation template. You can also download the template as a starting point for your own implementation. To launch the stack in a different AWS Region, use the Region selector in the console navigation bar. On the Create stack page, verify that the correct template URL shows in the Amazon S3 URL text box and choose Next . On the Specify stack details page, assign a name to your stack. Under Parameters , review the parameters for the template and modify them as necessary. This solution uses the following parameters. Parameter Default Description Endpoint <Requires input> The endpoint of the OpenSearch domain, for example, vpc-your_opensearch_domain_name-xcvgw6uu2o6zafsiefxubwuohe.us-east-1.es.amazonaws.com . DomainName <Requires input> The name of the OpenSearch domain. Email <Requires input> The notification email address. Alarms will be sent to this email address via SNS. ClusterStatusRed Yes Whether to enable alarm when at least one primary shard and its replicas are not allocated to a node. ClusterStatusYellow Yes Whether to enable alarm when at least one replica shard is not allocated to a node. FreeStorageSpace 10 Whether to enable alarm when a node in your cluster is down to the free storage space you entered in GiB. We recommend setting it to 25% of the storage space for each node. 0 means the alarm is disabled. ClusterIndexWritesBlocked 1 Index writes blocked error occurs for >= x times in 5 minutes, 1 consecutive time. Input 0 to disable this alarm. UnreachableNodeNumber 3 Nodes minimum is < x for 1 day, 1 consecutive time. 0 means the alarm is disabled. AutomatedSnapshotFailure Yes Whether to enable alarm when automated snapshot failed. AutomatedSnapshotFailure maximum is >= 1 for 1 minute, 1 consecutive time. CPUUtilization Yes Whether to enable alarm when sustained high usage of CPU occurred. CPUUtilization or WarmCPUUtilization maximum is >= 80% for 15 minutes, 3 consecutive times. JVMMemoryPressure Yes Whether to enable alarm when JVM RAM usage peak occurred. JVMMemoryPressure or WarmJVMMemoryPressure maximum is >= 80% for 5 minutes, 3 consecutive times. MasterCPUUtilization Yes Whether to enable alarm when sustained high usage of CPU occurred in master nodes. MasterCPUUtilization maximum is >= 50% for 15 minutes, 3 consecutive times. MasterJVMMemoryPressure Yes Whether to enable alarm when JVM RAM usage peak occurred in master nodes. MasterJVMMemoryPressure maximum is >= 80% for 15 minutes, 1 consecutive time. KMSKeyError Yes Whether to enable alarm when KMS encryption key is disabled. KMSKeyError is >= 1 for 1 minute, 1 consecutive time. KMSKeyInaccessible Yes Whether to enable alarm when KMS encryption key has been deleted or has revoked its grants to OpenSearch Service. KMSKeyInaccessible is >= 1 for 1 minute, 1 consecutive time. Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template creates AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a CREATE_COMPLETE status in approximately 5 minutes. Once you have created the alarms, a confirmation email will be sent to your email address. You need to click the Confirm link in the email. Go to the CloudWatch Alarms page by clicking the General configuration > Alarms > CloudWatch Alarms link on the Log Hub console , link location shown as follows: Make sure that all the alarms are in OK status. Because you might have missed the notification if alarms have changed it's status before subscription. Note Note that alarm will not send SNS notification to your email address if triggered before subscription! Which means that if your newly created alarm is triggered right after it's creation, you will not be able to get notifications. We recommend you check the alarms status after enabling the OpenSearch alarms, if you see any alarm which is in In Alarm status, please fix that issue first. Delete alarms Log in to the Log Hub console. In the navigation pane, under Domains , choose OpenSearch domains . Select the domain from the table. Choose the Alarms tab. Choose the Delete . On the confirmation prompt, choose Delete .","title":"Alarms"},{"location":"implementation-guide/domains/alarms/#recommended-alarms","text":"Amazon OpenSearch provides a set of recommended CloudWatch alarms to monitor the health of AOS domains. Log Hub helps you to create the alarms automatically, and send notification to your email (or SMS) via SNS.","title":"Recommended Alarms"},{"location":"implementation-guide/domains/alarms/#create-alarms","text":"","title":"Create alarms"},{"location":"implementation-guide/domains/alarms/#using-the-log-hub-console","text":"Log in to the Log Hub console. In the navigation pane, under Domains , choose OpenSearch domains . Select the domain from the table. Under General configuration , choose Enable at the Alarms label. Enter the Email . Choose the alarms you want to create and adjust the settings if necessary. Choose Create .","title":"Using the Log Hub console"},{"location":"implementation-guide/domains/alarms/#using-the-cloudformation-stack","text":"This automated AWS CloudFormation template deploys the Log Hub - Alarms solution in the AWS Cloud. Log in to the AWS Management Console and select the button to launch the log-hub-alarms AWS CloudFormation template. You can also download the template as a starting point for your own implementation. To launch the stack in a different AWS Region, use the Region selector in the console navigation bar. On the Create stack page, verify that the correct template URL shows in the Amazon S3 URL text box and choose Next . On the Specify stack details page, assign a name to your stack. Under Parameters , review the parameters for the template and modify them as necessary. This solution uses the following parameters. Parameter Default Description Endpoint <Requires input> The endpoint of the OpenSearch domain, for example, vpc-your_opensearch_domain_name-xcvgw6uu2o6zafsiefxubwuohe.us-east-1.es.amazonaws.com . DomainName <Requires input> The name of the OpenSearch domain. Email <Requires input> The notification email address. Alarms will be sent to this email address via SNS. ClusterStatusRed Yes Whether to enable alarm when at least one primary shard and its replicas are not allocated to a node. ClusterStatusYellow Yes Whether to enable alarm when at least one replica shard is not allocated to a node. FreeStorageSpace 10 Whether to enable alarm when a node in your cluster is down to the free storage space you entered in GiB. We recommend setting it to 25% of the storage space for each node. 0 means the alarm is disabled. ClusterIndexWritesBlocked 1 Index writes blocked error occurs for >= x times in 5 minutes, 1 consecutive time. Input 0 to disable this alarm. UnreachableNodeNumber 3 Nodes minimum is < x for 1 day, 1 consecutive time. 0 means the alarm is disabled. AutomatedSnapshotFailure Yes Whether to enable alarm when automated snapshot failed. AutomatedSnapshotFailure maximum is >= 1 for 1 minute, 1 consecutive time. CPUUtilization Yes Whether to enable alarm when sustained high usage of CPU occurred. CPUUtilization or WarmCPUUtilization maximum is >= 80% for 15 minutes, 3 consecutive times. JVMMemoryPressure Yes Whether to enable alarm when JVM RAM usage peak occurred. JVMMemoryPressure or WarmJVMMemoryPressure maximum is >= 80% for 5 minutes, 3 consecutive times. MasterCPUUtilization Yes Whether to enable alarm when sustained high usage of CPU occurred in master nodes. MasterCPUUtilization maximum is >= 50% for 15 minutes, 3 consecutive times. MasterJVMMemoryPressure Yes Whether to enable alarm when JVM RAM usage peak occurred in master nodes. MasterJVMMemoryPressure maximum is >= 80% for 15 minutes, 1 consecutive time. KMSKeyError Yes Whether to enable alarm when KMS encryption key is disabled. KMSKeyError is >= 1 for 1 minute, 1 consecutive time. KMSKeyInaccessible Yes Whether to enable alarm when KMS encryption key has been deleted or has revoked its grants to OpenSearch Service. KMSKeyInaccessible is >= 1 for 1 minute, 1 consecutive time. Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template creates AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a CREATE_COMPLETE status in approximately 5 minutes. Once you have created the alarms, a confirmation email will be sent to your email address. You need to click the Confirm link in the email. Go to the CloudWatch Alarms page by clicking the General configuration > Alarms > CloudWatch Alarms link on the Log Hub console , link location shown as follows: Make sure that all the alarms are in OK status. Because you might have missed the notification if alarms have changed it's status before subscription. Note Note that alarm will not send SNS notification to your email address if triggered before subscription! Which means that if your newly created alarm is triggered right after it's creation, you will not be able to get notifications. We recommend you check the alarms status after enabling the OpenSearch alarms, if you see any alarm which is in In Alarm status, please fix that issue first.","title":"Using the CloudFormation stack"},{"location":"implementation-guide/domains/alarms/#delete-alarms","text":"Log in to the Log Hub console. In the navigation pane, under Domains , choose OpenSearch domains . Select the domain from the table. Choose the Alarms tab. Choose the Delete . On the confirmation prompt, choose Delete .","title":"Delete alarms"},{"location":"implementation-guide/domains/import/","text":"Domain Operations Once logged into the Log Hub console, you can import an AOS domain. Log Hub supports OpenSearch domain with fine-grained access control enabled within a VPC only. Prerequisite Log Hub supports Amazon OpenSearch Service, engine version Elasticsearch 7.10 and above, and engine version OpenSearch 1.0 and above. Log Hub supports OpenSearch clusters within VPC. If you don't have an AOS domain yet, you can create an AOS domain within VPC. See Launching your Amazon OpenSearch Service domains within a VPC . Log Hub supports OpenSearch clusters with fine-grained access control only. In the security configuration, the Access policy should look like the image below: Import an AOS Domain Sign in to the Log Hub console. In the left navigation panel, under Domains , choose Import OpenSearch Domain . On the Select domain page, choose a domain from the dropdown list. The dropdown list will display only domains in the same region as the solution. Choose Next . On the Configure network page, under Network creation , choose Manual and click Next ; or choose Automatic , and go to step 9. Under VPC , choose a VPC from the list. By default, the solution creates a standalone VPC, and you can choose the one named LogHubVpc/DefaultVPC . You can also choose the same VPC as your AOS domains. Under Log Processing Subnet Group , select at least 2 subnets from the dropdown list. By default, the solution creates two private subnets. You can choose subnets named LogHubVpc/DefaultVPC/privateSubnet1 and LogHubVpc/DefaultVPC/privateSubnet2 . Under Log Processing Security Group , select one from the dropdown list. By default, the solution creates one Security Group named ProcessSecurityGroup . On the Create tags page, add tags if needed. Choose Import . Set up VPC Peering By default, the solution creates a standalone VPC. You need to create VPC Peering to allow the log processing layer to have access to your AOS domains. Note Automatic mode will create VPC peering and configure route table automatically. You do not need to set up VPC peering again. Follow this section to create VPC peering, update security group and update route tables. Create VPC Peering Connection Sign in to the Log Hub console. In the left navigation panel, under Domains , select OpenSearch Domains . Find the domain you imported and select the domain name. Choose the Network tab. Copy the VPC ID in both sections OpenSearch domain network and Log processing network . You will create Peering Connection between these two VPCs. Navigate to VPC Console Peering Connections . Select the Create peering connection button. On the Create peering connection page, enter a name, for example, log-hub . For the Select a local VPC to peer with, VPC ID (Requester) , select the VPC ID of the Log processing network . For the Select another VPC to peer with, VPC ID (Accepter) , select the VPC ID of the OpenSearch domain network . Choose Create peering connection , and navigate to the peering connection detail page. Click the Actions button and choose Accept request . Update Route Tables Go to the Log Hub console. In the OpenSearch domain network section, click the subnet under AZs and Subnets to open the subnet console in a new tab. Select the subnet, and choose the Route table tab. Select the associated route table of the subnet to open the route table configuration page. Select the Routes tab, and choose Edit routes . Add a route 10.255.0.0/16 (the CIDR of Log Hub\uff0c if you created Log Hub with existing VPC, please change this value) pointing to the Peering Connection you just created. Go back to the Log Hub console. Click the VPC ID under the OpenSearch domain network section. Select the VPC ID on the VPC Console and find its IPv4 CIDR . On the Log Hub console, in the Log processing network section, click the subnets under AZs and Subnets to open the subnets in new tabs. Repeat step 3, 4, 5, 6 to add an opposite route. Namely, configure the IPv4 CIDR of the OpenSearch VPC to point to the Peering Connection. You need to repeat the steps for each subnet of Log processing network. Update Security Group of OpenSearch Domain On the Log Hub console, under the OpenSearch domain network section, select the Security Group ID in Security Groups to open the Security Group in a new tab. On the console, select Edit inbound rules . Add the rule ALLOW TCP/443 from 10.255.0.0/16 (the CIDR of Log Hub\uff0c if you created Log Hub with existing VPC, please change this value). Choose Save rules . Remove an AOS domain If needed, you can remove the AOS domains. Important Removing the domain from Log Hub will NOT delete the AOS domain in your AWS account. It will NOT impact any existing log analytics pipelines. Sign in to the Log Hub console. In the navigation pane, under Domains , choose OpenSearch Domains . Select the domain from the table. Choose Remove . In the confirmation dialog box, choose Remove .","title":"Domain Operations"},{"location":"implementation-guide/domains/import/#domain-operations","text":"Once logged into the Log Hub console, you can import an AOS domain. Log Hub supports OpenSearch domain with fine-grained access control enabled within a VPC only.","title":"Domain Operations"},{"location":"implementation-guide/domains/import/#prerequisite","text":"Log Hub supports Amazon OpenSearch Service, engine version Elasticsearch 7.10 and above, and engine version OpenSearch 1.0 and above. Log Hub supports OpenSearch clusters within VPC. If you don't have an AOS domain yet, you can create an AOS domain within VPC. See Launching your Amazon OpenSearch Service domains within a VPC . Log Hub supports OpenSearch clusters with fine-grained access control only. In the security configuration, the Access policy should look like the image below:","title":"Prerequisite"},{"location":"implementation-guide/domains/import/#import-an-aos-domain","text":"Sign in to the Log Hub console. In the left navigation panel, under Domains , choose Import OpenSearch Domain . On the Select domain page, choose a domain from the dropdown list. The dropdown list will display only domains in the same region as the solution. Choose Next . On the Configure network page, under Network creation , choose Manual and click Next ; or choose Automatic , and go to step 9. Under VPC , choose a VPC from the list. By default, the solution creates a standalone VPC, and you can choose the one named LogHubVpc/DefaultVPC . You can also choose the same VPC as your AOS domains. Under Log Processing Subnet Group , select at least 2 subnets from the dropdown list. By default, the solution creates two private subnets. You can choose subnets named LogHubVpc/DefaultVPC/privateSubnet1 and LogHubVpc/DefaultVPC/privateSubnet2 . Under Log Processing Security Group , select one from the dropdown list. By default, the solution creates one Security Group named ProcessSecurityGroup . On the Create tags page, add tags if needed. Choose Import .","title":"Import an AOS Domain"},{"location":"implementation-guide/domains/import/#set-up-vpc-peering","text":"By default, the solution creates a standalone VPC. You need to create VPC Peering to allow the log processing layer to have access to your AOS domains. Note Automatic mode will create VPC peering and configure route table automatically. You do not need to set up VPC peering again. Follow this section to create VPC peering, update security group and update route tables.","title":"Set up VPC Peering"},{"location":"implementation-guide/domains/import/#create-vpc-peering-connection","text":"Sign in to the Log Hub console. In the left navigation panel, under Domains , select OpenSearch Domains . Find the domain you imported and select the domain name. Choose the Network tab. Copy the VPC ID in both sections OpenSearch domain network and Log processing network . You will create Peering Connection between these two VPCs. Navigate to VPC Console Peering Connections . Select the Create peering connection button. On the Create peering connection page, enter a name, for example, log-hub . For the Select a local VPC to peer with, VPC ID (Requester) , select the VPC ID of the Log processing network . For the Select another VPC to peer with, VPC ID (Accepter) , select the VPC ID of the OpenSearch domain network . Choose Create peering connection , and navigate to the peering connection detail page. Click the Actions button and choose Accept request .","title":"Create VPC Peering Connection"},{"location":"implementation-guide/domains/import/#update-route-tables","text":"Go to the Log Hub console. In the OpenSearch domain network section, click the subnet under AZs and Subnets to open the subnet console in a new tab. Select the subnet, and choose the Route table tab. Select the associated route table of the subnet to open the route table configuration page. Select the Routes tab, and choose Edit routes . Add a route 10.255.0.0/16 (the CIDR of Log Hub\uff0c if you created Log Hub with existing VPC, please change this value) pointing to the Peering Connection you just created. Go back to the Log Hub console. Click the VPC ID under the OpenSearch domain network section. Select the VPC ID on the VPC Console and find its IPv4 CIDR . On the Log Hub console, in the Log processing network section, click the subnets under AZs and Subnets to open the subnets in new tabs. Repeat step 3, 4, 5, 6 to add an opposite route. Namely, configure the IPv4 CIDR of the OpenSearch VPC to point to the Peering Connection. You need to repeat the steps for each subnet of Log processing network.","title":"Update Route Tables"},{"location":"implementation-guide/domains/import/#update-security-group-of-opensearch-domain","text":"On the Log Hub console, under the OpenSearch domain network section, select the Security Group ID in Security Groups to open the Security Group in a new tab. On the console, select Edit inbound rules . Add the rule ALLOW TCP/443 from 10.255.0.0/16 (the CIDR of Log Hub\uff0c if you created Log Hub with existing VPC, please change this value). Choose Save rules .","title":"Update Security Group of OpenSearch Domain"},{"location":"implementation-guide/domains/import/#remove-an-aos-domain","text":"If needed, you can remove the AOS domains. Important Removing the domain from Log Hub will NOT delete the AOS domain in your AWS account. It will NOT impact any existing log analytics pipelines. Sign in to the Log Hub console. In the navigation pane, under Domains , choose OpenSearch Domains . Select the domain from the table. Choose Remove . In the confirmation dialog box, choose Remove .","title":"Remove an AOS domain"},{"location":"implementation-guide/domains/proxy/","text":"By default, an AOS domain within VPC cannot be accessed from the Internet. Log Hub creates a highly available Nginx cluster which allows you to access the OpenSearch Dashboards from the Internet. Alternatively, you can choose to access the AOS domains using SSH Tunnel . This section introduces the proxy stack architecture and how to complete the following: Create a proxy Create an associated DNS record Access AOS via proxy Delete a proxy Architecture Log Hub creates an Auto Scaling Group (ASG) together with an Application Load Balancer (ALB) . The workflow is as follows: Users access the custom domain for the proxy, and the domain needs to be resolved via DNS service (for example, using Route 53 on AWS). The DNS service routes the traffic to internet-facing ALB. The ALB distributes traffic to backend Nginx server running on Amazon EC2 within ASG. The Nginx server redirects the requests to OpenSearch Dashboards. (optional) VPC peering is required if the VPC for the proxy is not the same as the OpenSearch service. Create a proxy You can create the Nginx-based proxy using the Log Hub console or by deploying a standalone CloudFormation stack. Prerequisites Make sure an AOS domain within VPC is available. The domain associated SSL certificate is created or uploaded in Amazon Certificate Manager (ACM) . Make sure you have the EC2 private key (.pem) file. Using the Log Hub console Log in to the Log Hub console. In the navigation pane, under Domains , choose OpenSearch domains . Select the domain from the table. Under General configuration , choose Enable at the Access Proxy label. Note Once the access proxy is enabled, a link to the access proxy will be available. On the Create access proxy page, under Public access proxy , select at least 2 subnets for Public Subnets . You can choose 2 public subnets named LogHubVPC/DefaultVPC/publicSubnet , which are created by Log Hub by default. Choose a Security Group of the ALB in Public Security Group . You can choose a security group named ProxySecurityGroup , which is created by Log Hub default. Enter the Domain Name . Choose Load Balancer SSL Certificate associated with the domain name. Choose the Nginx Instance Key Name . Choose Create . Using the CloudFormation stack This automated AWS CloudFormation template deploys the Log Hub - Nginx access proxy solution in the AWS Cloud. Log in to the AWS Management Console and select the button to launch the nginx-for-opensearch AWS CloudFormation template. You can also download the template as a starting point for your own implementation. To launch the stack in a different AWS Region, use the Region selector in the console navigation bar. On the Create stack page, verify that the correct template URL shows in the Amazon S3 URL text box and choose Next . On the Specify stack details page, assign a name to your stack. Under Parameters , review the parameters for the template and modify them as necessary. This solution uses the following parameters. Parameter Default Description VPCId <Requires input> The VPC to deploy the Nginx proxy resources, for example, vpc-bef13dc7 . PublicSubnetIds <Requires input> The public subnets where ELB are deployed. You need to select at least two public subnets, for example, subnet-12345abc, subnet-54321cba . ELBSecurityGroupId <Requires input> The Security group being associated with the ELB, for example, sg-123456 . ELBDomain <Requires input> The custom domain name of the ELB, for example, dashboard.example.com . ELBDomainCertificateArn <Requires input> The SSL certificate ARN associated with the ELBDomain. The certificate must be created from Amazon Certificate Manager (ACM) . PrivateSubnetIds <Requires input> The private subnets where Nginx instances are deployed. You need to select at least two private subnets, for example, subnet-12345abc, subnet-54321cba . NginxSecurityGroupId <Requires input> The Security group associated with the Nginx instances. The security group must allow access from ELB security group. KeyName <Requires input> The PEM key name of the Nginx instances. EngineType OpenSearch The engine type of the OpenSearch. Select OpenSearch or Elasticsearch. Endpoint <Requires input> The OpenSearch endpoint, for example, vpc-your_opensearch_domain_name-xcvgw6uu2o6zafsiefxubwuohe.us-east-1.es.amazonaws.com . CognitoEndpoint <Optional> The Cognito User Pool endpoint URL of the OpenSearch domain, for example, mydomain.auth.us-east-1.amazoncognito.com . Leave empty if your OpenSearch domain is not authenticated through Cognito User Pool. Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template creates AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a CREATE_COMPLETE status in approximately 15 minutes. Create an associated DNS record After provisioning the proxy infrastructure, you need to create an associated DNS record in your DNS resolver. The following introduces how to find the ALB domain, and then create a CNAME record pointing to this domain. Log in to the Log Hub console. In the navigation pane, under Domains , choose OpenSearch domains . Select the domain from the table. Choose the Access Proxy tab. You can see Load Balancer Domain which is the ALB domain. Go to the DNS resolver, create a CNAME record pointing to this domain. If your domain is managed by Amazon Route 53 , refer to Creating records by using the Amazon Route 53 console . Access AOS via proxy After the DNS record takes effect, you can access the AOS built-in dashboard from anywhere via proxy. You can enter the domain of the proxy in your browser, or click the Link button under Access Proxy in the General Configuration section. Delete a Proxy Log in to the Log Hub console. In the navigation pane, under Domains , choose OpenSearch domains . Select the domain from the table. Choose the Access Proxy tab. Choose the Delete . On the confirmation prompt, choose Delete .","title":"Access Proxy"},{"location":"implementation-guide/domains/proxy/#architecture","text":"Log Hub creates an Auto Scaling Group (ASG) together with an Application Load Balancer (ALB) . The workflow is as follows: Users access the custom domain for the proxy, and the domain needs to be resolved via DNS service (for example, using Route 53 on AWS). The DNS service routes the traffic to internet-facing ALB. The ALB distributes traffic to backend Nginx server running on Amazon EC2 within ASG. The Nginx server redirects the requests to OpenSearch Dashboards. (optional) VPC peering is required if the VPC for the proxy is not the same as the OpenSearch service.","title":"Architecture"},{"location":"implementation-guide/domains/proxy/#create-a-proxy","text":"You can create the Nginx-based proxy using the Log Hub console or by deploying a standalone CloudFormation stack. Prerequisites Make sure an AOS domain within VPC is available. The domain associated SSL certificate is created or uploaded in Amazon Certificate Manager (ACM) . Make sure you have the EC2 private key (.pem) file.","title":"Create a proxy"},{"location":"implementation-guide/domains/proxy/#using-the-log-hub-console","text":"Log in to the Log Hub console. In the navigation pane, under Domains , choose OpenSearch domains . Select the domain from the table. Under General configuration , choose Enable at the Access Proxy label. Note Once the access proxy is enabled, a link to the access proxy will be available. On the Create access proxy page, under Public access proxy , select at least 2 subnets for Public Subnets . You can choose 2 public subnets named LogHubVPC/DefaultVPC/publicSubnet , which are created by Log Hub by default. Choose a Security Group of the ALB in Public Security Group . You can choose a security group named ProxySecurityGroup , which is created by Log Hub default. Enter the Domain Name . Choose Load Balancer SSL Certificate associated with the domain name. Choose the Nginx Instance Key Name . Choose Create .","title":"Using the Log Hub console"},{"location":"implementation-guide/domains/proxy/#using-the-cloudformation-stack","text":"This automated AWS CloudFormation template deploys the Log Hub - Nginx access proxy solution in the AWS Cloud. Log in to the AWS Management Console and select the button to launch the nginx-for-opensearch AWS CloudFormation template. You can also download the template as a starting point for your own implementation. To launch the stack in a different AWS Region, use the Region selector in the console navigation bar. On the Create stack page, verify that the correct template URL shows in the Amazon S3 URL text box and choose Next . On the Specify stack details page, assign a name to your stack. Under Parameters , review the parameters for the template and modify them as necessary. This solution uses the following parameters. Parameter Default Description VPCId <Requires input> The VPC to deploy the Nginx proxy resources, for example, vpc-bef13dc7 . PublicSubnetIds <Requires input> The public subnets where ELB are deployed. You need to select at least two public subnets, for example, subnet-12345abc, subnet-54321cba . ELBSecurityGroupId <Requires input> The Security group being associated with the ELB, for example, sg-123456 . ELBDomain <Requires input> The custom domain name of the ELB, for example, dashboard.example.com . ELBDomainCertificateArn <Requires input> The SSL certificate ARN associated with the ELBDomain. The certificate must be created from Amazon Certificate Manager (ACM) . PrivateSubnetIds <Requires input> The private subnets where Nginx instances are deployed. You need to select at least two private subnets, for example, subnet-12345abc, subnet-54321cba . NginxSecurityGroupId <Requires input> The Security group associated with the Nginx instances. The security group must allow access from ELB security group. KeyName <Requires input> The PEM key name of the Nginx instances. EngineType OpenSearch The engine type of the OpenSearch. Select OpenSearch or Elasticsearch. Endpoint <Requires input> The OpenSearch endpoint, for example, vpc-your_opensearch_domain_name-xcvgw6uu2o6zafsiefxubwuohe.us-east-1.es.amazonaws.com . CognitoEndpoint <Optional> The Cognito User Pool endpoint URL of the OpenSearch domain, for example, mydomain.auth.us-east-1.amazoncognito.com . Leave empty if your OpenSearch domain is not authenticated through Cognito User Pool. Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template creates AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a CREATE_COMPLETE status in approximately 15 minutes.","title":"Using the CloudFormation stack"},{"location":"implementation-guide/domains/proxy/#create-an-associated-dns-record","text":"After provisioning the proxy infrastructure, you need to create an associated DNS record in your DNS resolver. The following introduces how to find the ALB domain, and then create a CNAME record pointing to this domain. Log in to the Log Hub console. In the navigation pane, under Domains , choose OpenSearch domains . Select the domain from the table. Choose the Access Proxy tab. You can see Load Balancer Domain which is the ALB domain. Go to the DNS resolver, create a CNAME record pointing to this domain. If your domain is managed by Amazon Route 53 , refer to Creating records by using the Amazon Route 53 console .","title":"Create an associated DNS record"},{"location":"implementation-guide/domains/proxy/#access-aos-via-proxy","text":"After the DNS record takes effect, you can access the AOS built-in dashboard from anywhere via proxy. You can enter the domain of the proxy in your browser, or click the Link button under Access Proxy in the General Configuration section.","title":"Access AOS via proxy"},{"location":"implementation-guide/domains/proxy/#delete-a-proxy","text":"Log in to the Log Hub console. In the navigation pane, under Domains , choose OpenSearch domains . Select the domain from the table. Choose the Access Proxy tab. Choose the Delete . On the confirmation prompt, choose Delete .","title":"Delete a Proxy"},{"location":"implementation-guide/getting-started/","text":"Getting Started After deploying the solution , you can read this chapter first to learn quickly how to leverage Log Hub for log ingestion (Amazon CloudTrail logs as an example), and log visualization. You can also choose to start with Domain management , then build AWS Service Log Analytics Pipelines and Application Log Analytics Pipelines . Steps Step 1: Import AOS domain . Import an existing AOS domain into the solution. Step 2: Create Access Proxy . Create a public access proxy which allows you to access AOS templated dashboard from anywhere. Step 3: Ingest CloudTrail Logs . Ingest CloudTrail logs into the specified AOS domain. Step 4: Access AOS built-in dashboard . View the dashboard of CloudTrail logs.","title":"Overview"},{"location":"implementation-guide/getting-started/#getting-started","text":"After deploying the solution , you can read this chapter first to learn quickly how to leverage Log Hub for log ingestion (Amazon CloudTrail logs as an example), and log visualization. You can also choose to start with Domain management , then build AWS Service Log Analytics Pipelines and Application Log Analytics Pipelines .","title":"Getting Started"},{"location":"implementation-guide/getting-started/#steps","text":"Step 1: Import AOS domain . Import an existing AOS domain into the solution. Step 2: Create Access Proxy . Create a public access proxy which allows you to access AOS templated dashboard from anywhere. Step 3: Ingest CloudTrail Logs . Ingest CloudTrail logs into the specified AOS domain. Step 4: Access AOS built-in dashboard . View the dashboard of CloudTrail logs.","title":"Steps"},{"location":"implementation-guide/getting-started/1.import-domain/","text":"Step 1: Import an Amazon OpenSearch domain To use the Log Hub solution for the first time, you must import AOS domains first. Log Hub supports Amazon OpenSearch domain with fine-grained access control enabled within a VPC only. Important Currently, Log Hub supports Amazon Elasticsearch 7.10 and later, or Amazon OpenSearch 1.0 and later. Prerequisite At least one AOS domain within VPC. If you don't have an AOS domain yet, you can create an AOS domain within VPC. See Launching your Amazon OpenSearch Service domains within a VPC . Steps Use the following procedure to import an AOS domain on the Log Hub console. Sign in to the Log Hub console. In the navigation pane, under Domains , choose Import OpenSearch Domain . On the Step 1. Select domain page, choose a domain from the dropdown list. Choose Next . On the Step 2. Configure network page, under Network creation , choose Automatic . If your Log Hub and OpenSearch domains resides in two different VPCs, the Automatic mode will create a VPC Peering Connection between them, and update route tables. See details in Set up VPC Peering . On the Step 3. Create tags page, choose Import .","title":"Step 1. Import Domain"},{"location":"implementation-guide/getting-started/1.import-domain/#step-1-import-an-amazon-opensearch-domain","text":"To use the Log Hub solution for the first time, you must import AOS domains first. Log Hub supports Amazon OpenSearch domain with fine-grained access control enabled within a VPC only. Important Currently, Log Hub supports Amazon Elasticsearch 7.10 and later, or Amazon OpenSearch 1.0 and later.","title":"Step 1: Import an Amazon OpenSearch domain"},{"location":"implementation-guide/getting-started/1.import-domain/#prerequisite","text":"At least one AOS domain within VPC. If you don't have an AOS domain yet, you can create an AOS domain within VPC. See Launching your Amazon OpenSearch Service domains within a VPC .","title":"Prerequisite"},{"location":"implementation-guide/getting-started/1.import-domain/#steps","text":"Use the following procedure to import an AOS domain on the Log Hub console. Sign in to the Log Hub console. In the navigation pane, under Domains , choose Import OpenSearch Domain . On the Step 1. Select domain page, choose a domain from the dropdown list. Choose Next . On the Step 2. Configure network page, under Network creation , choose Automatic . If your Log Hub and OpenSearch domains resides in two different VPCs, the Automatic mode will create a VPC Peering Connection between them, and update route tables. See details in Set up VPC Peering . On the Step 3. Create tags page, choose Import .","title":"Steps"},{"location":"implementation-guide/getting-started/2.create-proxy/","text":"Step 2: Create Access Proxy You can create a Nginx proxy and create an DNS record pointing to the proxy, so that you can access the AOS dashboard securely from public network. For more information, refer to Access Proxy in the Domain Management chapter. Create a Nginx proxy Sign in to the Log Hub console. In the navigation pane, under Domains , choose OpenSearch domains . Select the domain from the table. Under General configuration , choose Enable at the Access Proxy label. On the Create access proxy page, under Public access proxy , select at least 2 subnets which contain LogHubVpc/DefaultVPC/publicSubnetX for the Public Subnets . For Public Security Group , choose the Security Group which contains ProxySecurityGroup . Enter the Domain Name . Choose the associated Load Balancer SSL Certificate which applies to the domain name. Choose the Nginx Instance Key Name . Choose Create . After provisioning the proxy infrastructure, you need to create an associated DNS record in your DNS resolver. The following introduces how to find the Application Load Balancing (ALB) domain, and then create a CNAME record pointing to this domain. Create an DNS record Sign in to the Log Hub console. In the navigation pane, under Domains , choose OpenSearch domains . Select the domain from the table. Choose the Access Proxy tab. Find Load Balancer Domain , which is the ALB domain. Go to the DNS resolver, and create a CNAME record pointing to this domain. If your domain is managed by Amazon Route 53 , refer to Creating records by using the Amazon Route 53 console .","title":"Step 2. Create Proxy"},{"location":"implementation-guide/getting-started/2.create-proxy/#step-2-create-access-proxy","text":"You can create a Nginx proxy and create an DNS record pointing to the proxy, so that you can access the AOS dashboard securely from public network. For more information, refer to Access Proxy in the Domain Management chapter.","title":"Step 2: Create Access Proxy"},{"location":"implementation-guide/getting-started/2.create-proxy/#create-a-nginx-proxy","text":"Sign in to the Log Hub console. In the navigation pane, under Domains , choose OpenSearch domains . Select the domain from the table. Under General configuration , choose Enable at the Access Proxy label. On the Create access proxy page, under Public access proxy , select at least 2 subnets which contain LogHubVpc/DefaultVPC/publicSubnetX for the Public Subnets . For Public Security Group , choose the Security Group which contains ProxySecurityGroup . Enter the Domain Name . Choose the associated Load Balancer SSL Certificate which applies to the domain name. Choose the Nginx Instance Key Name . Choose Create . After provisioning the proxy infrastructure, you need to create an associated DNS record in your DNS resolver. The following introduces how to find the Application Load Balancing (ALB) domain, and then create a CNAME record pointing to this domain.","title":"Create a Nginx proxy"},{"location":"implementation-guide/getting-started/2.create-proxy/#create-an-dns-record","text":"Sign in to the Log Hub console. In the navigation pane, under Domains , choose OpenSearch domains . Select the domain from the table. Choose the Access Proxy tab. Find Load Balancer Domain , which is the ALB domain. Go to the DNS resolver, and create a CNAME record pointing to this domain. If your domain is managed by Amazon Route 53 , refer to Creating records by using the Amazon Route 53 console .","title":"Create an DNS record"},{"location":"implementation-guide/getting-started/3.build-cloudtrail-pipeline/","text":"Step 3: Ingest Amazon CloudTrail Logs You can build a log analytics pipeline to ingest Amazon CloudTrail logs. Important Make sure your CloudTrail and Log Hub are in the same AWS region. Sign in to the Log Hub Console. In the navigation pane, select AWS Service Log Analytics Pipelines . Choose Create a log ingestion . In the AWS Services section, choose Amazon CloudTrail . Choose Next . Under Specify settings , for Trail , select one from the dropdown list. Choose Next . In the Specify OpenSearch domain section, select the imported domain for Amazon OpenSearch domain . Choose Yes for Sample dashboard . Keep default values and choose Next . Choose Create .","title":"Step 3. Ingest CloudTrail Logs"},{"location":"implementation-guide/getting-started/3.build-cloudtrail-pipeline/#step-3-ingest-amazon-cloudtrail-logs","text":"You can build a log analytics pipeline to ingest Amazon CloudTrail logs. Important Make sure your CloudTrail and Log Hub are in the same AWS region. Sign in to the Log Hub Console. In the navigation pane, select AWS Service Log Analytics Pipelines . Choose Create a log ingestion . In the AWS Services section, choose Amazon CloudTrail . Choose Next . Under Specify settings , for Trail , select one from the dropdown list. Choose Next . In the Specify OpenSearch domain section, select the imported domain for Amazon OpenSearch domain . Choose Yes for Sample dashboard . Keep default values and choose Next . Choose Create .","title":"Step 3: Ingest Amazon CloudTrail Logs"},{"location":"implementation-guide/getting-started/4.view-dashboard/","text":"Step 4: Access AOS Build-in Dashboard After the DNS record takes effect, you can access the AOS built-in dashboard from anywhere via proxy. Enter the domain of the proxy in your browser. Alternatively, click the Link button under Access Proxy in the General Configuration section of the domain. Enter your credentials to log in to Amazon OpenSearch Dashboard. Click the username icon of AOS dashboard from the top right corner. Choose Switch Tenants . On the Select your tenant page, choose Global , and click Confirm . On the left navigation panel, choose Dashboards . Choose the AOS dashboard created automatically and start to explore your data.","title":"Step 4. View Dashboard"},{"location":"implementation-guide/getting-started/4.view-dashboard/#step-4-access-aos-build-in-dashboard","text":"After the DNS record takes effect, you can access the AOS built-in dashboard from anywhere via proxy. Enter the domain of the proxy in your browser. Alternatively, click the Link button under Access Proxy in the General Configuration section of the domain. Enter your credentials to log in to Amazon OpenSearch Dashboard. Click the username icon of AOS dashboard from the top right corner. Choose Switch Tenants . On the Select your tenant page, choose Global , and click Confirm . On the left navigation panel, choose Dashboards . Choose the AOS dashboard created automatically and start to explore your data.","title":"Step 4: Access AOS Build-in Dashboard"},{"location":"implementation-guide/link-account/","text":"Cross-Account Ingestion Log Hub supports ingesting AWS Service logs and Application logs in different AWS accounts within the same region. After deploying Log Hub in one account (main account), you can launch the CloudFormation stack in a different account (member account), and associate the two accounts (main account and member account) to implement cross-account ingestion. Concepts Main account : One account in which you deployed the Log Hub console. The OpenSearch cluster(s) must also be in the same account. Member account : Another account from which you want to ingest AWS Service logs or application logs. The CloudFormation stack in the member account has the least privileges. Log Hub need to provision some AWS resources in the member account to collect logs, and will assume an IAM role provisioned in the member account to list or create resources. For more information, refer to the Architecture section. Add a member account Step 1. Launch a CloudFormation stack in the member account Sign in to the Log Hub console. In the navigation pane, under Resources , choose Cross-Account Ingestion . Click the Link an Account button. It displays the steps to deploy the CloudFormation stack in the member account. Important You need to copy the template URL, which will be used later. Go to the CloudFormation console of the member account. Click the Create stack button and choose With new resources (standard) . In the Create stack page, enter the template URL you have copied in Amazon S3 URL . Follow the steps to create the CloudFormation stack and wait until the CloudFormation stack is provisioned. Go to the Outputs tab to check the parameters which will be used in Step 2 . Step 2. Link a member account Go back to the Log Hub console. (Optional) In the navigation panel, under Resources , choose Cross-Account Ingestion . In Step 2. Link an account , enter the parameters using the Outputs parameters from Step 1 . Parameter CloudFormation Outputs Description Account Name N/A Name of the member account. Account ID N/A 12-digit AWS account ID. Cross Account Role ARN CrossAccountRoleARN Log Hub will assume this role to operate resources in the member account. FluentBit Agent Installation Document AgentInstallDocument Log Hub will use this SSM Document to install Fluent Bit agent on EC2 instances in the member account. FluentBit Agent Configuration Document AgentConfigDocument Log Hub will use this SSM Document to deliver Fluent Bit configuration to EC2 instances. Cross Account S3 Bucket CrossAccountS3Bucket You can use the Log Hub console to enable some AWS Service logs and output them to Amazon S3. The logs will be stored in this account. Cross Account Stack ID CrossAccountStackId CloudFormation stack ID in the member account. Cross Account KMS Key CrossAccountKMSKeyARN Log Hub will use the Key Management Services (KMS) key to encrypt Simple Queue Service (SQS). Click the Link button.","title":"Cross-Account Ingestion"},{"location":"implementation-guide/link-account/#cross-account-ingestion","text":"Log Hub supports ingesting AWS Service logs and Application logs in different AWS accounts within the same region. After deploying Log Hub in one account (main account), you can launch the CloudFormation stack in a different account (member account), and associate the two accounts (main account and member account) to implement cross-account ingestion.","title":"Cross-Account Ingestion"},{"location":"implementation-guide/link-account/#concepts","text":"Main account : One account in which you deployed the Log Hub console. The OpenSearch cluster(s) must also be in the same account. Member account : Another account from which you want to ingest AWS Service logs or application logs. The CloudFormation stack in the member account has the least privileges. Log Hub need to provision some AWS resources in the member account to collect logs, and will assume an IAM role provisioned in the member account to list or create resources. For more information, refer to the Architecture section.","title":"Concepts"},{"location":"implementation-guide/link-account/#add-a-member-account","text":"","title":"Add a member account"},{"location":"implementation-guide/link-account/#step-1-launch-a-cloudformation-stack-in-the-member-account","text":"Sign in to the Log Hub console. In the navigation pane, under Resources , choose Cross-Account Ingestion . Click the Link an Account button. It displays the steps to deploy the CloudFormation stack in the member account. Important You need to copy the template URL, which will be used later. Go to the CloudFormation console of the member account. Click the Create stack button and choose With new resources (standard) . In the Create stack page, enter the template URL you have copied in Amazon S3 URL . Follow the steps to create the CloudFormation stack and wait until the CloudFormation stack is provisioned. Go to the Outputs tab to check the parameters which will be used in Step 2 .","title":"Step 1. Launch a CloudFormation stack in the member account"},{"location":"implementation-guide/link-account/#step-2-link-a-member-account","text":"Go back to the Log Hub console. (Optional) In the navigation panel, under Resources , choose Cross-Account Ingestion . In Step 2. Link an account , enter the parameters using the Outputs parameters from Step 1 . Parameter CloudFormation Outputs Description Account Name N/A Name of the member account. Account ID N/A 12-digit AWS account ID. Cross Account Role ARN CrossAccountRoleARN Log Hub will assume this role to operate resources in the member account. FluentBit Agent Installation Document AgentInstallDocument Log Hub will use this SSM Document to install Fluent Bit agent on EC2 instances in the member account. FluentBit Agent Configuration Document AgentConfigDocument Log Hub will use this SSM Document to deliver Fluent Bit configuration to EC2 instances. Cross Account S3 Bucket CrossAccountS3Bucket You can use the Log Hub console to enable some AWS Service logs and output them to Amazon S3. The logs will be stored in this account. Cross Account Stack ID CrossAccountStackId CloudFormation stack ID in the member account. Cross Account KMS Key CrossAccountKMSKeyARN Log Hub will use the Key Management Services (KMS) key to encrypt Simple Queue Service (SQS). Click the Link button.","title":"Step 2. Link a member account"},{"location":"implementation-guide/resources/aws-services/","text":"AWS Services AWS CloudFormation Amazon OpenSearch Service Amazon S3 AWS Lambda Amazon CloudFront AWS AppSync Amazon Cognito User Pool AWS Step Functions Amazon DynamoDB AWS Systems Manager Amazon EventBridge Amazon Kinesis Data Streams Amazon Kinesis Data Firehose","title":"AWS Services"},{"location":"implementation-guide/resources/aws-services/#aws-services","text":"AWS CloudFormation Amazon OpenSearch Service Amazon S3 AWS Lambda Amazon CloudFront AWS AppSync Amazon Cognito User Pool AWS Step Functions Amazon DynamoDB AWS Systems Manager Amazon EventBridge Amazon Kinesis Data Streams Amazon Kinesis Data Firehose","title":"AWS Services"},{"location":"implementation-guide/resources/open-ssl/","text":"OpenSSL 1.1 Installation Log Hub uses Fluent Bit as the logging agent, which requires OpenSSL 1.1 or later. You can install the dependency according to your operating system (OS). It is recommended to make your own AMI with OpenSSL 1.1 installed. Important If your OS is not listed below, it does not mean you cannot use Log Hub. You need to find a way to install OpenSSL 1.1. Amazon Linux 2 sudo yum install openssl11 Ubuntu 20.04 OpenSSL 1.1 is installed by default. 18.04 ln -s /usr/lib/x86_64-linux-gnu/libsasl2.so.2 /usr/lib/libsasl2.so.3 Debian GNU/10 ln -s /usr/lib/x86_64-linux-gnu/libsasl2.so.2 /usr/lib/libsasl2.so.3 GNU/11 ln -s /usr/lib/x86_64-linux-gnu/libsasl2.so.2 /usr/lib/libsasl2.so.3 Red Hat Enterprise Linux 8.X OpenSSL 1.1 is installed by default. 7.X sudo yum -y install wget sudo yum -y install ca-certificates echo \"ca_directory=/etc/ssl/certs\" | sudo tee -a /etc/wgetrc > /dev/null wget https://github.com/openssl/openssl/archive/OpenSSL_1_1_1-stable.zip sudo yum -y install gcc unzip perl unzip OpenSSL_1_1_1-stable.zip cd openssl-OpenSSL_1_1_1-stable ./config sudo make sudo make install echo \"/usr/local/lib64/\" | sudo tee -a /etc/ld.so.conf > /dev/null sudo ldconfig SUSE Linux Enterprise Server 15 OpenSSL 1.1 is installed by default.","title":"OpenSSL Installation"},{"location":"implementation-guide/resources/open-ssl/#openssl-11-installation","text":"Log Hub uses Fluent Bit as the logging agent, which requires OpenSSL 1.1 or later. You can install the dependency according to your operating system (OS). It is recommended to make your own AMI with OpenSSL 1.1 installed. Important If your OS is not listed below, it does not mean you cannot use Log Hub. You need to find a way to install OpenSSL 1.1.","title":"OpenSSL 1.1 Installation"},{"location":"implementation-guide/resources/open-ssl/#amazon-linux-2","text":"sudo yum install openssl11","title":"Amazon Linux 2"},{"location":"implementation-guide/resources/open-ssl/#ubuntu","text":"","title":"Ubuntu"},{"location":"implementation-guide/resources/open-ssl/#2004","text":"OpenSSL 1.1 is installed by default.","title":"20.04"},{"location":"implementation-guide/resources/open-ssl/#1804","text":"ln -s /usr/lib/x86_64-linux-gnu/libsasl2.so.2 /usr/lib/libsasl2.so.3","title":"18.04"},{"location":"implementation-guide/resources/open-ssl/#debian","text":"","title":"Debian"},{"location":"implementation-guide/resources/open-ssl/#gnu10","text":"ln -s /usr/lib/x86_64-linux-gnu/libsasl2.so.2 /usr/lib/libsasl2.so.3","title":"GNU/10"},{"location":"implementation-guide/resources/open-ssl/#gnu11","text":"ln -s /usr/lib/x86_64-linux-gnu/libsasl2.so.2 /usr/lib/libsasl2.so.3","title":"GNU/11"},{"location":"implementation-guide/resources/open-ssl/#red-hat-enterprise-linux","text":"","title":"Red Hat Enterprise Linux"},{"location":"implementation-guide/resources/open-ssl/#8x","text":"OpenSSL 1.1 is installed by default.","title":"8.X"},{"location":"implementation-guide/resources/open-ssl/#7x","text":"sudo yum -y install wget sudo yum -y install ca-certificates echo \"ca_directory=/etc/ssl/certs\" | sudo tee -a /etc/wgetrc > /dev/null wget https://github.com/openssl/openssl/archive/OpenSSL_1_1_1-stable.zip sudo yum -y install gcc unzip perl unzip OpenSSL_1_1_1-stable.zip cd openssl-OpenSSL_1_1_1-stable ./config sudo make sudo make install echo \"/usr/local/lib64/\" | sudo tee -a /etc/ld.so.conf > /dev/null sudo ldconfig","title":"7.X"},{"location":"implementation-guide/resources/open-ssl/#suse-linux-enterprise-server","text":"","title":"SUSE Linux Enterprise Server"},{"location":"implementation-guide/resources/open-ssl/#15","text":"OpenSSL 1.1 is installed by default.","title":"15"},{"location":"implementation-guide/resources/upload-ssl-certificate/","text":"Upload SSL Certificate to IAM Upload the SSL certificate by running the AWS CLI command upload-server-certificate similar to the following: aws iam upload-server-certificate --path /cloudfront/ \\ --server-certificate-name YourCertificate \\ --certificate-body file://Certificate.pem \\ --certificate-chain file://CertificateChain.pem \\ --private-key file://PrivateKey.pem Replace the file names and Your Certificate with the names for your uploaded files and certificate. You must specify the file:// prefix in the certificate-body, certificate-chain and private-key parameters in the API request. Otherwise, the request fails with a MalformedCertificate: Unknown error message. Note You must specify a path using the --path option. The path must begin with /cloudfront and must include a trailing slash (for example, /cloudfront/test/). After the certificate is uploaded, the AWS command upload-server-certificate returns metadata for the uploaded certificate, including the certificate's Amazon Resource Name (ARN), friendly name, identifier (ID), and expiration date. To view the uploaded certificate, run the AWS CLI command list-server-certificates : aws iam list-server-certificates For more information, see uploading a server certificate to IAM.","title":"Upload Certificate"},{"location":"implementation-guide/resources/upload-ssl-certificate/#upload-ssl-certificate-to-iam","text":"Upload the SSL certificate by running the AWS CLI command upload-server-certificate similar to the following: aws iam upload-server-certificate --path /cloudfront/ \\ --server-certificate-name YourCertificate \\ --certificate-body file://Certificate.pem \\ --certificate-chain file://CertificateChain.pem \\ --private-key file://PrivateKey.pem Replace the file names and Your Certificate with the names for your uploaded files and certificate. You must specify the file:// prefix in the certificate-body, certificate-chain and private-key parameters in the API request. Otherwise, the request fails with a MalformedCertificate: Unknown error message. Note You must specify a path using the --path option. The path must begin with /cloudfront and must include a trailing slash (for example, /cloudfront/test/). After the certificate is uploaded, the AWS command upload-server-certificate returns metadata for the uploaded certificate, including the certificate's Amazon Resource Name (ARN), friendly name, identifier (ID), and expiration date. To view the uploaded certificate, run the AWS CLI command list-server-certificates : aws iam list-server-certificates For more information, see uploading a server certificate to IAM.","title":"Upload SSL Certificate to IAM"},{"location":"updates/roadmap/","text":"Roadmap Note Feature request and bug report is welcome, please submit your requset via GitHub Issues . v0.1.0, 12/31/2021 Category Feature Description Domain Management Import/Remove AOS domain Import or remove an AOS domain within VPC into the Log Hub solution through the web console. Domain Management Public access proxy Automatically create an Nginx-based proxy that allows the customers to access the AOS dashboards through the Internet. Domain Management Recommended alarms Create the recommended AOS alarms and send notifications to customers through SNS. AWS Service Log CloudTrail log template (1) Support automatic CloudTrail log ingestion (2) One-click to create a dashboard for CloudTrail using templates. AWS Service Log Amazon S3 access log template (1) Support automatic S3 log ingestion from the a selected S3 location. (2) One-click to create a dashboard for S3 access log. AWS Service Log Lifecycle Management Automate log lifecycle using Index State Management (ISM) Support UltraWarm and Cold Storage. AWS Service Log Amazon RDS MySQL/Aurora Slow query log (1) Support automatic RDS/Aurora MySQL log ingestion (2) One-click to create the dashboard using template. AWS Service Log Amazon RDS MySQL/Aurora Error log (1) Support automatic RDS/Aurora MySQL log ingestion (2) One-click to create the dashboard using template. AWS Service Log Amazon CloudFront standard access log template (1) Support automatic log ingestion. (2) One-click to create the dashboard using template. Application Log Instance Group Create a group of instance to apply the same log configuration. Application Log Log Config Create a log agent configuration (e.g. log type, log file path) that applies to a certain version of log agent. Application Log Log pipeline Create a log pipeline (on top of Amazon Kinesis Data Streams) which allows the log agent to collect and send logs. Application Log JSON format log ingestion Build an end-to-end pipeline to ingest JSON format log data. Deployment Web console CDK/CloudFormation deployment Deploy the solution via AWS CDK or Amazon CloudFormation. It will provision a stack with a built-in Log Hub web console. Deployment Standalone log pipeline CDK/CloudFormation deployment Deploy a single log pipeline via AWS CDK or Amazon CloudFormation. All supported log type can be deployed as a standalone stack. Workshop Data insights workshop Demonstrate how to use Log Hub to build a centralized logging platform to explore the data insights. v0.2.0, 3/15/2022 Category Feature Description AWS Service Log ELB log template Application Load Balancer access log ingestion and visualization. AWS Service Log WAF Log template WAF ingestion and visualization. Application Log RegEx single-line text log template Support Parse and ingest logs using FluentBit Regular Expression in single-line text format . Application Log RegEx multi-line text custom log template Support Parse and ingest logs using FluentBit Regular Expression in multi-line text format. Application Log RegEx Java - Spring Boot log template Support Parse and ingest logs using FluentBit Regular Expression in Spring Boot log format. Application Log Nginx Log template Support ingest Nginx format log and create visualization dashboard. Application Log Apache HTTP Server template Support ingest Apache HTTP Server format log and create dashboard. Codeless Log Processors IP2Location Converter A plugin to convert the IP address to location information. Web Console Zh-CN Add Simplified Chinese user interface. Web Console OpenID Connect (OIDC) authentication Expand the authentication for OIDC to support China regions deployment. v1.0.0 (MVP), 5/31/2022 Category Feature Description Application Log Ingest logs from S3 bucket Allows ingest JSON/Single-line Text format logs from a S3 bucket. Codeless Log Processors User Agent to Device Info A plugin to convert User-Agent filed to device information. Application Log EKS Pod log ingestion Wizard to ingest logs from EKS clusters. v1.1.0, Q3/2022 Category Feature Description AWS Service Log AWS Config log template AWS Config log ingestion and visualization. AWS Service Log VPC Flow Logs template VPC Flows Logs log ingestion and visualization. AWS Service Log Cross-region/account region support Add support for cross-region/account service log ingestion. Application Log Cross-region/account support Add support for cross-region/account application log ingestion. Codeless Log Processors Data Prepper integration Allows customers to import existing Data Prepper domain and use the built-in processors to process logs. This depends on whether Data Prepper supports log processing. v1.2.0, Q4/2022 Category Feature Description Codeless Log Processors Log preview Allows customers to preview log on the Log Hub console. Codeless Log Processors Embedded plugin code editor Allows customers to write plugin code in Python directly in Log Hub console. Console Resource viewer Add resource list in the Log Pipeline detail.","title":"Roadmap"},{"location":"updates/roadmap/#roadmap","text":"Note Feature request and bug report is welcome, please submit your requset via GitHub Issues .","title":"Roadmap"},{"location":"updates/roadmap/#v010-12312021","text":"Category Feature Description Domain Management Import/Remove AOS domain Import or remove an AOS domain within VPC into the Log Hub solution through the web console. Domain Management Public access proxy Automatically create an Nginx-based proxy that allows the customers to access the AOS dashboards through the Internet. Domain Management Recommended alarms Create the recommended AOS alarms and send notifications to customers through SNS. AWS Service Log CloudTrail log template (1) Support automatic CloudTrail log ingestion (2) One-click to create a dashboard for CloudTrail using templates. AWS Service Log Amazon S3 access log template (1) Support automatic S3 log ingestion from the a selected S3 location. (2) One-click to create a dashboard for S3 access log. AWS Service Log Lifecycle Management Automate log lifecycle using Index State Management (ISM) Support UltraWarm and Cold Storage. AWS Service Log Amazon RDS MySQL/Aurora Slow query log (1) Support automatic RDS/Aurora MySQL log ingestion (2) One-click to create the dashboard using template. AWS Service Log Amazon RDS MySQL/Aurora Error log (1) Support automatic RDS/Aurora MySQL log ingestion (2) One-click to create the dashboard using template. AWS Service Log Amazon CloudFront standard access log template (1) Support automatic log ingestion. (2) One-click to create the dashboard using template. Application Log Instance Group Create a group of instance to apply the same log configuration. Application Log Log Config Create a log agent configuration (e.g. log type, log file path) that applies to a certain version of log agent. Application Log Log pipeline Create a log pipeline (on top of Amazon Kinesis Data Streams) which allows the log agent to collect and send logs. Application Log JSON format log ingestion Build an end-to-end pipeline to ingest JSON format log data. Deployment Web console CDK/CloudFormation deployment Deploy the solution via AWS CDK or Amazon CloudFormation. It will provision a stack with a built-in Log Hub web console. Deployment Standalone log pipeline CDK/CloudFormation deployment Deploy a single log pipeline via AWS CDK or Amazon CloudFormation. All supported log type can be deployed as a standalone stack. Workshop Data insights workshop Demonstrate how to use Log Hub to build a centralized logging platform to explore the data insights.","title":"v0.1.0, 12/31/2021"},{"location":"updates/roadmap/#v020-3152022","text":"Category Feature Description AWS Service Log ELB log template Application Load Balancer access log ingestion and visualization. AWS Service Log WAF Log template WAF ingestion and visualization. Application Log RegEx single-line text log template Support Parse and ingest logs using FluentBit Regular Expression in single-line text format . Application Log RegEx multi-line text custom log template Support Parse and ingest logs using FluentBit Regular Expression in multi-line text format. Application Log RegEx Java - Spring Boot log template Support Parse and ingest logs using FluentBit Regular Expression in Spring Boot log format. Application Log Nginx Log template Support ingest Nginx format log and create visualization dashboard. Application Log Apache HTTP Server template Support ingest Apache HTTP Server format log and create dashboard. Codeless Log Processors IP2Location Converter A plugin to convert the IP address to location information. Web Console Zh-CN Add Simplified Chinese user interface. Web Console OpenID Connect (OIDC) authentication Expand the authentication for OIDC to support China regions deployment.","title":"v0.2.0, 3/15/2022"},{"location":"updates/roadmap/#v100-mvp-5312022","text":"Category Feature Description Application Log Ingest logs from S3 bucket Allows ingest JSON/Single-line Text format logs from a S3 bucket. Codeless Log Processors User Agent to Device Info A plugin to convert User-Agent filed to device information. Application Log EKS Pod log ingestion Wizard to ingest logs from EKS clusters.","title":"v1.0.0 (MVP), 5/31/2022"},{"location":"updates/roadmap/#v110-q32022","text":"Category Feature Description AWS Service Log AWS Config log template AWS Config log ingestion and visualization. AWS Service Log VPC Flow Logs template VPC Flows Logs log ingestion and visualization. AWS Service Log Cross-region/account region support Add support for cross-region/account service log ingestion. Application Log Cross-region/account support Add support for cross-region/account application log ingestion. Codeless Log Processors Data Prepper integration Allows customers to import existing Data Prepper domain and use the built-in processors to process logs. This depends on whether Data Prepper supports log processing.","title":"v1.1.0, Q3/2022"},{"location":"updates/roadmap/#v120-q42022","text":"Category Feature Description Codeless Log Processors Log preview Allows customers to preview log on the Log Hub console. Codeless Log Processors Embedded plugin code editor Allows customers to write plugin code in Python directly in Log Hub console. Console Resource viewer Add resource list in the Log Pipeline detail.","title":"v1.2.0, Q4/2022"},{"location":"workshop/clean-up/","text":"Clean Up (Optional) Delete EKS Cluster Info You need to clean up EKS only if you have setup EKS Cluster during this workshop Undeploy the applications. Go to the Cloud9 workspace created in Pre-request kubectl delete -f fluent-bit-logging.yaml kubectl delete -f nginx.yaml Delete the EKS Cluster eksctl delete cluster --name=loghub-workshop-eks Delete the workspace Go to your Cloud9 Environment through AWS Management Console Select the environment named eksworkspace and delete Delete Stacks Please follow the steps to clean up all the stacks: Go to AWS Management Console > VPC . Delete the VPC peering. Go to AWS Management Console > EC2 . Detach created policy from Instance named LoghubWorkshop/workshopASG Go to AWS Management Console > CloudFormation . Detete all the log pipelines Delete proxy stack Delete WorkshopDemo stack Delete LogHub stack","title":"6. Clean Up"},{"location":"workshop/clean-up/#clean-up","text":"","title":"Clean Up"},{"location":"workshop/clean-up/#optional-delete-eks-cluster","text":"Info You need to clean up EKS only if you have setup EKS Cluster during this workshop Undeploy the applications. Go to the Cloud9 workspace created in Pre-request kubectl delete -f fluent-bit-logging.yaml kubectl delete -f nginx.yaml Delete the EKS Cluster eksctl delete cluster --name=loghub-workshop-eks Delete the workspace Go to your Cloud9 Environment through AWS Management Console Select the environment named eksworkspace and delete","title":"(Optional) Delete EKS Cluster"},{"location":"workshop/clean-up/#delete-stacks","text":"Please follow the steps to clean up all the stacks: Go to AWS Management Console > VPC . Delete the VPC peering. Go to AWS Management Console > EC2 . Detach created policy from Instance named LoghubWorkshop/workshopASG Go to AWS Management Console > CloudFormation . Detete all the log pipelines Delete proxy stack Delete WorkshopDemo stack Delete LogHub stack","title":"Delete Stacks"},{"location":"workshop/introduction/","text":"Introduction Pretend you are working as an operation engineer in a e-commercial company X, your manager asks you to build a centralized logging system, and at the same time, enable the Business Intelligence team to perform some basic data analyze functionalities through this system, like showing the top 10 popular products, etc. It sounds annoying, right? Because building a centralized logging system is always a time-consuming and complicated job for operation teams. Not to mention the effort to maintain high availability and low operational cost. Now, Log Hub can help! It's an AWS Solution that makes log analytics easy on AWS. This workshop will help you quickly understand and get hands on Log Hub solution. It will help you go through the whole process and take a glance at how much the dev-ops effort can be saved by using this solution. What you need to do during this workshop: Deploy the Log Hub solution and a dummy website in your AWS account (using CloudFormation) to simulate the environment of an e-commercial website. Ingest both AWS Service logs and application logs (EKS pod logs as optional) to take a peek at possible ways of utilization. Use OpenSearch Dashboards to monitor logs and extract business values from those out-of-box dashboards. For detailed architecture design of Log Hub, please refer to this diagram:","title":"1. Introduction"},{"location":"workshop/introduction/#introduction","text":"Pretend you are working as an operation engineer in a e-commercial company X, your manager asks you to build a centralized logging system, and at the same time, enable the Business Intelligence team to perform some basic data analyze functionalities through this system, like showing the top 10 popular products, etc. It sounds annoying, right? Because building a centralized logging system is always a time-consuming and complicated job for operation teams. Not to mention the effort to maintain high availability and low operational cost. Now, Log Hub can help! It's an AWS Solution that makes log analytics easy on AWS. This workshop will help you quickly understand and get hands on Log Hub solution. It will help you go through the whole process and take a glance at how much the dev-ops effort can be saved by using this solution. What you need to do during this workshop: Deploy the Log Hub solution and a dummy website in your AWS account (using CloudFormation) to simulate the environment of an e-commercial website. Ingest both AWS Service logs and application logs (EKS pod logs as optional) to take a peek at possible ways of utilization. Use OpenSearch Dashboards to monitor logs and extract business values from those out-of-box dashboards. For detailed architecture design of Log Hub, please refer to this diagram:","title":"Introduction"},{"location":"workshop/dashboard-data/generate-logs/","text":"Generate Logs Warning Before proceeding, please make sure you have finished all the previous sections! You have set up 4 types of log ingestion in a web hosting user scenarios. Now, it is time to generate some logs. Generate access logs Please tick the All Log-Hub Pipeline Setup Completed column in this Quip to let the support team know that you have finished creating all the log pipelines in the previous section. Once the support team noticed your tick, we will start to create access event from our side for you. And you will be able to see a tick on the Log Generation Started column. Now we can proceed to view dashboard section!","title":"Generate Logs"},{"location":"workshop/dashboard-data/generate-logs/#generate-logs","text":"Warning Before proceeding, please make sure you have finished all the previous sections! You have set up 4 types of log ingestion in a web hosting user scenarios. Now, it is time to generate some logs.","title":"Generate Logs"},{"location":"workshop/dashboard-data/generate-logs/#generate-access-logs","text":"Please tick the All Log-Hub Pipeline Setup Completed column in this Quip to let the support team know that you have finished creating all the log pipelines in the previous section. Once the support team noticed your tick, we will start to create access event from our side for you. And you will be able to see a tick on the Log Generation Started column. Now we can proceed to view dashboard section!","title":"Generate access logs"},{"location":"workshop/dashboard-data/view-dashboard/","text":"View dashboard We have successfully finished all the steps before viewing the dashboards. Now, let's explore the OpenSearch dashboard. Please open up the OpenSearch Dashboard we previously logged in. On the Log Hub console, select the OpenSearch Domains on the left navigation bar. Select the domain you have imported. Click the Link in General configuration > Access Proxy . Double-check your tenant by click the little circle on the right upper corner, select Switch tenants . Check if Global is selected, then click Confirm . Now you can go and play with your dashboard, go to the location shown in the graph below, you can find several dashboards have already been imported for you. Click each one of them, and you can view all the details by yourself: Let's see one example dashboard, the elb sample dashboard. Select workshop-elb-dashboard and change the time range, we can see elb logs has been streamed into OpenSearch already: There are several metrics we can see, for example: we can see detailed number of total sent bytes and received bytes. Operation engineers can extract useful information out of it and adjust their business architecture. For BI team, let's see the Top Request URLs block, we can easily find out which product was the most viewed product in their website. The above only gives you a possible way of using the sample OpenSearch Dashboard. Customers with specific demand can even customize their own dashboard to get business insights. Now, you can continue play around inside the dashboard and our workshop is reaching the end.","title":"View dashboard"},{"location":"workshop/dashboard-data/view-dashboard/#view-dashboard","text":"We have successfully finished all the steps before viewing the dashboards. Now, let's explore the OpenSearch dashboard. Please open up the OpenSearch Dashboard we previously logged in. On the Log Hub console, select the OpenSearch Domains on the left navigation bar. Select the domain you have imported. Click the Link in General configuration > Access Proxy . Double-check your tenant by click the little circle on the right upper corner, select Switch tenants . Check if Global is selected, then click Confirm . Now you can go and play with your dashboard, go to the location shown in the graph below, you can find several dashboards have already been imported for you. Click each one of them, and you can view all the details by yourself: Let's see one example dashboard, the elb sample dashboard. Select workshop-elb-dashboard and change the time range, we can see elb logs has been streamed into OpenSearch already: There are several metrics we can see, for example: we can see detailed number of total sent bytes and received bytes. Operation engineers can extract useful information out of it and adjust their business architecture. For BI team, let's see the Top Request URLs block, we can easily find out which product was the most viewed product in their website. The above only gives you a possible way of using the sample OpenSearch Dashboard. Customers with specific demand can even customize their own dashboard to get business insights. Now, you can continue play around inside the dashboard and our workshop is reaching the end.","title":"View dashboard"},{"location":"workshop/deployment/acm-certification/","text":"Import SSL certificate into ACM Estimated time: 2 minutes In this section, you will import an SSL certificate into ACM. An ACM certificate is needed to create a proxy to access the OpenSearch Dashboards. We recommended you to use your own domain and certificate. In this workshop, for your convenience, we have generated the certificate for you using Let's encrypt . Follow the instruction below to import it into ACM. Go to AWS Certificate Manager Console . Select Import on the right-upper corner. Download the cert.pem , open with text editor and copy to fill in Certificate body . Download the privkey.pem , open with text editor and copy to fill in Certificate private key . Download the chain.pem , open with text editor and copy to fill in Certificate chain . Click Next , Next and Import . If you see the certification shows Issued , it means certification successfully imported.","title":"2.3 Get ACM Certification"},{"location":"workshop/deployment/acm-certification/#import-ssl-certificate-into-acm","text":"Estimated time: 2 minutes In this section, you will import an SSL certificate into ACM. An ACM certificate is needed to create a proxy to access the OpenSearch Dashboards. We recommended you to use your own domain and certificate. In this workshop, for your convenience, we have generated the certificate for you using Let's encrypt . Follow the instruction below to import it into ACM. Go to AWS Certificate Manager Console . Select Import on the right-upper corner. Download the cert.pem , open with text editor and copy to fill in Certificate body . Download the privkey.pem , open with text editor and copy to fill in Certificate private key . Download the chain.pem , open with text editor and copy to fill in Certificate chain . Click Next , Next and Import . If you see the certification shows Issued , it means certification successfully imported.","title":"Import SSL certificate into ACM"},{"location":"workshop/deployment/create-eks/","text":"Create EKS Cluster Estimated time: 20 minutes Must Read Make sure you have one extra vacancy VPC which will be used for EKS Cluster. Make sure you have one extra EIP (Elastic IP address) vacancy for NAT used by EKS Cluster. Create a Workspace Launch Cloud9 Warning If you already have a Cloud 9 Environment. Just open the existing IDE in the Cloud9 console. Create a Cloud9 Environment through AWS Management Console Select Create environment Name it eksworkspace , click Next. Choose t3.small for instance type, take all default values and click Create environment When it comes up, close the welcome tab, and Open a new terminal tab . Your workspace should now look like this: Upgrade AWS Cli version by running the command below in the terminal curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" unzip awscliv2.zip sudo ./aws/install Grand AdministratorAccess to the workspace Click the top-right grey circle button and select Manage EC2 Instance Select the instance, then choose Security Tab . If your EC2 have an IAM Role already, Click the IAM Role and add AdministratorAccess to the permission. If your EC2 does not have an IAM Role created. Create an IAM Role and attach to it. Follow this link to create an IAM role with Administrator access Confirm that AWS service and EC2 are selected, then click Next: Permission to view permissions. Confirm that AdministratorAccess is checked, then click Next: Tags to assign tags. Take the defaults, and click Next: Review to review. Confirm that loghubworkshop-admin is filled in as Name, and click Create role. Go back to your EC2, choose Actions / Security / Modify IAM Role , and add loghubworkshop-admin Update IAM Settings for your workspace Info Cloud9 normally manages IAM credentials dynamically. This isn\u2019t currently compatible with the EKS IAM authentication, so we will disable it and rely on the IAM role instead. To ensure temporary credentials aren\u2019t already in place we will remove any existing credentials file as well as disabling AWS managed temporary credentials: aws cloud9 update-environment --environment-id $C9_PID --managed-credentials-action DISABLE rm -vf ${HOME}/.aws/credentials Configure our aws cli with us-east-1 as default aws configure set default.region us-east-1 Install Kubernetes Tools Warning In this workshop, we will use kubectl v1.22. In your workspace (Cloud9 IDE), run the command below: curl -LO https://dl.k8s.io/release/v1.22.0/bin/linux/amd64/kubectl sudo chmod 755 ./kubectl sudo mv ./kubectl /usr/local/bin Install eksctl In your workspace (Cloud9 IDE), run the command below: curl --silent --location \"https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz\" | tar xz -C /tmp sudo mv -v /tmp/eksctl /usr/local/bin Create an EKS Cluster In your workspace, create a new file eks.yaml . Copy and paste the content below in eks.yaml file created above and save: --- apiVersion : eksctl.io/v1alpha5 kind : ClusterConfig metadata : name : loghub-workshop-eks region : us-east-1 version : \"1.22\" iam : withOIDC : true managedNodeGroups : - name : workshop-nodes desiredCapacity : 1 instanceType : m6g.large privateNetworking : true securityGroups : attachIDs : [ \"{SecurityGroup_ID}\" ] ssh : enableSsm : true vpc : id : \"{VPC_ID}\" subnets : private : us-east-1a : id : \"{SUBNET_us_east_1a}\" us-east-1b : id : \"{SUBNET_us_east_1b}\" Replace the {VPC_ID} , {SUBNET_us_east_1a} , {SUBNET_us_east_1b} with the value which can be found below Go to AWS Console > VPC > Subnets Use the value of VPC and Subnet . Please be careful that the subnets are different in each availability zones. Find and replace the {SecurityGroup_ID} . Go to AWS Console > OpenSearch . Which is created during Create Demo Website Use the value of Security group . run the command to create EKS eksctl create cluster -f eks.yaml Wait till success Deploy Nginx in EKS create a new file nginx.yaml with the content below and save: --- apiVersion : v1 kind : Namespace metadata : name : nginx-ns --- apiVersion : v1 kind : ServiceAccount metadata : name : nginx-user namespace : nginx-ns --- apiVersion : apps/v1 kind : Deployment metadata : namespace : nginx-ns name : app-nginx-demo labels : app.kubernetes.io/name : app-nginx-demo version : v1 spec : replicas : 1 selector : matchLabels : app : app-nginx-demo strategy : rollingUpdate : maxSurge : 25% maxUnavailable : 25% type : RollingUpdate template : metadata : labels : app : app-nginx-demo spec : serviceAccountName : nginx-user containers : - image : nginx:1.20 imagePullPolicy : Always name : nginx ports : - containerPort : 80 protocol : TCP --- apiVersion : v1 kind : Service metadata : name : nginx-service namespace : nginx-ns spec : type : LoadBalancer selector : app : app-nginx-demo ports : - protocol : TCP port : 80 targetPort : 80 Deploy nginx kubectl apply -f nginx.yaml make sure that nginx pod is running kubectl get pods -n nginx-ns","title":"2.5 (Optional) Create EKS Cluster"},{"location":"workshop/deployment/create-eks/#create-eks-cluster","text":"Estimated time: 20 minutes","title":"Create EKS Cluster"},{"location":"workshop/deployment/create-eks/#must-read","text":"Make sure you have one extra vacancy VPC which will be used for EKS Cluster. Make sure you have one extra EIP (Elastic IP address) vacancy for NAT used by EKS Cluster.","title":"Must Read"},{"location":"workshop/deployment/create-eks/#create-a-workspace","text":"","title":"Create a Workspace"},{"location":"workshop/deployment/create-eks/#launch-cloud9","text":"Warning If you already have a Cloud 9 Environment. Just open the existing IDE in the Cloud9 console. Create a Cloud9 Environment through AWS Management Console Select Create environment Name it eksworkspace , click Next. Choose t3.small for instance type, take all default values and click Create environment When it comes up, close the welcome tab, and Open a new terminal tab . Your workspace should now look like this: Upgrade AWS Cli version by running the command below in the terminal curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" unzip awscliv2.zip sudo ./aws/install","title":"Launch Cloud9"},{"location":"workshop/deployment/create-eks/#grand-administratoraccess-to-the-workspace","text":"Click the top-right grey circle button and select Manage EC2 Instance Select the instance, then choose Security Tab . If your EC2 have an IAM Role already, Click the IAM Role and add AdministratorAccess to the permission. If your EC2 does not have an IAM Role created. Create an IAM Role and attach to it. Follow this link to create an IAM role with Administrator access Confirm that AWS service and EC2 are selected, then click Next: Permission to view permissions. Confirm that AdministratorAccess is checked, then click Next: Tags to assign tags. Take the defaults, and click Next: Review to review. Confirm that loghubworkshop-admin is filled in as Name, and click Create role. Go back to your EC2, choose Actions / Security / Modify IAM Role , and add loghubworkshop-admin","title":"Grand AdministratorAccess to the workspace"},{"location":"workshop/deployment/create-eks/#update-iam-settings-for-your-workspace","text":"Info Cloud9 normally manages IAM credentials dynamically. This isn\u2019t currently compatible with the EKS IAM authentication, so we will disable it and rely on the IAM role instead. To ensure temporary credentials aren\u2019t already in place we will remove any existing credentials file as well as disabling AWS managed temporary credentials: aws cloud9 update-environment --environment-id $C9_PID --managed-credentials-action DISABLE rm -vf ${HOME}/.aws/credentials Configure our aws cli with us-east-1 as default aws configure set default.region us-east-1","title":"Update IAM Settings for your workspace"},{"location":"workshop/deployment/create-eks/#install-kubernetes-tools","text":"Warning In this workshop, we will use kubectl v1.22. In your workspace (Cloud9 IDE), run the command below: curl -LO https://dl.k8s.io/release/v1.22.0/bin/linux/amd64/kubectl sudo chmod 755 ./kubectl sudo mv ./kubectl /usr/local/bin","title":"Install Kubernetes Tools"},{"location":"workshop/deployment/create-eks/#install-eksctl","text":"In your workspace (Cloud9 IDE), run the command below: curl --silent --location \"https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz\" | tar xz -C /tmp sudo mv -v /tmp/eksctl /usr/local/bin","title":"Install eksctl"},{"location":"workshop/deployment/create-eks/#create-an-eks-cluster","text":"In your workspace, create a new file eks.yaml . Copy and paste the content below in eks.yaml file created above and save: --- apiVersion : eksctl.io/v1alpha5 kind : ClusterConfig metadata : name : loghub-workshop-eks region : us-east-1 version : \"1.22\" iam : withOIDC : true managedNodeGroups : - name : workshop-nodes desiredCapacity : 1 instanceType : m6g.large privateNetworking : true securityGroups : attachIDs : [ \"{SecurityGroup_ID}\" ] ssh : enableSsm : true vpc : id : \"{VPC_ID}\" subnets : private : us-east-1a : id : \"{SUBNET_us_east_1a}\" us-east-1b : id : \"{SUBNET_us_east_1b}\" Replace the {VPC_ID} , {SUBNET_us_east_1a} , {SUBNET_us_east_1b} with the value which can be found below Go to AWS Console > VPC > Subnets Use the value of VPC and Subnet . Please be careful that the subnets are different in each availability zones. Find and replace the {SecurityGroup_ID} . Go to AWS Console > OpenSearch . Which is created during Create Demo Website Use the value of Security group . run the command to create EKS eksctl create cluster -f eks.yaml Wait till success","title":"Create an EKS Cluster"},{"location":"workshop/deployment/create-eks/#deploy-nginx-in-eks","text":"create a new file nginx.yaml with the content below and save: --- apiVersion : v1 kind : Namespace metadata : name : nginx-ns --- apiVersion : v1 kind : ServiceAccount metadata : name : nginx-user namespace : nginx-ns --- apiVersion : apps/v1 kind : Deployment metadata : namespace : nginx-ns name : app-nginx-demo labels : app.kubernetes.io/name : app-nginx-demo version : v1 spec : replicas : 1 selector : matchLabels : app : app-nginx-demo strategy : rollingUpdate : maxSurge : 25% maxUnavailable : 25% type : RollingUpdate template : metadata : labels : app : app-nginx-demo spec : serviceAccountName : nginx-user containers : - image : nginx:1.20 imagePullPolicy : Always name : nginx ports : - containerPort : 80 protocol : TCP --- apiVersion : v1 kind : Service metadata : name : nginx-service namespace : nginx-ns spec : type : LoadBalancer selector : app : app-nginx-demo ports : - protocol : TCP port : 80 targetPort : 80 Deploy nginx kubectl apply -f nginx.yaml make sure that nginx pod is running kubectl get pods -n nginx-ns","title":"Deploy Nginx in EKS"},{"location":"workshop/deployment/deploy-demo-web-site/","text":"Deploy E-Commerce Demo Site & OpenSearch Domain Estimated time: 20 minutes Warning Please make sure we have at least two vacancies to create new VPCs in your us-east-1 region. This workshop will automatically create two VPCs in your us-east-1 region in total, so lack of VPC limit would cause deployment failure. Launch Stack Go to the AWS Management Console and select the button below to launch the WorkshopDemo AWS CloudFormation template. We launch this template in US East (N. Virginia) Region, please check the region on the right-upper corner and make sure it's correct. On the Create stack page, verify that the correct template URL shows in the Amazon S3 URL text box and choose Next . On the Specify stack details page, keep the name unchanged. Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box I acknowledging that the template creates AWS Identity and Access Management (IAM) resources. Choose Create Stack to deploy the stack. The deployment process will take about 15 mins. This Cloudformation Stack will help you automatically deploy a complete three-tier web site architecture, which consists of ALB, EC2, S3, Cloudfront, DDB and an OpenSearch inside. The architecture diagram is shown as follows: You can now view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a CREATE_COMPLETE status in approximately 20 minutes. Verify the Demo Site & Import Sample Data You can now acess the front-end web page through the output of the CloudFormation and import some sample data. Select the CloudFormation Stack, and choose Outputs. Find the value of ALBCNAME and open the URL in browser. Click the Import Demo Data button The web should look like this: Note If it shows code 502, please wait for 3 more minutes to let EC2 fully booted. Then refresh the web site again. If it doesn\u2019t work, please reboot two EC2, which names are LoghubWorkshop/workshopASG , the demo site will be restarted automatically within 2 minutes.","title":"2.4 Deploy Demo Web Site"},{"location":"workshop/deployment/deploy-demo-web-site/#deploy-e-commerce-demo-site-opensearch-domain","text":"Estimated time: 20 minutes Warning Please make sure we have at least two vacancies to create new VPCs in your us-east-1 region. This workshop will automatically create two VPCs in your us-east-1 region in total, so lack of VPC limit would cause deployment failure.","title":"Deploy E-Commerce Demo Site &amp; OpenSearch Domain"},{"location":"workshop/deployment/deploy-demo-web-site/#launch-stack","text":"Go to the AWS Management Console and select the button below to launch the WorkshopDemo AWS CloudFormation template. We launch this template in US East (N. Virginia) Region, please check the region on the right-upper corner and make sure it's correct. On the Create stack page, verify that the correct template URL shows in the Amazon S3 URL text box and choose Next . On the Specify stack details page, keep the name unchanged. Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box I acknowledging that the template creates AWS Identity and Access Management (IAM) resources. Choose Create Stack to deploy the stack. The deployment process will take about 15 mins. This Cloudformation Stack will help you automatically deploy a complete three-tier web site architecture, which consists of ALB, EC2, S3, Cloudfront, DDB and an OpenSearch inside. The architecture diagram is shown as follows: You can now view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a CREATE_COMPLETE status in approximately 20 minutes.","title":"Launch Stack"},{"location":"workshop/deployment/deploy-demo-web-site/#verify-the-demo-site-import-sample-data","text":"You can now acess the front-end web page through the output of the CloudFormation and import some sample data. Select the CloudFormation Stack, and choose Outputs. Find the value of ALBCNAME and open the URL in browser. Click the Import Demo Data button The web should look like this: Note If it shows code 502, please wait for 3 more minutes to let EC2 fully booted. Then refresh the web site again. If it doesn\u2019t work, please reboot two EC2, which names are LoghubWorkshop/workshopASG , the demo site will be restarted automatically within 2 minutes.","title":"Verify the Demo Site &amp; Import Sample Data"},{"location":"workshop/deployment/deploy-log-hub/","text":"Deploy Log Hub Estimated time: 15 minutes Warning Before following this section, please make sure we have one more vacancy to create new VPC, and two more vacancies to create EIP in your us-east-1 region. This cloudformation deployment will automatically create one VPC in your us-east-1 region and occupy two more EIP in total, so lack of VPC and EIP would cause deployment failure. Further more, five new S3 buckets will be created in total. So please also make sure your S3 bucket limit has not been reached. Launch Stack Log in the AWS Management Console and select the button below to launch the LogHub AWS CloudFormation template. We launch this template in US East (N. Virginia) Region, please check the region on the right-upper corner and make sure it's correct. On the Create stack page, verify that the correct template URL shows in the Amazon S3 URL text box and choose Next . On the Specify stack details page, leave the stack name as LogHub . Under Parameters , enter the email, this email will be used as your username to login the dashboard. Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template creates AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a CREATE_COMPLETE status in approximately 15 minutes. The successful deployment should look like this: Access the Log Hub Web Console This solution will generate a CloudFront endpoint that gives you access to the Log Hub console. The endpoint can be found in Outputs section of the CloudFormation template as WebConsoleUrl . An auto-generated password will be sent to your email address, you will need it to log in to the console. Please remember to omit the last digit . in your email. Open the WebConsoleUrl in the browser. You will be navigated to a sign-in page. Input the email as the Username , and fill with the auto-generated password in the Password field. Choose Sign in . You will be asked to change your password for the first-time login. Follow the guide to change your password. You will be asked to confirm your email address for password recovery. Skip it this time. So far, we have successfully deployed the main stack of LogHub. Now you can see the LogHub Web Console , please do not close it, we will do further steps on it later.","title":"3. Deploy Log Hub"},{"location":"workshop/deployment/deploy-log-hub/#deploy-log-hub","text":"Estimated time: 15 minutes Warning Before following this section, please make sure we have one more vacancy to create new VPC, and two more vacancies to create EIP in your us-east-1 region. This cloudformation deployment will automatically create one VPC in your us-east-1 region and occupy two more EIP in total, so lack of VPC and EIP would cause deployment failure. Further more, five new S3 buckets will be created in total. So please also make sure your S3 bucket limit has not been reached.","title":"Deploy Log Hub"},{"location":"workshop/deployment/deploy-log-hub/#launch-stack","text":"Log in the AWS Management Console and select the button below to launch the LogHub AWS CloudFormation template. We launch this template in US East (N. Virginia) Region, please check the region on the right-upper corner and make sure it's correct. On the Create stack page, verify that the correct template URL shows in the Amazon S3 URL text box and choose Next . On the Specify stack details page, leave the stack name as LogHub . Under Parameters , enter the email, this email will be used as your username to login the dashboard. Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template creates AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a CREATE_COMPLETE status in approximately 15 minutes. The successful deployment should look like this:","title":"Launch Stack"},{"location":"workshop/deployment/deploy-log-hub/#access-the-log-hub-web-console","text":"This solution will generate a CloudFront endpoint that gives you access to the Log Hub console. The endpoint can be found in Outputs section of the CloudFormation template as WebConsoleUrl . An auto-generated password will be sent to your email address, you will need it to log in to the console. Please remember to omit the last digit . in your email. Open the WebConsoleUrl in the browser. You will be navigated to a sign-in page. Input the email as the Username , and fill with the auto-generated password in the Password field. Choose Sign in . You will be asked to change your password for the first-time login. Follow the guide to change your password. You will be asked to confirm your email address for password recovery. Skip it this time. So far, we have successfully deployed the main stack of LogHub. Now you can see the LogHub Web Console , please do not close it, we will do further steps on it later.","title":"Access the Log Hub Web Console"},{"location":"workshop/deployment/key-pair/","text":"EC2 Key Pair Estimated time: 2 minutes Note We deploy all the things in US East (N. Virginia) Region, so please make sure you are in the correct region! During the deployment of Log Hub, we need a key pair to initiate several EC2 instances to host Nginx server acting as proxy for OpenSearch Dashboards. So if you are using a new AWS account, please follow the steps below to create a new key pair: Go to AWS EC2 console > Key pairs Click Create key pair on right-upper corner of the page Type your own key-pair name and create, then automated download will initiate","title":"2.1 EC2 Key Pair"},{"location":"workshop/deployment/key-pair/#ec2-key-pair","text":"Estimated time: 2 minutes Note We deploy all the things in US East (N. Virginia) Region, so please make sure you are in the correct region! During the deployment of Log Hub, we need a key pair to initiate several EC2 instances to host Nginx server acting as proxy for OpenSearch Dashboards. So if you are using a new AWS account, please follow the steps below to create a new key pair: Go to AWS EC2 console > Key pairs Click Create key pair on right-upper corner of the page Type your own key-pair name and create, then automated download will initiate","title":"EC2 Key Pair"},{"location":"workshop/deployment/must-read/","text":"Must Read Before you proceed to the next section, please read the following basic pre-requisites. Failure of meeting these requirements will cause the failure of deployment for sure. Make sure you do not skip or ignore any one of them: We deploy all the things in N. Virginia (us-east-1) Region. The workshop is intended to be work in other regions as well. But we have not tested in other regions. Make sure you have at least TWO vacancies to create new VPCs in your us-east-1 region. This workshop will automatically create two VPCs in the us-east-1 region. Make sure you have at least THREE EIP (Elastic IP addresses) vacancies . This workshop will occupy three EIP, one for E-Commerce Demo Site and the other two for OpenSearch Dashboard Proxy. Make sure you have at least EIGHT S3 bucket vacancies. This workshop will create eight new s3 buckets in your account.","title":"2.0 Must Read"},{"location":"workshop/deployment/must-read/#must-read","text":"Before you proceed to the next section, please read the following basic pre-requisites. Failure of meeting these requirements will cause the failure of deployment for sure. Make sure you do not skip or ignore any one of them: We deploy all the things in N. Virginia (us-east-1) Region. The workshop is intended to be work in other regions as well. But we have not tested in other regions. Make sure you have at least TWO vacancies to create new VPCs in your us-east-1 region. This workshop will automatically create two VPCs in the us-east-1 region. Make sure you have at least THREE EIP (Elastic IP addresses) vacancies . This workshop will occupy three EIP, one for E-Commerce Demo Site and the other two for OpenSearch Dashboard Proxy. Make sure you have at least EIGHT S3 bucket vacancies. This workshop will create eight new s3 buckets in your account.","title":"Must Read"},{"location":"workshop/deployment/service-linked-role/","text":"Create service linked role for your AWS account Estimated time: 2 minutes Note It's OK to skip this section if your account has already deployed OpenSearch once before. Please jump to 2.3. Make sure you have already setup AWS credentials on your local machine. Open up a new terminal. Type in: aws configure Please double-check the access key, secret key and region are correct for your deployment account Type in: aws iam create-service-linked-role --aws-service-name es.amazonaws.com This command will add a OpenSearch service linked role for you. It gives permission to OpenSearch to launch in your new created VPC. If the output of that command shows a JSON format policy: { \"Role\": { \"Path\": \"/aws-service-role/es.amazonaws.com/\", \"RoleName\": \"AWSServiceRoleForAmazonElasticsearchService\", \"RoleId\": \"XXXXXXXXXXXXXXXXXX\", \"Arn\": \"arn:aws:iam::XXXXXXXXXXXXX:role/aws-service-role/es.amazonaws.com/AWSServiceRoleForAmazonElasticsearchService\", \"CreateDate\": \"2021-12-23T05:29:55+00:00\", \"AssumeRolePolicyDocument\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": [ \"sts:AssumeRole\" ], \"Effect\": \"Allow\", \"Principal\": { \"Service\": [ \"es.amazonaws.com\" ] } } ] } } } That means the role has been successfully created. You can proceed to deploy demo web site. Note It's OK if it shows: An error occurred (InvalidInput) when calling the CreateServiceLinkedRole operation: Service role name AWSServiceRoleForAmazonElasticsearchService has been taken in this account, please try a different suffix. This is means you have already created the ES service linked role before.","title":"2.2 Create service linked role"},{"location":"workshop/deployment/service-linked-role/#create-service-linked-role-for-your-aws-account","text":"Estimated time: 2 minutes Note It's OK to skip this section if your account has already deployed OpenSearch once before. Please jump to 2.3. Make sure you have already setup AWS credentials on your local machine. Open up a new terminal. Type in: aws configure Please double-check the access key, secret key and region are correct for your deployment account Type in: aws iam create-service-linked-role --aws-service-name es.amazonaws.com This command will add a OpenSearch service linked role for you. It gives permission to OpenSearch to launch in your new created VPC. If the output of that command shows a JSON format policy: { \"Role\": { \"Path\": \"/aws-service-role/es.amazonaws.com/\", \"RoleName\": \"AWSServiceRoleForAmazonElasticsearchService\", \"RoleId\": \"XXXXXXXXXXXXXXXXXX\", \"Arn\": \"arn:aws:iam::XXXXXXXXXXXXX:role/aws-service-role/es.amazonaws.com/AWSServiceRoleForAmazonElasticsearchService\", \"CreateDate\": \"2021-12-23T05:29:55+00:00\", \"AssumeRolePolicyDocument\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": [ \"sts:AssumeRole\" ], \"Effect\": \"Allow\", \"Principal\": { \"Service\": [ \"es.amazonaws.com\" ] } } ] } } } That means the role has been successfully created. You can proceed to deploy demo web site. Note It's OK if it shows: An error occurred (InvalidInput) when calling the CreateServiceLinkedRole operation: Service role name AWSServiceRoleForAmazonElasticsearchService has been taken in this account, please try a different suffix. This is means you have already created the ES service linked role before.","title":"Create service linked role for your AWS account"},{"location":"workshop/domain-management/access-proxy/","text":"Access AOS via Proxy Estimated time: 3 minutes We have deployed proxys through UI in the previous section. Now, let's try to access the OpenSearch Dashboard through ALB DNS address. Go to Log Hub Console > OpenSearch Domains > workshop-os > Access Proxy Copy the Load Balancer Domain name: LogHu-LoadB-XXXXXXXXXX Note Please do not use the Domain name to access LogHub. In this workshop it will not work because we are entering a fake one. But for real customer cases, the domain name should be a real one. Open a new tab in your browser, type in: https://<Your_Copied_Load_Balancer_Domain_Name>/_dashboards/ . The browser may warn you that the link you are going to is not secure. Please just ignore the warning and choose the Advanced button. The following graph is an example of Chrome : Click the revealed URL. The following graph is an example of FireFox : Click Accept the Risk and Continue . Note If you still can not access, please double check if you have disabled Enhanced Protection function in your browser. We have this warning issue because the url we are using is not resolved in Route53. This is a expected issue and will only occur in this workshop. For real use case, customers need to use a resolved domain name and valid certification to access the dashboard. Now we can start login the OpenSearch Dashboard! The username is admin and password is Loghub@@123 , which are both fixed, so just copy and paste. You can now access the OpenSearch portal! Select Global on the popup window: Then select Explore on my own \uff0cthen you can see a blank dashboard since we have not generated access log yet: You have completed this part and successfully access the proxy server to view the OpenSearch Dashboard! Just leave the dashboard open and we will go back later.","title":"4.3 Access Proxy"},{"location":"workshop/domain-management/access-proxy/#access-aos-via-proxy","text":"Estimated time: 3 minutes We have deployed proxys through UI in the previous section. Now, let's try to access the OpenSearch Dashboard through ALB DNS address. Go to Log Hub Console > OpenSearch Domains > workshop-os > Access Proxy Copy the Load Balancer Domain name: LogHu-LoadB-XXXXXXXXXX Note Please do not use the Domain name to access LogHub. In this workshop it will not work because we are entering a fake one. But for real customer cases, the domain name should be a real one. Open a new tab in your browser, type in: https://<Your_Copied_Load_Balancer_Domain_Name>/_dashboards/ . The browser may warn you that the link you are going to is not secure. Please just ignore the warning and choose the Advanced button. The following graph is an example of Chrome : Click the revealed URL. The following graph is an example of FireFox : Click Accept the Risk and Continue . Note If you still can not access, please double check if you have disabled Enhanced Protection function in your browser. We have this warning issue because the url we are using is not resolved in Route53. This is a expected issue and will only occur in this workshop. For real use case, customers need to use a resolved domain name and valid certification to access the dashboard. Now we can start login the OpenSearch Dashboard! The username is admin and password is Loghub@@123 , which are both fixed, so just copy and paste. You can now access the OpenSearch portal! Select Global on the popup window: Then select Explore on my own \uff0cthen you can see a blank dashboard since we have not generated access log yet: You have completed this part and successfully access the proxy server to view the OpenSearch Dashboard! Just leave the dashboard open and we will go back later.","title":"Access AOS via Proxy"},{"location":"workshop/domain-management/create-proxy/","text":"Create proxy Estimated time: 15 minutes Note Please make sure you have finished the section Deployment > Pre-requisites of this workshop guide before proceeding. By default, Amazon OpenSearch domain within VPC cannot be access from the Internet. There are a couple of ways to access the built-in dashboard of OpenSearch using VPC. In Log Hub solution, you can deploy a Nginx based proxy to allows public access to the OpenSearch domain. The following is the architecture diagram: Create a proxy In the navigation pane, under Clusters , choose OpenSearch domains . Select the domain from the table. Under General configuration , choose Enable at the Access Proxy label. On the Create access proxy page, under Public access proxy , you must select TWO subnets for Public Subnets , named LogHubVPC/DefaultVPC/publicSubnet1 and LogHubVPC/DefaultVPC/publicSubnet2 . Choose a Security Group of the ALB in Public Security Group , named LogHub-ProxySecurityGroup-xxx . Input the following Domain Name : fakename.workshop.log-hub.solutions.aws.dev Notice that: This Domain Name is a fake one and we will do nothing for it in this workshop. For real use case, customers will need to enter a real Domain name, which will be used to grant access via public. Choose the associated Load Balancer SSL Certificate which applies to the domain name. Choose the Nginx Instance Key Pair Name . And check if the page looks like this graph below: Choose Create . The above shows that proxys are creating now! It will take 10 minutes to fully deploy the proxy, so please wait until the creating status changes to a link like that: So, please do not proceed until it's done. Note Please do not click the Link . We will access the proxy through ALB directly in the next section.","title":"4.2 Create Proxy"},{"location":"workshop/domain-management/create-proxy/#create-proxy","text":"Estimated time: 15 minutes Note Please make sure you have finished the section Deployment > Pre-requisites of this workshop guide before proceeding. By default, Amazon OpenSearch domain within VPC cannot be access from the Internet. There are a couple of ways to access the built-in dashboard of OpenSearch using VPC. In Log Hub solution, you can deploy a Nginx based proxy to allows public access to the OpenSearch domain. The following is the architecture diagram:","title":"Create proxy"},{"location":"workshop/domain-management/create-proxy/#create-a-proxy","text":"In the navigation pane, under Clusters , choose OpenSearch domains . Select the domain from the table. Under General configuration , choose Enable at the Access Proxy label. On the Create access proxy page, under Public access proxy , you must select TWO subnets for Public Subnets , named LogHubVPC/DefaultVPC/publicSubnet1 and LogHubVPC/DefaultVPC/publicSubnet2 . Choose a Security Group of the ALB in Public Security Group , named LogHub-ProxySecurityGroup-xxx . Input the following Domain Name : fakename.workshop.log-hub.solutions.aws.dev Notice that: This Domain Name is a fake one and we will do nothing for it in this workshop. For real use case, customers will need to enter a real Domain name, which will be used to grant access via public. Choose the associated Load Balancer SSL Certificate which applies to the domain name. Choose the Nginx Instance Key Pair Name . And check if the page looks like this graph below: Choose Create . The above shows that proxys are creating now! It will take 10 minutes to fully deploy the proxy, so please wait until the creating status changes to a link like that: So, please do not proceed until it's done. Note Please do not click the Link . We will access the proxy through ALB directly in the next section.","title":"Create a proxy"},{"location":"workshop/domain-management/import-domain/","text":"Import AOS domain Estimated time: 2 minutes Log Hub solution is built on top of Amazon OpenSearch Service. In this section, you will import an existing OpenSearch domain. In the navigation panel, under Clusters , choose Import OpenSearch Domain . On Select domain page, choose a domain from the dropdown list. The dropdown list will only list domain in the same region as the Log Hub solution using VPC. We choose workshop-os , which is the OpenSearch we created in Deployment section using CloudFormation. Choose Next . On Configure network page, under Network creation , choose Automatic . Choose Next . We can skip the Tags now, choose Import . We have successfully imported a OpenSearch Domain: What has been automatically done for me? Firstly, a VPC peering connection is automatically established between your Workshop-Demo-VPC and your LogHub-VPC . Secondly, security groups and detailed routing mechanisms are automatically inserted into your Workshop-Demo-VPC . Info Let's take a look at the architecture for VPC peering: As we can see, we need to peer the VPC which contains the log processors (10.255.0.0/16) with the OpenSearch VPC (10.0.0.0/16), and enable processors to go through the workshop demo VPC so as to process logs for us.","title":"4.1 Import Domain"},{"location":"workshop/domain-management/import-domain/#import-aos-domain","text":"Estimated time: 2 minutes Log Hub solution is built on top of Amazon OpenSearch Service. In this section, you will import an existing OpenSearch domain. In the navigation panel, under Clusters , choose Import OpenSearch Domain . On Select domain page, choose a domain from the dropdown list. The dropdown list will only list domain in the same region as the Log Hub solution using VPC. We choose workshop-os , which is the OpenSearch we created in Deployment section using CloudFormation. Choose Next . On Configure network page, under Network creation , choose Automatic . Choose Next . We can skip the Tags now, choose Import . We have successfully imported a OpenSearch Domain:","title":"Import AOS domain"},{"location":"workshop/domain-management/import-domain/#what-has-been-automatically-done-for-me","text":"Firstly, a VPC peering connection is automatically established between your Workshop-Demo-VPC and your LogHub-VPC . Secondly, security groups and detailed routing mechanisms are automatically inserted into your Workshop-Demo-VPC . Info Let's take a look at the architecture for VPC peering: As we can see, we need to peer the VPC which contains the log processors (10.255.0.0/16) with the OpenSearch VPC (10.0.0.0/16), and enable processors to go through the workshop demo VPC so as to process logs for us.","title":"What has been automatically done for me?"},{"location":"workshop/log-analytics-pipelines/application-log/","text":"Ingest Application Logs via Log Hub Console Estimated time: 10 minutes Log Hub supports ingest AWS Service logs and application (e.g. Nginx , Apache HTTP Server ) logs. This section will guide you to ingest the access logs of a group of Spring Boot servers which you have deployed in Deploy Demo Web Site . In this section, you will learn how to install log agents on selected instances, define log format and ingest logs on a single web console. The following is the architecture diagram. Create application log pipeline Go to LogHub Web Console , choose Application Log in Log Analytics Pipelines section Click Create a pipeline and type in the following parameters: Index name: app-pipe Shard number: 2 Enable auto scaling?: No Click Next , and choose the AOS domain as workshop-os , remain other parameters and select Next , then Create Then you can see the pipeline is in Creating status. Create EC2 policy If we want to enable servers to be able to stream logs to kinesis, EC2 policies are needed! So let's do some quick steps and create a new EC2 policy for your Demo Website spring servers. Warning Please wait until the application pipeline status changes to Active ! On the Log Hub Console , select the pipeline name and view the details of that log pipeline Go to Permission tab and copy the provided JSON policy Go to AWS Console > IAM > Policies on the left column Click Create Policy , choose JSON and replace all the content inside the text block. Remember to substitute <YOUR ACCOUNT ID> with your true account id! Please refer to the graph below: Click Next , Next , then type in the name for this policy, example name: loghub-ec2-policy Choose Create policy Go to AWS Console > EC2 , choose one of the instance which name is LoghubWorkshop/workshopASG , select Security tab and click the IAM Role link Click Add permissions > Attach policies , and attach that newly created policy to this role Create Instance Group Go to LogHub Web Console , choose Instance Group on the left side of the page Click Create an instance group , now you can see two instances on the list: Note All the instances with ssm agent will come up in this list, if there are non-relevant instances, please search for Instances ID in AWS Console first. Choosing the wrong instances might cause no data in dashboard. 3. Select both of the instances and click Install log agent , the agent installation process will start. We use fluent-bit as log agent in LogHub. Please wait until the installation complete, it will show Online in Pending Status column: 4. Then we can type in the name for instance group and click Create . The instance group is successfully created. Create Spring log config Go to Log Hub Console , choose Log Config on the left most side of the page Click Create a log config , type in the Config Name like: spring-config . Choose the log type as Multi-line Text . Choose the Parser as Java-Spring Boot . Copy paste the following log format in Log Format text box: %d{yyyy-MM-dd HH:mm:ss.SSS} %-5level [%thread] %logger : %msg%n Copy and paste the following sample log into the Sample Log box: 2022-02-18 10:32:26.400 ERROR [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.ArithmeticException: / by zero] with root cause java.lang.ArithmeticException: / by zero at com.springexamples.demo.web.LoggerController.logs(LoggerController.java:22) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke Click Parse Log , you can see the following attributes: This means that your sample logs has been successfully parsed base on input log format. Click Save . We have successfully created a multi-line Spring Boot log config. Create log ingestion Note Please make sure the application log pipeline is in Active status, before proceeding this section. Find the application log pipeline you just created, by clicking it's name, we can enter the detailed page: Click Create an Ingestion , choose From Instance Group . Then, select Choose exists , click Next Select the instance group you have just created and click Next Type in the following log path: /tmp/springboot-sf4j-logback.log Select Choose exists and choose spring-config . The rest parameters will be auto filled for you. Click Next , then click Create We have successfully created one ingestion for Spring Boot Logs. Create Spring Boot Multi-line Logs Let's go back to your Workshop Demo Website again, go to the detail page of Funny Moto. Click Add To Cart button. Status Code 500 will show up, that's what we expected: We are generating Spring Boot exceptions in the back-end server. You can do these two steps multiple times to create more java multi-line logs. View Application Log Dashboard We have created Spring Boot application log Pipeline, now let's go back to the OpenSearch Dashboard and have a look! Open the Dashboard page in your browser. Create Index Pattern Go to the location shown in the graph below and select Stack Management : Select Index Patterns : Select Create Index Pattern : Type in app-pipe-* and click Next step > : Select time as time field and click Create index pattern : Go to the location shown in the graph below: Click app-pipe at the location below: You can find the original Spring boot logs: We have completed all the steps of creating an application log pipeline.","title":"5.2 Ingest Application Logs via Log Hub Console"},{"location":"workshop/log-analytics-pipelines/application-log/#ingest-application-logs-via-log-hub-console","text":"Estimated time: 10 minutes Log Hub supports ingest AWS Service logs and application (e.g. Nginx , Apache HTTP Server ) logs. This section will guide you to ingest the access logs of a group of Spring Boot servers which you have deployed in Deploy Demo Web Site . In this section, you will learn how to install log agents on selected instances, define log format and ingest logs on a single web console. The following is the architecture diagram.","title":"Ingest Application Logs via Log Hub Console"},{"location":"workshop/log-analytics-pipelines/application-log/#create-application-log-pipeline","text":"Go to LogHub Web Console , choose Application Log in Log Analytics Pipelines section Click Create a pipeline and type in the following parameters: Index name: app-pipe Shard number: 2 Enable auto scaling?: No Click Next , and choose the AOS domain as workshop-os , remain other parameters and select Next , then Create Then you can see the pipeline is in Creating status.","title":"Create application log pipeline"},{"location":"workshop/log-analytics-pipelines/application-log/#create-ec2-policy","text":"If we want to enable servers to be able to stream logs to kinesis, EC2 policies are needed! So let's do some quick steps and create a new EC2 policy for your Demo Website spring servers. Warning Please wait until the application pipeline status changes to Active ! On the Log Hub Console , select the pipeline name and view the details of that log pipeline Go to Permission tab and copy the provided JSON policy Go to AWS Console > IAM > Policies on the left column Click Create Policy , choose JSON and replace all the content inside the text block. Remember to substitute <YOUR ACCOUNT ID> with your true account id! Please refer to the graph below: Click Next , Next , then type in the name for this policy, example name: loghub-ec2-policy Choose Create policy Go to AWS Console > EC2 , choose one of the instance which name is LoghubWorkshop/workshopASG , select Security tab and click the IAM Role link Click Add permissions > Attach policies , and attach that newly created policy to this role","title":"Create EC2 policy"},{"location":"workshop/log-analytics-pipelines/application-log/#create-instance-group","text":"Go to LogHub Web Console , choose Instance Group on the left side of the page Click Create an instance group , now you can see two instances on the list: Note All the instances with ssm agent will come up in this list, if there are non-relevant instances, please search for Instances ID in AWS Console first. Choosing the wrong instances might cause no data in dashboard. 3. Select both of the instances and click Install log agent , the agent installation process will start. We use fluent-bit as log agent in LogHub. Please wait until the installation complete, it will show Online in Pending Status column: 4. Then we can type in the name for instance group and click Create . The instance group is successfully created.","title":"Create Instance Group"},{"location":"workshop/log-analytics-pipelines/application-log/#create-spring-log-config","text":"Go to Log Hub Console , choose Log Config on the left most side of the page Click Create a log config , type in the Config Name like: spring-config . Choose the log type as Multi-line Text . Choose the Parser as Java-Spring Boot . Copy paste the following log format in Log Format text box: %d{yyyy-MM-dd HH:mm:ss.SSS} %-5level [%thread] %logger : %msg%n Copy and paste the following sample log into the Sample Log box: 2022-02-18 10:32:26.400 ERROR [http-nio-8080-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.ArithmeticException: / by zero] with root cause java.lang.ArithmeticException: / by zero at com.springexamples.demo.web.LoggerController.logs(LoggerController.java:22) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke Click Parse Log , you can see the following attributes: This means that your sample logs has been successfully parsed base on input log format. Click Save . We have successfully created a multi-line Spring Boot log config.","title":"Create Spring log config"},{"location":"workshop/log-analytics-pipelines/application-log/#create-log-ingestion","text":"Note Please make sure the application log pipeline is in Active status, before proceeding this section. Find the application log pipeline you just created, by clicking it's name, we can enter the detailed page: Click Create an Ingestion , choose From Instance Group . Then, select Choose exists , click Next Select the instance group you have just created and click Next Type in the following log path: /tmp/springboot-sf4j-logback.log Select Choose exists and choose spring-config . The rest parameters will be auto filled for you. Click Next , then click Create We have successfully created one ingestion for Spring Boot Logs.","title":"Create log ingestion"},{"location":"workshop/log-analytics-pipelines/application-log/#create-spring-boot-multi-line-logs","text":"Let's go back to your Workshop Demo Website again, go to the detail page of Funny Moto. Click Add To Cart button. Status Code 500 will show up, that's what we expected: We are generating Spring Boot exceptions in the back-end server. You can do these two steps multiple times to create more java multi-line logs.","title":"Create Spring Boot Multi-line Logs"},{"location":"workshop/log-analytics-pipelines/application-log/#view-application-log-dashboard","text":"We have created Spring Boot application log Pipeline, now let's go back to the OpenSearch Dashboard and have a look! Open the Dashboard page in your browser. Create Index Pattern Go to the location shown in the graph below and select Stack Management : Select Index Patterns : Select Create Index Pattern : Type in app-pipe-* and click Next step > : Select time as time field and click Create index pattern : Go to the location shown in the graph below: Click app-pipe at the location below: You can find the original Spring boot logs: We have completed all the steps of creating an application log pipeline.","title":"View Application Log Dashboard"},{"location":"workshop/log-analytics-pipelines/cloudfront-log/","text":"Ingest AWS Service Logs via Log Hub Console Log Hub provides two ways to ingest AWS Services logs, via Log Hub console or CloudFormation Stack. In this section, you will learn how to ingest Amazon CloudFront logs and RDS/Aurora MySQL logs using the Log Hub console. CloudFront Logs Estimated time: 12 minutes CloudFront Standard Logs provide detailed records about every request that\u2019s made to a distribution. In this chapter, you will learn how to ingest CloudFront access logs into Amazon OpenSearch service and build up dashboards. By following the steps, Log Hub will create the architecture in your AWS account: Go to Log Hub Console . In the navigation pane, under Log Analytics Pipelines , choose AWS Service Log . Choose the Create a log ingestion button. In the AWS Services section, choose Amazon CloudFront . Choose Next . Under Specify settings , choose Automatic for CloudFront logs enabling . The automatic mode will detect the CloudFront log location automatically. For Automatic mode , choose the CloudFront distribution from the dropdown list. You just need to choose the one named LogHub-Workshop Assets Choose Next . In Log Processing page, we can select multiple Ingested fields and Enriched fields . Please select all the enriched fields by clicking Location -optional and OS/User Agent -optional The location enriched functions will be demonstrated in the next section. Click Next . In the Specify OpenSearch domain section, select an imported domain for Amazon OpenSearch domain . Remain the other part of the page unchanged. Choose Next . Choose Create . You can view the status of the stack in the LogHub Web console: Status column shows creating means that the log pipeline is being created. Hold on! Before proceed to the next step, please wait until the pipeline status changes to Active . You can click the refresh button to get updated status. Create CloudFront fake logs After the pipeline status changes to Active , we can go to the Workshop Demo Website and start creating some CloudFront fake logs. Note We are simulating a real use case from a customer whose e-commercial website is frequently being visited, so fake logs can help us to better understand customer's business situation. Firstly, go to the Workshop Demo Website, click Generate Logs , which is on the right-upper corner. Then click Generate CloudFront Logs . Wait for a few seconds until it shows the following pop-up: We have finished the log generation step! View Cloudfront Log Dashboard Since we have created the CloudFront Log Pipeline and generated fake log, now let's go back to the OpenSearch Dashboard and have a look! Open the Dashboard page in your browser. Go to the location shown in the graph below, you can find the CloudFront dashboard have already been imported for you, which name is xxxxxxxxxxxxx-cloudfront-dashboard . Click it and you can view all the details by yourself: The CloudFront dashboard should look like this: So far, we have successfully created a service pipeline for CloudFront Service, and we are able to get insight of the dashboard in OpenSearch. RDS/Aurora MySQL Logs Estimated time: 10 minutes In this section, we will describe how to ingest logs from Amazon RDS into Amazon OpenSearch service and build up visualization dashboards. By following the steps, Log Hub will create the architecture in your AWS account: Go back to the Log Hub Console. In the navigation pane, under Log Analytics Pipelines , choose AWS Service Log . Choose the Create a log ingestion button. In the AWS Services section, choose Amazon RDS . Choose Next . Under Specify logs settings , choose Automatic . Choose the RDS cluster from the dropdown list. We choose MySQL-workshop-db . Make sure you select the Audit log option! Choose Next . In the Specify OpenSearch domain section, select an imported domain for Amazon OpenSearch domain . Remain the other part of the page unchanged. Choose Next . Choose Create . You can view the status of the stack in the LogHub Web console. Status column shows creating means that the log pipeline is being created. Hold on! Please wait until the status change to \"Active\" before proceeding. Generate slow query logs Now we can go to the Workshop Demo Website and start creating some RDS logs. Firstly, go back to Workshop Demo Website home again, we can see three products listed on the Website. We click the View Detail button under Funny Moto . Note The product details will show up very slowly. Because we are generating slow query logs here. That's what we expected, because we are generating slow query logs now. View RDS Log Dashboard We can now leave the website behind and go to OpenSearch Dashboard to take a peek. Open the Dashboard page in your browser. Go to the location shown in the graph below, you can find the RDS dashboard have already been imported for you, which name is workshop-db-rds-dashboard . Click it and you can view all the details by yourself: The RDS dashboard should look like this: Congratulations! We have created the service log pipeline for RDS successfully.","title":"5.1 Ingest Service Logs via Log Hub Console"},{"location":"workshop/log-analytics-pipelines/cloudfront-log/#ingest-aws-service-logs-via-log-hub-console","text":"Log Hub provides two ways to ingest AWS Services logs, via Log Hub console or CloudFormation Stack. In this section, you will learn how to ingest Amazon CloudFront logs and RDS/Aurora MySQL logs using the Log Hub console.","title":"Ingest AWS Service Logs via Log Hub Console"},{"location":"workshop/log-analytics-pipelines/cloudfront-log/#cloudfront-logs","text":"Estimated time: 12 minutes CloudFront Standard Logs provide detailed records about every request that\u2019s made to a distribution. In this chapter, you will learn how to ingest CloudFront access logs into Amazon OpenSearch service and build up dashboards. By following the steps, Log Hub will create the architecture in your AWS account: Go to Log Hub Console . In the navigation pane, under Log Analytics Pipelines , choose AWS Service Log . Choose the Create a log ingestion button. In the AWS Services section, choose Amazon CloudFront . Choose Next . Under Specify settings , choose Automatic for CloudFront logs enabling . The automatic mode will detect the CloudFront log location automatically. For Automatic mode , choose the CloudFront distribution from the dropdown list. You just need to choose the one named LogHub-Workshop Assets Choose Next . In Log Processing page, we can select multiple Ingested fields and Enriched fields . Please select all the enriched fields by clicking Location -optional and OS/User Agent -optional The location enriched functions will be demonstrated in the next section. Click Next . In the Specify OpenSearch domain section, select an imported domain for Amazon OpenSearch domain . Remain the other part of the page unchanged. Choose Next . Choose Create . You can view the status of the stack in the LogHub Web console: Status column shows creating means that the log pipeline is being created. Hold on! Before proceed to the next step, please wait until the pipeline status changes to Active . You can click the refresh button to get updated status.","title":"CloudFront Logs"},{"location":"workshop/log-analytics-pipelines/cloudfront-log/#create-cloudfront-fake-logs","text":"After the pipeline status changes to Active , we can go to the Workshop Demo Website and start creating some CloudFront fake logs. Note We are simulating a real use case from a customer whose e-commercial website is frequently being visited, so fake logs can help us to better understand customer's business situation. Firstly, go to the Workshop Demo Website, click Generate Logs , which is on the right-upper corner. Then click Generate CloudFront Logs . Wait for a few seconds until it shows the following pop-up: We have finished the log generation step!","title":"Create CloudFront fake logs"},{"location":"workshop/log-analytics-pipelines/cloudfront-log/#view-cloudfront-log-dashboard","text":"Since we have created the CloudFront Log Pipeline and generated fake log, now let's go back to the OpenSearch Dashboard and have a look! Open the Dashboard page in your browser. Go to the location shown in the graph below, you can find the CloudFront dashboard have already been imported for you, which name is xxxxxxxxxxxxx-cloudfront-dashboard . Click it and you can view all the details by yourself: The CloudFront dashboard should look like this: So far, we have successfully created a service pipeline for CloudFront Service, and we are able to get insight of the dashboard in OpenSearch.","title":"View Cloudfront Log Dashboard"},{"location":"workshop/log-analytics-pipelines/cloudfront-log/#rdsaurora-mysql-logs","text":"Estimated time: 10 minutes In this section, we will describe how to ingest logs from Amazon RDS into Amazon OpenSearch service and build up visualization dashboards. By following the steps, Log Hub will create the architecture in your AWS account: Go back to the Log Hub Console. In the navigation pane, under Log Analytics Pipelines , choose AWS Service Log . Choose the Create a log ingestion button. In the AWS Services section, choose Amazon RDS . Choose Next . Under Specify logs settings , choose Automatic . Choose the RDS cluster from the dropdown list. We choose MySQL-workshop-db . Make sure you select the Audit log option! Choose Next . In the Specify OpenSearch domain section, select an imported domain for Amazon OpenSearch domain . Remain the other part of the page unchanged. Choose Next . Choose Create . You can view the status of the stack in the LogHub Web console. Status column shows creating means that the log pipeline is being created. Hold on! Please wait until the status change to \"Active\" before proceeding.","title":"RDS/Aurora MySQL Logs"},{"location":"workshop/log-analytics-pipelines/cloudfront-log/#generate-slow-query-logs","text":"Now we can go to the Workshop Demo Website and start creating some RDS logs. Firstly, go back to Workshop Demo Website home again, we can see three products listed on the Website. We click the View Detail button under Funny Moto . Note The product details will show up very slowly. Because we are generating slow query logs here. That's what we expected, because we are generating slow query logs now.","title":"Generate slow query logs"},{"location":"workshop/log-analytics-pipelines/cloudfront-log/#view-rds-log-dashboard","text":"We can now leave the website behind and go to OpenSearch Dashboard to take a peek. Open the Dashboard page in your browser. Go to the location shown in the graph below, you can find the RDS dashboard have already been imported for you, which name is workshop-db-rds-dashboard . Click it and you can view all the details by yourself: The RDS dashboard should look like this: Congratulations! We have created the service log pipeline for RDS successfully.","title":"View RDS Log Dashboard"},{"location":"workshop/log-analytics-pipelines/eks-log/","text":"Ingest EKS Pod Logs via Log Hub Console Create Nginx log config Go to Log Hub Console , choose Log Config on the left most side of the page Click Create a log config , type in the Config Name like: nginx-config . Choose the log type as Nginx . Copy paste the following log format in Log Format text box: log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; Copy and paste the following sample log into the Sample Log box: 127.0.0.1 - - [24/Dec/2021:01:27:11 +0000] \"GET / HTTP/1.1\" 200 3520 \"-\" \"curl/7.79.1\" \"-\" Click Parse Log Click Save . We have successfully created a multi-line Spring Boot log config. Import an EKS Cluster Go to the Log Hub Console . In the left sidebar, under Log Source , choose EKS Cluster . Click the Import a Cluster button. Choose the loghub-workshop-eks . Select DaemonSet as logging agent's deployment pattern. Choose Next . Choose the AOS domain as workshop-os . Configure the Network the EKS cluster and OpenSearch During the pre-requisites , we have created the EKS in the same VPC of OpenSearch. So, we can skip the VPC peering in this workshop. But we still need to update the security group. Go to AWS Console > OpenSearch Copy the value of Security group . Then click the security group to view details Edit the inbound rule of the security group Allow All Traffic from the Security group you copied above. Save the rules Go back to the Log Hub console, and check the checkbox that you have completed the \"Network Configuration\". Choose Next . Choose Create . Create eks pod log ingestion Click the EKS Cluster loghub-workshop-eks that has been imported above. Go to App Log Ingestion tab and click Create an Ingestion . In Specify Pipeline Settings page, Select Create new Index Prefix: eks-nginx Click Next In Specify log config page: Type in the following log path: /var/log/containers/app-nginx-demo*nginx-ns* And Select nginx-config from Log Config dropdown. Click Next Click Create Wait the App Log Ingestion Status as Created Deploy fluent-bit agent to EKS Waring Please follow the workshop guide to deploy the fluent-bit agent Click the DaemonSet Guide tab Deploy fluent-bit log agent as DaemonSet Go to the Cloud9 workspace created in Pre-request Create a file fluent-bit-logging.yaml and copy&paste the yaml generated in LogHub console run the command below in terminal kubectl apply -f fluent-bit-logging.yaml Make sure your fluent-bit is running kubectl get pods -n logging Generate Nginx Pod Logs Run the command, and you will find the load balancer at LoadBalancer Ingress in response kubectl describe service nginx-service -n nginx-ns In a browser, enter the load balancer address, and you should see Welcome to nginx This will generate access log. Feel free to generate more by refreshing the page. View the Nginx Log Dashboard We can now leave the website behind and go to OpenSearch Dashboard to take a peek. Open the Dashboard page in your browser. Go to the location shown in the graph below, you can find the RDS dashboard have already been imported for you, which name is eks-nginx-dashboard . Click it and you can view all the details by yourself: The dashboard should look like this: We have completed all the steps of creating an eks pod log pipeline.","title":"5.4 (Optional) Ingest EKS Pod Logs via Log Hub Console"},{"location":"workshop/log-analytics-pipelines/eks-log/#ingest-eks-pod-logs-via-log-hub-console","text":"","title":"Ingest EKS Pod Logs via Log Hub Console"},{"location":"workshop/log-analytics-pipelines/eks-log/#create-nginx-log-config","text":"Go to Log Hub Console , choose Log Config on the left most side of the page Click Create a log config , type in the Config Name like: nginx-config . Choose the log type as Nginx . Copy paste the following log format in Log Format text box: log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; Copy and paste the following sample log into the Sample Log box: 127.0.0.1 - - [24/Dec/2021:01:27:11 +0000] \"GET / HTTP/1.1\" 200 3520 \"-\" \"curl/7.79.1\" \"-\" Click Parse Log Click Save . We have successfully created a multi-line Spring Boot log config.","title":"Create Nginx log config"},{"location":"workshop/log-analytics-pipelines/eks-log/#import-an-eks-cluster","text":"Go to the Log Hub Console . In the left sidebar, under Log Source , choose EKS Cluster . Click the Import a Cluster button. Choose the loghub-workshop-eks . Select DaemonSet as logging agent's deployment pattern. Choose Next . Choose the AOS domain as workshop-os . Configure the Network the EKS cluster and OpenSearch During the pre-requisites , we have created the EKS in the same VPC of OpenSearch. So, we can skip the VPC peering in this workshop. But we still need to update the security group. Go to AWS Console > OpenSearch Copy the value of Security group . Then click the security group to view details Edit the inbound rule of the security group Allow All Traffic from the Security group you copied above. Save the rules Go back to the Log Hub console, and check the checkbox that you have completed the \"Network Configuration\". Choose Next . Choose Create .","title":"Import an EKS Cluster"},{"location":"workshop/log-analytics-pipelines/eks-log/#create-eks-pod-log-ingestion","text":"Click the EKS Cluster loghub-workshop-eks that has been imported above. Go to App Log Ingestion tab and click Create an Ingestion . In Specify Pipeline Settings page, Select Create new Index Prefix: eks-nginx Click Next In Specify log config page: Type in the following log path: /var/log/containers/app-nginx-demo*nginx-ns* And Select nginx-config from Log Config dropdown. Click Next Click Create Wait the App Log Ingestion Status as Created","title":"Create eks pod log ingestion"},{"location":"workshop/log-analytics-pipelines/eks-log/#deploy-fluent-bit-agent-to-eks","text":"Waring Please follow the workshop guide to deploy the fluent-bit agent Click the DaemonSet Guide tab Deploy fluent-bit log agent as DaemonSet Go to the Cloud9 workspace created in Pre-request Create a file fluent-bit-logging.yaml and copy&paste the yaml generated in LogHub console run the command below in terminal kubectl apply -f fluent-bit-logging.yaml Make sure your fluent-bit is running kubectl get pods -n logging","title":"Deploy fluent-bit agent to EKS"},{"location":"workshop/log-analytics-pipelines/eks-log/#generate-nginx-pod-logs","text":"Run the command, and you will find the load balancer at LoadBalancer Ingress in response kubectl describe service nginx-service -n nginx-ns In a browser, enter the load balancer address, and you should see Welcome to nginx This will generate access log. Feel free to generate more by refreshing the page.","title":"Generate Nginx Pod Logs"},{"location":"workshop/log-analytics-pipelines/eks-log/#view-the-nginx-log-dashboard","text":"We can now leave the website behind and go to OpenSearch Dashboard to take a peek. Open the Dashboard page in your browser. Go to the location shown in the graph below, you can find the RDS dashboard have already been imported for you, which name is eks-nginx-dashboard . Click it and you can view all the details by yourself: The dashboard should look like this: We have completed all the steps of creating an eks pod log pipeline.","title":"View the Nginx Log Dashboard"},{"location":"workshop/log-analytics-pipelines/elb-log/","text":"Ingest Logs via CloudFormation Stack Estimated time: 10 minutes In addition to the Log Hub console, Log Hub also allows customers to ingest logs by provisioning a standalone CloudFormation template. These templates are super useful when The customer has limited log types, for example the customer only one type of logs to analyze. The customer wants to integrate with the Infrastructure-as-Code technology, and they can reuse the CloudFormation templates. In this chapter, you will learn how to ingest ELB access logs into Amazon OpenSearch service and build up dashboards. ELB Access logs provides access logs that capture detailed information about requests sent to your load balancer. ELB publishes a log file for each load balancer node every 5 minutes. Enable ELB Access Logs Go to AWS Console > EC2 > Load Balancers on the left column of the page Select the balancer which name starts with Works-works- Under Description tab, we can find Attributes section, select Edit attributes Please enable AccessLogs and create a new s3 location to store ELB, please save the name of s3 for later usage. Also, select Create this location for me . The suggested name is: <your-login>-loghub-workshop-logging-bucket/elb Please double-check if you have selected all the following items: Click Save . Create log ingestion using CloudFormation Log in the AWS Management Console and select the button to launch the LogHub-ELBLog AWS CloudFormation template. Click Next and fill in the parameters required: Parameter Default Description Log Bucket Name <Requires input> The S3 bucket stores ELB log, which we created in adding ELB attributes: YOURLOGIN-loghub-workshop-logging-bucket Log Bucket Prefix <Requires input> Type in elb Engine Type OpenSearch Choose OpenSearch . OpenSearch Domain Name <Requires input> Type in workshop-os OpenSearch Endpoint <Requires input> The OpenSearch endpoint URL. You can find it inside the Log Hub Portal: AWS Console > Cloudformation > Stacks > WorkshopDemo > Ouputs > opensearchDomain Index Prefix <requires input> Type in workshop Create Sample Dashboard Yes Choose Yes this time. VPC ID <requires input> Select the VPC which name starts with LogHub/LogHubVpc/DefaultVPC Subnet IDs <requires input> Select TWO private subnets which names are LogHub/LogHubVpc/DefaultVPC/privateSubnet1 and LogHub/LogHubVpc/DefaultVPC/privateSubnet2 Security Group ID <requires input> Select the Security Group which name start with LogHub-ProcessSecurityGroup- S3 Backup Bucket <requires input> YOURLOGIN-loghub-workshop-logging-bucket Number Of Shards 5 Number of shards to distribute the index evenly across all data nodes, keep the size of each shard between 10-50 GiB. Number of Replicas 1 The number of days required to move the index into warm storage, this is only effecitve when the value is >0 and warm storage is enabled in OpenSearch. Days to Warm Storage 0 Number of replicas for OpenSearch Index. Each replica is a full copy of an index. Days to Cold Storage 0 The number of days required to move the index into cold storage, this is only effecitve when the value is >0 and cold storage is enabled in OpenSearch. Days to Retain 0 The total number of days to retain the index, if value is 0, the index will not be deleted. Your parameters should look mostly like this: Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template creates AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a CREATE_COMPLETE status in approximately 10 minutes. We have successfully created a service log pipeline for ELB from Cloudformation, and congrats on finishing all the sections in this workshop!","title":"5.3 Ingest Logs via CloudFormation Stack"},{"location":"workshop/log-analytics-pipelines/elb-log/#ingest-logs-via-cloudformation-stack","text":"Estimated time: 10 minutes In addition to the Log Hub console, Log Hub also allows customers to ingest logs by provisioning a standalone CloudFormation template. These templates are super useful when The customer has limited log types, for example the customer only one type of logs to analyze. The customer wants to integrate with the Infrastructure-as-Code technology, and they can reuse the CloudFormation templates. In this chapter, you will learn how to ingest ELB access logs into Amazon OpenSearch service and build up dashboards. ELB Access logs provides access logs that capture detailed information about requests sent to your load balancer. ELB publishes a log file for each load balancer node every 5 minutes.","title":"Ingest Logs via CloudFormation Stack"},{"location":"workshop/log-analytics-pipelines/elb-log/#enable-elb-access-logs","text":"Go to AWS Console > EC2 > Load Balancers on the left column of the page Select the balancer which name starts with Works-works- Under Description tab, we can find Attributes section, select Edit attributes Please enable AccessLogs and create a new s3 location to store ELB, please save the name of s3 for later usage. Also, select Create this location for me . The suggested name is: <your-login>-loghub-workshop-logging-bucket/elb Please double-check if you have selected all the following items: Click Save .","title":"Enable ELB Access Logs"},{"location":"workshop/log-analytics-pipelines/elb-log/#create-log-ingestion-using-cloudformation","text":"Log in the AWS Management Console and select the button to launch the LogHub-ELBLog AWS CloudFormation template. Click Next and fill in the parameters required: Parameter Default Description Log Bucket Name <Requires input> The S3 bucket stores ELB log, which we created in adding ELB attributes: YOURLOGIN-loghub-workshop-logging-bucket Log Bucket Prefix <Requires input> Type in elb Engine Type OpenSearch Choose OpenSearch . OpenSearch Domain Name <Requires input> Type in workshop-os OpenSearch Endpoint <Requires input> The OpenSearch endpoint URL. You can find it inside the Log Hub Portal: AWS Console > Cloudformation > Stacks > WorkshopDemo > Ouputs > opensearchDomain Index Prefix <requires input> Type in workshop Create Sample Dashboard Yes Choose Yes this time. VPC ID <requires input> Select the VPC which name starts with LogHub/LogHubVpc/DefaultVPC Subnet IDs <requires input> Select TWO private subnets which names are LogHub/LogHubVpc/DefaultVPC/privateSubnet1 and LogHub/LogHubVpc/DefaultVPC/privateSubnet2 Security Group ID <requires input> Select the Security Group which name start with LogHub-ProcessSecurityGroup- S3 Backup Bucket <requires input> YOURLOGIN-loghub-workshop-logging-bucket Number Of Shards 5 Number of shards to distribute the index evenly across all data nodes, keep the size of each shard between 10-50 GiB. Number of Replicas 1 The number of days required to move the index into warm storage, this is only effecitve when the value is >0 and warm storage is enabled in OpenSearch. Days to Warm Storage 0 Number of replicas for OpenSearch Index. Each replica is a full copy of an index. Days to Cold Storage 0 The number of days required to move the index into cold storage, this is only effecitve when the value is >0 and cold storage is enabled in OpenSearch. Days to Retain 0 The total number of days to retain the index, if value is 0, the index will not be deleted. Your parameters should look mostly like this: Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template creates AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation console in the Status column. You should receive a CREATE_COMPLETE status in approximately 10 minutes. We have successfully created a service log pipeline for ELB from Cloudformation, and congrats on finishing all the sections in this workshop!","title":"Create log ingestion using CloudFormation"},{"location":"workshop/log-analytics-pipelines/multi-line-dashboard/","text":"View Multi-line Log Dashboard We have created the multi-line application Pipeline, now let's go back to the OpenSearch Dashboard and have a look! Open the Dashboard page in your browser. Go to the location shown in the graph below, you can find the Multi-line application dashboard, which have already been imported for you, which name is -dashboard . Click it and you can view all the details by yourself:","title":"Multi line dashboard"},{"location":"workshop/log-analytics-pipelines/multi-line-dashboard/#view-multi-line-log-dashboard","text":"We have created the multi-line application Pipeline, now let's go back to the OpenSearch Dashboard and have a look! Open the Dashboard page in your browser. Go to the location shown in the graph below, you can find the Multi-line application dashboard, which have already been imported for you, which name is -dashboard . Click it and you can view all the details by yourself:","title":"View Multi-line Log Dashboard"},{"location":"workshop/log-analytics-pipelines/rds-log/","text":"RDS/Aurora MySQL Logs Estimated time: 10 minutes In this section, we will describe how to ingest logs from Amazon RDS into Amazon OpenSearch service and build up visualization dashboards. By following the steps, Log Hub will create the architecture in your AWS account: Sign in to the Log Hub Console. In the navigation pane, under Log Analytics Pipelines , choose Service Log . Choose the Create a log ingestion button. In the AWS Services section, choose Amazon RDS . Choose Next . Under Specify logs settings , choose Automatic . Choose the RDS cluster from the dropdown list. We choose MySQL-workshop-db . Make sure you select the Audit log option! Choose Next . In the Specify OpenSearch domain section, select an imported domain for Amazon OpenSearch domain . Remain the other part of the page unchanged. Choose Next . Choose Create . You can view the status of the stack in the LogHub Web console. Status column shows creating means that the log pipeline is being created. Hold on! Please wait until the status change to \"Active\" before proceeding. Generate slow query logs Now we can go to the Workshop Demo Website and start creating some RDS logs. Firstly, go back to Workshop Demo Website home again, we can see three products listed on the Website. We click the View Detail button under Funny Moto . Notice that: The product details will show up very slowly. Because we are generating slow query logs here. That's what we expected, because we are generating slow query logs now. View RDS Log Dashboard We can now leave the website behind and go to OpenSearch Dashboard to take a peek. Open the Dashboard page in your browser. Go to the location shown in the graph below, you can find the RDS dashboard have already been imported for you, which name is workshop-db-rds-dashboard . Click it and you can view all the details by yourself: The RDS dashboard should look like this: Congratulations! We have created the service log pipeline for RDS successfully.","title":"Rds log"},{"location":"workshop/log-analytics-pipelines/rds-log/#rdsaurora-mysql-logs","text":"Estimated time: 10 minutes In this section, we will describe how to ingest logs from Amazon RDS into Amazon OpenSearch service and build up visualization dashboards. By following the steps, Log Hub will create the architecture in your AWS account: Sign in to the Log Hub Console. In the navigation pane, under Log Analytics Pipelines , choose Service Log . Choose the Create a log ingestion button. In the AWS Services section, choose Amazon RDS . Choose Next . Under Specify logs settings , choose Automatic . Choose the RDS cluster from the dropdown list. We choose MySQL-workshop-db . Make sure you select the Audit log option! Choose Next . In the Specify OpenSearch domain section, select an imported domain for Amazon OpenSearch domain . Remain the other part of the page unchanged. Choose Next . Choose Create . You can view the status of the stack in the LogHub Web console. Status column shows creating means that the log pipeline is being created. Hold on! Please wait until the status change to \"Active\" before proceeding.","title":"RDS/Aurora MySQL Logs"},{"location":"workshop/log-analytics-pipelines/rds-log/#generate-slow-query-logs","text":"Now we can go to the Workshop Demo Website and start creating some RDS logs. Firstly, go back to Workshop Demo Website home again, we can see three products listed on the Website. We click the View Detail button under Funny Moto . Notice that: The product details will show up very slowly. Because we are generating slow query logs here. That's what we expected, because we are generating slow query logs now.","title":"Generate slow query logs"},{"location":"workshop/log-analytics-pipelines/rds-log/#view-rds-log-dashboard","text":"We can now leave the website behind and go to OpenSearch Dashboard to take a peek. Open the Dashboard page in your browser. Go to the location shown in the graph below, you can find the RDS dashboard have already been imported for you, which name is workshop-db-rds-dashboard . Click it and you can view all the details by yourself: The RDS dashboard should look like this: Congratulations! We have created the service log pipeline for RDS successfully.","title":"View RDS Log Dashboard"}]}